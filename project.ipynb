{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 26 days\n",
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 26 days\n",
      "Using gpu device 0: GeForce GTX 780 (CNMeM is enabled)\n",
      "/home/i265983/Dokumenty/nn_assignments/libs/Theano/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "The streams return batches containing (u'features', u'targets')\n",
      "Each trainin batch consits of a tuple containing:\n",
      " - an array of size (25, 3, 32, 32) containing float32\n",
      " - an array of size (25, 1) containing uint8\n",
      "Validation/test batches consits of tuples containing:\n",
      " - an array of size (100, 3, 32, 32) containing float32\n",
      " - an array of size (100, 1) containing uint8\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import theano\n",
    "import theano.tensor as TT\n",
    "import lasagne\n",
    "import lasagne.layers as LL\n",
    "import lasagne.nonlinearities as LN\n",
    "import lasagne.init as LI\n",
    "from common.plotting import plot_mat\n",
    "\n",
    "\n",
    "from fuel.datasets.cifar10 import CIFAR10\n",
    "from fuel.transformers import ScaleAndShift, Cast, Flatten, Mapping\n",
    "from fuel.streams import DataStream\n",
    "from fuel.schemes import SequentialScheme, ShuffledScheme\n",
    "CIFAR10.default_transformers = ((ScaleAndShift, [2.0 / 255.0, -1], {'which_sources': 'features'}),\n",
    "                                (Cast, [np.float32], {'which_sources': 'features'}))\n",
    "cifar10_train = CIFAR10((\"train\",), subset=slice(None,40000))\n",
    "# this stream will shuffle the CIFAR10 set and return us batches of 100 examples\n",
    "cifar10_train_stream = DataStream.default_stream(cifar10_train,\n",
    "                                                 iteration_scheme=ShuffledScheme(cifar10_train.num_examples, 25))\n",
    "cifar10_validation = CIFAR10((\"train\",), subset=slice(40000, None))\n",
    "# We will use larger portions for testing and validation\n",
    "# as these dont do a backward pass and reauire less RAM.\n",
    "cifar10_validation_stream = DataStream.default_stream(cifar10_validation,\n",
    "                                                      iteration_scheme=SequentialScheme(cifar10_validation.num_examples,\n",
    "                                                                                        100))\n",
    "cifar10_test = CIFAR10((\"test\",))\n",
    "cifar10_test_stream = DataStream.default_stream(cifar10_test,\n",
    "                                                iteration_scheme=SequentialScheme(cifar10_test.num_examples, 100))\n",
    "\n",
    "\n",
    "# Check print\n",
    "print \"The streams return batches containing %s\" % (cifar10_train_stream.sources,)\n",
    "print \"Each trainin batch consits of a tuple containing:\"\n",
    "for element in next(cifar10_train_stream.get_epoch_iterator()):\n",
    "    print \" - an array of size %s containing %s\" % (element.shape, element.dtype)\n",
    "print \"Validation/test batches consits of tuples containing:\"\n",
    "for element in next(cifar10_test_stream.get_epoch_iterator()):\n",
    "    print \" - an array of size %s containing %s\" % (element.shape, element.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvNeuralNet:\n",
    "    wdec_layers = [LL.Conv2DLayer, LL.DenseLayer]\n",
    "    def __init__(self, input_var, target_var, layers, data_shape, batch_size=None):\n",
    "        self.input_var = input_var\n",
    "        self.target_var = target_var\n",
    "        self.layers = [LL.InputLayer(shape=(batch_size,)+data_shape,\n",
    "                                     input_var=self.input_var)]\n",
    "        #self.wdec = 0\n",
    "        for layer in layers:\n",
    "            if layer['type'] == LL.DenseLayer and 'W' not in layer['args']:\n",
    "                shape = LL.get_output_shape(self.layers[-1])\n",
    "                layer['args']['W'] = LI.Uniform(range=(1. / np.sqrt(shape[1])))\n",
    "            self.layers.append(layer['type'](incoming=self.layers[-1], **layer['args']))\n",
    "            #if layer['type'] in ConvNeuralNet.wdec_layers:\n",
    "            #    self.wdec += lasagne.regularization.l2(self.layers[-1].W)\n",
    "        self.network = self.layers[-1]\n",
    "        #self.wdec = TT.sum([lasagne.regularization.l2(param)\n",
    "        #                    for param in LL.get_all_params(self.network, regularizable=True)])\n",
    "        self.wdec = lasagne.regularization.regularize_network_params(self.network,\n",
    "                                                                     lasagne.regularization.l2)\n",
    "        \n",
    "    def initialize(self, learning_rate, momentum, wdec_const):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.wdec_const = wdec_const\n",
    "        \n",
    "        self.prediction = LL.get_output(self.network, deterministic=False)\n",
    "        self.loss = lasagne.objectives.categorical_crossentropy(self.prediction, self.target_var)\n",
    "        self.loss = self.loss.mean() + self.wdec_const * self.wdec\n",
    "        \n",
    "        self.params = LL.get_all_params(self.network, trainable=True)\n",
    "        # https://blogs.princeton.edu/imabandit/2013/04/01/acceleratedgradientdescent/\n",
    "        self.updates = lasagne.updates.nesterov_momentum(self.loss,\n",
    "                                                self.params,\n",
    "                                                learning_rate=self.learning_rate,\n",
    "                                                momentum=self.momentum)\n",
    "        \n",
    "        self.train_acc = TT.mean(TT.eq(TT.argmax(self.prediction, axis=1), self.target_var),\n",
    "                                 dtype=theano.config.floatX)\n",
    "        \n",
    "        self.test_prediction = LL.get_output(self.network, deterministic=True)\n",
    "        self.test_loss = lasagne.objectives.categorical_crossentropy(self.test_prediction,\n",
    "                                                                     self.target_var)\n",
    "        self.test_loss = self.test_loss.mean()\n",
    "        self.test_acc = TT.mean(TT.eq(TT.argmax(self.test_prediction, axis=1), self.target_var),\n",
    "                                dtype=theano.config.floatX)\n",
    "        \n",
    "        self.train_fn = theano.function([self.input_var, self.target_var],\n",
    "                                        [self.loss, self.train_acc],\n",
    "                                        updates=self.updates)\n",
    "        self.val_fn = theano.function([self.input_var, self.target_var],\n",
    "                                      [self.test_loss, self.test_acc])\n",
    "        self.test_prediction_fn = theano.function([self.input_var], [self.test_prediction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAACjCAYAAACuViRsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIoYE8YYdERERMST4X2RJPJRH8fL4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f29b346c290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Transform(object):\n",
    "    def __init__(self, rng=None):\n",
    "        if rng == None:\n",
    "            rng = numpy.random\n",
    "        self.rng = rng\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X\n",
    "    \n",
    "    def name(self):\n",
    "        return \"Identity transformation\"\n",
    "\n",
    "class Shift(Transform):\n",
    "    def __init__(self, shift_size=4, **kwargs):\n",
    "        super(Shift, self).__init__(**kwargs)\n",
    "        self.shift_size = shift_size\n",
    "        \n",
    "    def transform(self, X):\n",
    "        res = X\n",
    "        for i in xrange(res.shape[0]):\n",
    "            res[i] = np.roll(res[i], self.rng.randint(-self.shift_size, self.shift_size + 1), axis=1)\n",
    "            res[i] = np.roll(res[i], self.rng.randint(-self.shift_size, self.shift_size + 1), axis=2)\n",
    "        return res\n",
    "    \n",
    "    def name(self):\n",
    "        return \"Random shift by %d\" % self.shift.size\n",
    "    \n",
    "trans = [trans() for trans in Transform.__subclasses__()]\n",
    "def random_transform(X_batch):\n",
    "    global trans\n",
    "    return trans[np.random.randint(0, len(trans))].transform(X_batch)\n",
    "\n",
    "# example of transformation\n",
    "for X_batch, Y_batch in cifar10_train_stream.get_epoch_iterator():\n",
    "    X = X_batch\n",
    "    break\n",
    "X = random_transform(X[:10])\n",
    "plot_mat(X, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i265983/.local/lib/python2.7/site-packages/lasagne/layers/conv.py:489: UserWarning: The `image_shape` keyword argument to `tensor.nnet.conv2d` is deprecated, it has been renamed to `input_shape`.\n",
      "  border_mode=border_mode)\n"
     ]
    }
   ],
   "source": [
    "input_var = TT.tensor4('inputs')\n",
    "target_var = TT.ivector('targets')\n",
    "\n",
    "net = ConvNeuralNet(input_var, target_var,\n",
    "                    layers=[{'type' : LL.Conv2DLayer,\n",
    "                             'args' : {'num_filters' : 50,\n",
    "                                       'filter_size' : (5,5),\n",
    "                                       'nonlinearity' : LN.rectify,\n",
    "                                       'W' : LI.Normal(std=0.05,mean=0.0)}},\n",
    "                            {'type' : LL.MaxPool2DLayer,\n",
    "                             'args' : {'pool_size' : (2,2)}},\n",
    "                            {'type' : LL.DropoutLayer,\n",
    "                             'args' : {'p' : 0.2}},\n",
    "                            {'type' : LL.Conv2DLayer,\n",
    "                             'args' : {'num_filters' : 100,\n",
    "                                       'filter_size' : (5,5),\n",
    "                                       'nonlinearity' : LN.rectify,\n",
    "                                       'W' : LI.Normal(std=0.05,mean=0.0)}},\n",
    "                            {'type' : LL.MaxPool2DLayer,\n",
    "                             'args' : {'pool_size' : (2,2)}},\n",
    "                            {'type' : LL.DropoutLayer,\n",
    "                             'args' : {'p' : 0.2}},\n",
    "                            {'type' : LL.FlattenLayer,\n",
    "                             'args' : {}},\n",
    "                            {'type' : LL.DenseLayer,\n",
    "                             'args' : {'num_units' : 500,\n",
    "                                       'nonlinearity' : LN.rectify}},\n",
    "                            {'type' : LL.DropoutLayer,\n",
    "                             'args' : {'p' : 0.5}},\n",
    "                            {'type' : LL.DenseLayer,\n",
    "                             'args' : {'num_units' : 500,\n",
    "                                       'nonlinearity' : LN.rectify}},\n",
    "                            {'type' : LL.DropoutLayer,\n",
    "                             'args' : {'p' : 0.5}},\n",
    "                            {'type' : LL.DenseLayer,\n",
    "                             'args' : {'num_units' : 100,\n",
    "                                       'nonlinearity' : LN.rectify}},\n",
    "                            {'type' : LL.DropoutLayer,\n",
    "                             'args' : {'p' : 0.5}},\n",
    "                            {'type' : LL.DenseLayer,\n",
    "                             'args' : {'num_units' : 10,\n",
    "                                       'nonlinearity' : LN.softmax}}\n",
    "                    ],\n",
    "                    data_shape = (3,32,32))\n",
    "\n",
    "l_rate = theano.shared(np.array(0.01, dtype=theano.config.floatX))\n",
    "momentum = 0.9\n",
    "wdec_const = 1e-3 #3e-3\n",
    "net.initialize(l_rate, momentum, wdec_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def snapshot_params(net):\n",
    "    return LL.get_all_param_values(net.network)\n",
    "def load_params(net, params):\n",
    "    LL.set_all_param_values(net.network, params)\n",
    "    \n",
    "def compute_error_rate(stream, net):\n",
    "    accs = 0.0\n",
    "    loss = 0.0\n",
    "    num_batches = 0.0\n",
    "    for X, Y in stream.get_epoch_iterator():\n",
    "        batch_loss, batch_acc = net.val_fn(X,Y.ravel())\n",
    "        loss += batch_loss\n",
    "        accs += batch_acc\n",
    "        num_batches += 1\n",
    "    return loss/num_batches, 1 - accs/num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started at 14:04:14\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 1 took 31.988s, currently going to do 5\n",
      "  training loss: 2.467094, validation loss: 1.622855\n",
      "  validation accuracy:\t\t39.01%\n",
      "  training accuracy:\t\t25.30%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 2 took 30.911s, currently going to do 5\n",
      "  training loss: 2.017827, validation loss: 1.345108\n",
      "  validation accuracy:\t\t50.58%\n",
      "  training accuracy:\t\t39.30%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 3 took 30.911s, currently going to do 7\n",
      "  training loss: 1.837685, validation loss: 1.320329\n",
      "  validation accuracy:\t\t53.48%\n",
      "  training accuracy:\t\t45.78%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 4 took 31.768s, currently going to do 9\n",
      "  training loss: 1.743103, validation loss: 1.184068\n",
      "  validation accuracy:\t\t58.86%\n",
      "  training accuracy:\t\t50.58%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 5 took 31.055s, currently going to do 11\n",
      "  training loss: 1.702495, validation loss: 1.092145\n",
      "  validation accuracy:\t\t62.26%\n",
      "  training accuracy:\t\t53.52%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 6 took 31.333s, currently going to do 13\n",
      "  training loss: 1.685485, validation loss: 1.042587\n",
      "  validation accuracy:\t\t63.53%\n",
      "  training accuracy:\t\t55.50%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 7 took 31.031s, currently going to do 15\n",
      "  training loss: 1.667271, validation loss: 1.032634\n",
      "  validation accuracy:\t\t64.79%\n",
      "  training accuracy:\t\t57.38%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 8 took 31.336s, currently going to do 17\n",
      "  training loss: 1.619754, validation loss: 0.912097\n",
      "  validation accuracy:\t\t68.96%\n",
      "  training accuracy:\t\t59.39%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 9 took 31.267s, currently going to do 19\n",
      "  training loss: 1.571367, validation loss: 0.897869\n",
      "  validation accuracy:\t\t69.43%\n",
      "  training accuracy:\t\t60.79%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 10 took 29.746s, currently going to do 19\n",
      "  training loss: 1.529286, validation loss: 0.897409\n",
      "  validation accuracy:\t\t69.27%\n",
      "  training accuracy:\t\t61.97%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 11 took 31.367s, currently going to do 23\n",
      "  training loss: 1.486118, validation loss: 0.823601\n",
      "  validation accuracy:\t\t71.60%\n",
      "  training accuracy:\t\t63.58%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 12 took 32.400s, currently going to do 25\n",
      "  training loss: 1.451326, validation loss: 0.825552\n",
      "  validation accuracy:\t\t71.70%\n",
      "  training accuracy:\t\t64.51%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 13 took 31.191s, currently going to do 27\n",
      "  training loss: 1.421217, validation loss: 0.826523\n",
      "  validation accuracy:\t\t71.76%\n",
      "  training accuracy:\t\t65.47%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 14 took 31.315s, currently going to do 29\n",
      "  training loss: 1.398308, validation loss: 0.808163\n",
      "  validation accuracy:\t\t72.10%\n",
      "  training accuracy:\t\t66.25%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 15 took 30.984s, currently going to do 31\n",
      "  training loss: 1.367054, validation loss: 0.785722\n",
      "  validation accuracy:\t\t72.78%\n",
      "  training accuracy:\t\t67.31%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 16 took 31.094s, currently going to do 33\n",
      "  training loss: 1.350115, validation loss: 0.736209\n",
      "  validation accuracy:\t\t75.38%\n",
      "  training accuracy:\t\t67.63%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 17 took 31.208s, currently going to do 35\n",
      "  training loss: 1.330535, validation loss: 0.732107\n",
      "  validation accuracy:\t\t75.66%\n",
      "  training accuracy:\t\t68.36%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 18 took 29.726s, currently going to do 35\n",
      "  training loss: 1.312027, validation loss: 0.724481\n",
      "  validation accuracy:\t\t74.94%\n",
      "  training accuracy:\t\t69.11%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 19 took 29.722s, currently going to do 35\n",
      "  training loss: 1.293800, validation loss: 0.753588\n",
      "  validation accuracy:\t\t74.05%\n",
      "  training accuracy:\t\t69.45%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 20 took 31.093s, currently going to do 41\n",
      "  training loss: 1.274107, validation loss: 0.691692\n",
      "  validation accuracy:\t\t76.94%\n",
      "  training accuracy:\t\t70.18%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 21 took 29.735s, currently going to do 41\n",
      "  training loss: 1.264033, validation loss: 0.690635\n",
      "  validation accuracy:\t\t76.76%\n",
      "  training accuracy:\t\t70.46%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 22 took 31.056s, currently going to do 45\n",
      "  training loss: 1.243708, validation loss: 0.674606\n",
      "  validation accuracy:\t\t77.34%\n",
      "  training accuracy:\t\t70.74%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 23 took 29.728s, currently going to do 45\n",
      "  training loss: 1.233874, validation loss: 0.687938\n",
      "  validation accuracy:\t\t76.68%\n",
      "  training accuracy:\t\t71.07%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 24 took 29.724s, currently going to do 45\n",
      "  training loss: 1.227748, validation loss: 0.728083\n",
      "  validation accuracy:\t\t75.12%\n",
      "  training accuracy:\t\t71.55%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 25 took 29.722s, currently going to do 45\n",
      "  training loss: 1.209508, validation loss: 0.671034\n",
      "  validation accuracy:\t\t77.14%\n",
      "  training accuracy:\t\t72.07%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 26 took 29.724s, currently going to do 45\n",
      "  training loss: 1.200023, validation loss: 0.688726\n",
      "  validation accuracy:\t\t77.27%\n",
      "  training accuracy:\t\t72.08%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 27 took 31.706s, currently going to do 55\n",
      "  training loss: 1.191069, validation loss: 0.663959\n",
      "  validation accuracy:\t\t77.55%\n",
      "  training accuracy:\t\t72.40%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 28 took 31.138s, currently going to do 57\n",
      "  training loss: 1.185866, validation loss: 0.642541\n",
      "  validation accuracy:\t\t78.24%\n",
      "  training accuracy:\t\t72.64%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 29 took 29.727s, currently going to do 57\n",
      "  training loss: 1.177880, validation loss: 0.665185\n",
      "  validation accuracy:\t\t77.44%\n",
      "  training accuracy:\t\t72.54%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 30 took 30.839s, currently going to do 61\n",
      "  training loss: 1.164332, validation loss: 0.632705\n",
      "  validation accuracy:\t\t78.38%\n",
      "  training accuracy:\t\t73.20%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 31 took 29.731s, currently going to do 61\n",
      "  training loss: 1.156255, validation loss: 0.636127\n",
      "  validation accuracy:\t\t78.07%\n",
      "  training accuracy:\t\t73.57%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 32 took 29.732s, currently going to do 61\n",
      "  training loss: 1.151718, validation loss: 0.648078\n",
      "  validation accuracy:\t\t78.18%\n",
      "  training accuracy:\t\t73.72%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 33 took 31.021s, currently going to do 67\n",
      "  training loss: 1.136271, validation loss: 0.630079\n",
      "  validation accuracy:\t\t78.68%\n",
      "  training accuracy:\t\t74.06%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 34 took 29.734s, currently going to do 67\n",
      "  training loss: 1.125698, validation loss: 0.647534\n",
      "  validation accuracy:\t\t78.00%\n",
      "  training accuracy:\t\t74.33%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 35 took 30.988s, currently going to do 71\n",
      "  training loss: 1.124881, validation loss: 0.602959\n",
      "  validation accuracy:\t\t79.56%\n",
      "  training accuracy:\t\t74.46%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 36 took 29.729s, currently going to do 71\n",
      "  training loss: 1.120133, validation loss: 0.610865\n",
      "  validation accuracy:\t\t79.51%\n",
      "  training accuracy:\t\t74.58%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 37 took 30.876s, currently going to do 75\n",
      "  training loss: 1.113863, validation loss: 0.598717\n",
      "  validation accuracy:\t\t80.00%\n",
      "  training accuracy:\t\t74.61%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 38 took 29.733s, currently going to do 75\n",
      "  training loss: 1.108990, validation loss: 0.605174\n",
      "  validation accuracy:\t\t79.71%\n",
      "  training accuracy:\t\t74.82%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 39 took 29.725s, currently going to do 75\n",
      "  training loss: 1.096969, validation loss: 0.630146\n",
      "  validation accuracy:\t\t78.30%\n",
      "  training accuracy:\t\t75.08%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 40 took 29.726s, currently going to do 75\n",
      "  training loss: 1.094140, validation loss: 0.597692\n",
      "  validation accuracy:\t\t79.43%\n",
      "  training accuracy:\t\t75.25%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 41 took 29.728s, currently going to do 75\n",
      "  training loss: 1.090161, validation loss: 0.586584\n",
      "  validation accuracy:\t\t79.92%\n",
      "  training accuracy:\t\t75.47%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 42 took 29.728s, currently going to do 75\n",
      "  training loss: 1.083705, validation loss: 0.594691\n",
      "  validation accuracy:\t\t79.90%\n",
      "  training accuracy:\t\t75.74%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 43 took 29.727s, currently going to do 75\n",
      "  training loss: 1.073364, validation loss: 0.608995\n",
      "  validation accuracy:\t\t79.25%\n",
      "  training accuracy:\t\t75.91%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 44 took 30.881s, currently going to do 89\n",
      "  training loss: 1.075307, validation loss: 0.577770\n",
      "  validation accuracy:\t\t80.48%\n",
      "  training accuracy:\t\t75.94%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 45 took 31.267s, currently going to do 91\n",
      "  training loss: 1.071399, validation loss: 0.577446\n",
      "  validation accuracy:\t\t80.63%\n",
      "  training accuracy:\t\t76.26%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 46 took 29.731s, currently going to do 91\n",
      "  training loss: 1.063322, validation loss: 0.595213\n",
      "  validation accuracy:\t\t79.79%\n",
      "  training accuracy:\t\t76.21%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 47 took 29.726s, currently going to do 91\n",
      "  training loss: 1.059130, validation loss: 0.578188\n",
      "  validation accuracy:\t\t80.54%\n",
      "  training accuracy:\t\t76.43%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 48 took 29.728s, currently going to do 91\n",
      "  training loss: 1.063810, validation loss: 0.638196\n",
      "  validation accuracy:\t\t78.80%\n",
      "  training accuracy:\t\t76.22%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 49 took 29.725s, currently going to do 91\n",
      "  training loss: 1.052167, validation loss: 0.577618\n",
      "  validation accuracy:\t\t80.19%\n",
      "  training accuracy:\t\t76.52%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 50 took 29.725s, currently going to do 91\n",
      "  training loss: 1.044634, validation loss: 0.576971\n",
      "  validation accuracy:\t\t80.53%\n",
      "  training accuracy:\t\t76.83%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 51 took 29.727s, currently going to do 91\n",
      "  training loss: 1.042370, validation loss: 0.579623\n",
      "  validation accuracy:\t\t80.11%\n",
      "  training accuracy:\t\t76.99%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 52 took 30.861s, currently going to do 105\n",
      "  training loss: 1.044501, validation loss: 0.572310\n",
      "  validation accuracy:\t\t80.85%\n",
      "  training accuracy:\t\t76.72%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 53 took 29.719s, currently going to do 105\n",
      "  training loss: 1.038269, validation loss: 0.570970\n",
      "  validation accuracy:\t\t80.80%\n",
      "  training accuracy:\t\t77.09%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 54 took 30.843s, currently going to do 109\n",
      "  training loss: 1.040592, validation loss: 0.560659\n",
      "  validation accuracy:\t\t80.87%\n",
      "  training accuracy:\t\t76.97%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 55 took 29.734s, currently going to do 109\n",
      "  training loss: 1.027467, validation loss: 0.581865\n",
      "  validation accuracy:\t\t80.00%\n",
      "  training accuracy:\t\t77.38%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 56 took 29.723s, currently going to do 109\n",
      "  training loss: 1.025941, validation loss: 0.565218\n",
      "  validation accuracy:\t\t80.80%\n",
      "  training accuracy:\t\t77.46%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 57 took 29.725s, currently going to do 109\n",
      "  training loss: 1.026505, validation loss: 0.579873\n",
      "  validation accuracy:\t\t80.27%\n",
      "  training accuracy:\t\t77.40%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 58 took 30.864s, currently going to do 117\n",
      "  training loss: 1.021895, validation loss: 0.551758\n",
      "  validation accuracy:\t\t81.19%\n",
      "  training accuracy:\t\t77.33%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 59 took 29.722s, currently going to do 117\n",
      "  training loss: 1.019842, validation loss: 0.568064\n",
      "  validation accuracy:\t\t80.76%\n",
      "  training accuracy:\t\t77.71%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 60 took 29.717s, currently going to do 117\n",
      "  training loss: 1.019046, validation loss: 0.566751\n",
      "  validation accuracy:\t\t80.70%\n",
      "  training accuracy:\t\t77.75%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 61 took 29.715s, currently going to do 117\n",
      "  training loss: 1.013001, validation loss: 0.580349\n",
      "  validation accuracy:\t\t80.55%\n",
      "  training accuracy:\t\t77.64%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 62 took 29.718s, currently going to do 117\n",
      "  training loss: 1.004295, validation loss: 0.564425\n",
      "  validation accuracy:\t\t81.13%\n",
      "  training accuracy:\t\t78.14%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 63 took 29.715s, currently going to do 117\n",
      "  training loss: 1.007430, validation loss: 0.566323\n",
      "  validation accuracy:\t\t80.69%\n",
      "  training accuracy:\t\t77.94%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 64 took 29.717s, currently going to do 117\n",
      "  training loss: 1.009323, validation loss: 0.571684\n",
      "  validation accuracy:\t\t80.93%\n",
      "  training accuracy:\t\t77.96%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 65 took 30.866s, currently going to do 131\n",
      "  training loss: 1.003010, validation loss: 0.546207\n",
      "  validation accuracy:\t\t81.63%\n",
      "  training accuracy:\t\t78.21%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 66 took 29.735s, currently going to do 131\n",
      "  training loss: 0.997672, validation loss: 0.562459\n",
      "  validation accuracy:\t\t81.04%\n",
      "  training accuracy:\t\t78.17%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 67 took 29.725s, currently going to do 131\n",
      "  training loss: 0.995877, validation loss: 0.554328\n",
      "  validation accuracy:\t\t81.17%\n",
      "  training accuracy:\t\t78.27%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 68 took 29.728s, currently going to do 131\n",
      "  training loss: 0.990460, validation loss: 0.552616\n",
      "  validation accuracy:\t\t81.39%\n",
      "  training accuracy:\t\t78.44%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 69 took 31.478s, currently going to do 139\n",
      "  training loss: 0.994004, validation loss: 0.537036\n",
      "  validation accuracy:\t\t81.94%\n",
      "  training accuracy:\t\t78.37%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 70 took 29.725s, currently going to do 139\n",
      "  training loss: 0.988094, validation loss: 0.533798\n",
      "  validation accuracy:\t\t81.87%\n",
      "  training accuracy:\t\t78.49%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 71 took 29.717s, currently going to do 139\n",
      "  training loss: 0.990014, validation loss: 0.537029\n",
      "  validation accuracy:\t\t81.72%\n",
      "  training accuracy:\t\t78.62%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 72 took 29.718s, currently going to do 139\n",
      "  training loss: 0.985171, validation loss: 0.529856\n",
      "  validation accuracy:\t\t81.92%\n",
      "  training accuracy:\t\t78.64%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 73 took 29.713s, currently going to do 139\n",
      "  training loss: 0.979361, validation loss: 0.545467\n",
      "  validation accuracy:\t\t81.60%\n",
      "  training accuracy:\t\t78.90%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 74 took 29.730s, currently going to do 139\n",
      "  training loss: 0.982252, validation loss: 0.537323\n",
      "  validation accuracy:\t\t81.72%\n",
      "  training accuracy:\t\t78.69%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 75 took 30.873s, currently going to do 151\n",
      "  training loss: 0.980430, validation loss: 0.534605\n",
      "  validation accuracy:\t\t82.07%\n",
      "  training accuracy:\t\t78.70%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 76 took 29.731s, currently going to do 151\n",
      "  training loss: 0.973162, validation loss: 0.554708\n",
      "  validation accuracy:\t\t81.18%\n",
      "  training accuracy:\t\t78.93%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 77 took 29.722s, currently going to do 151\n",
      "  training loss: 0.973687, validation loss: 0.546916\n",
      "  validation accuracy:\t\t81.46%\n",
      "  training accuracy:\t\t78.97%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 78 took 30.897s, currently going to do 157\n",
      "  training loss: 0.965172, validation loss: 0.525426\n",
      "  validation accuracy:\t\t82.17%\n",
      "  training accuracy:\t\t79.30%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 79 took 29.726s, currently going to do 157\n",
      "  training loss: 0.968025, validation loss: 0.529136\n",
      "  validation accuracy:\t\t81.99%\n",
      "  training accuracy:\t\t79.35%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 80 took 29.727s, currently going to do 157\n",
      "  training loss: 0.961902, validation loss: 0.530347\n",
      "  validation accuracy:\t\t82.09%\n",
      "  training accuracy:\t\t79.29%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 81 took 29.720s, currently going to do 157\n",
      "  training loss: 0.956921, validation loss: 0.543039\n",
      "  validation accuracy:\t\t81.36%\n",
      "  training accuracy:\t\t79.52%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 82 took 29.845s, currently going to do 157\n",
      "  training loss: 0.960321, validation loss: 0.537912\n",
      "  validation accuracy:\t\t81.69%\n",
      "  training accuracy:\t\t79.39%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 83 took 29.712s, currently going to do 157\n",
      "  training loss: 0.968029, validation loss: 0.539331\n",
      "  validation accuracy:\t\t81.80%\n",
      "  training accuracy:\t\t79.10%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 84 took 29.720s, currently going to do 157\n",
      "  training loss: 0.960462, validation loss: 0.536769\n",
      "  validation accuracy:\t\t81.99%\n",
      "  training accuracy:\t\t79.41%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 85 took 29.733s, currently going to do 157\n",
      "  training loss: 0.956395, validation loss: 0.529397\n",
      "  validation accuracy:\t\t82.14%\n",
      "  training accuracy:\t\t79.44%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 86 took 30.823s, currently going to do 173\n",
      "  training loss: 0.956631, validation loss: 0.522928\n",
      "  validation accuracy:\t\t82.69%\n",
      "  training accuracy:\t\t79.50%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 87 took 29.763s, currently going to do 173\n",
      "  training loss: 0.952187, validation loss: 0.549505\n",
      "  validation accuracy:\t\t81.64%\n",
      "  training accuracy:\t\t79.68%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 88 took 29.743s, currently going to do 173\n",
      "  training loss: 0.949554, validation loss: 0.541569\n",
      "  validation accuracy:\t\t81.81%\n",
      "  training accuracy:\t\t79.81%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 89 took 29.729s, currently going to do 173\n",
      "  training loss: 0.952245, validation loss: 0.523373\n",
      "  validation accuracy:\t\t82.27%\n",
      "  training accuracy:\t\t79.77%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 90 took 29.729s, currently going to do 173\n",
      "  training loss: 0.948780, validation loss: 0.536913\n",
      "  validation accuracy:\t\t81.90%\n",
      "  training accuracy:\t\t79.80%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 91 took 30.829s, currently going to do 183\n",
      "  training loss: 0.945157, validation loss: 0.515369\n",
      "  validation accuracy:\t\t82.71%\n",
      "  training accuracy:\t\t80.01%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 92 took 29.721s, currently going to do 183\n",
      "  training loss: 0.948068, validation loss: 0.519709\n",
      "  validation accuracy:\t\t82.63%\n",
      "  training accuracy:\t\t79.70%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 93 took 29.716s, currently going to do 183\n",
      "  training loss: 0.939388, validation loss: 0.516622\n",
      "  validation accuracy:\t\t82.45%\n",
      "  training accuracy:\t\t80.23%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 94 took 29.717s, currently going to do 183\n",
      "  training loss: 0.939900, validation loss: 0.519859\n",
      "  validation accuracy:\t\t82.56%\n",
      "  training accuracy:\t\t80.37%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 95 took 29.727s, currently going to do 183\n",
      "  training loss: 0.937650, validation loss: 0.538711\n",
      "  validation accuracy:\t\t81.82%\n",
      "  training accuracy:\t\t80.23%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 96 took 29.714s, currently going to do 183\n",
      "  training loss: 0.935051, validation loss: 0.531559\n",
      "  validation accuracy:\t\t82.31%\n",
      "  training accuracy:\t\t80.18%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 97 took 29.716s, currently going to do 183\n",
      "  training loss: 0.936860, validation loss: 0.516574\n",
      "  validation accuracy:\t\t82.40%\n",
      "  training accuracy:\t\t80.24%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 98 took 31.211s, currently going to do 197\n",
      "  training loss: 0.935094, validation loss: 0.508256\n",
      "  validation accuracy:\t\t83.29%\n",
      "  training accuracy:\t\t80.32%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 99 took 29.735s, currently going to do 197\n",
      "  training loss: 0.933061, validation loss: 0.512367\n",
      "  validation accuracy:\t\t82.81%\n",
      "  training accuracy:\t\t80.36%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 100 took 29.734s, currently going to do 197\n",
      "  training loss: 0.935554, validation loss: 0.505045\n",
      "  validation accuracy:\t\t82.92%\n",
      "  training accuracy:\t\t80.27%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 101 took 29.732s, currently going to do 197\n",
      "  training loss: 0.929308, validation loss: 0.523791\n",
      "  validation accuracy:\t\t82.49%\n",
      "  training accuracy:\t\t80.53%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 102 took 29.731s, currently going to do 197\n",
      "  training loss: 0.936317, validation loss: 0.519245\n",
      "  validation accuracy:\t\t82.48%\n",
      "  training accuracy:\t\t80.26%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 103 took 29.736s, currently going to do 197\n",
      "  training loss: 0.928290, validation loss: 0.512427\n",
      "  validation accuracy:\t\t82.93%\n",
      "  training accuracy:\t\t80.48%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 104 took 29.734s, currently going to do 197\n",
      "  training loss: 0.924259, validation loss: 0.518545\n",
      "  validation accuracy:\t\t82.46%\n",
      "  training accuracy:\t\t80.55%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 105 took 29.735s, currently going to do 197\n",
      "  training loss: 0.921140, validation loss: 0.508112\n",
      "  validation accuracy:\t\t82.79%\n",
      "  training accuracy:\t\t80.59%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 106 took 29.736s, currently going to do 197\n",
      "  training loss: 0.925171, validation loss: 0.501248\n",
      "  validation accuracy:\t\t83.13%\n",
      "  training accuracy:\t\t80.43%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 107 took 29.731s, currently going to do 197\n",
      "  training loss: 0.917165, validation loss: 0.520657\n",
      "  validation accuracy:\t\t82.57%\n",
      "  training accuracy:\t\t80.73%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 108 took 29.743s, currently going to do 197\n",
      "  training loss: 0.924660, validation loss: 0.506722\n",
      "  validation accuracy:\t\t83.04%\n",
      "  training accuracy:\t\t80.36%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 109 took 29.744s, currently going to do 197\n",
      "  training loss: 0.919500, validation loss: 0.506272\n",
      "  validation accuracy:\t\t83.20%\n",
      "  training accuracy:\t\t80.81%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 110 took 32.348s, currently going to do 221\n",
      "  training loss: 0.916100, validation loss: 0.499802\n",
      "  validation accuracy:\t\t83.34%\n",
      "  training accuracy:\t\t80.93%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 111 took 29.762s, currently going to do 221\n",
      "  training loss: 0.916783, validation loss: 0.502429\n",
      "  validation accuracy:\t\t83.07%\n",
      "  training accuracy:\t\t80.72%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 112 took 29.735s, currently going to do 221\n",
      "  training loss: 0.918818, validation loss: 0.520674\n",
      "  validation accuracy:\t\t82.37%\n",
      "  training accuracy:\t\t80.83%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 113 took 29.740s, currently going to do 221\n",
      "  training loss: 0.911785, validation loss: 0.507517\n",
      "  validation accuracy:\t\t83.24%\n",
      "  training accuracy:\t\t80.90%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 114 took 29.737s, currently going to do 221\n",
      "  training loss: 0.911209, validation loss: 0.516575\n",
      "  validation accuracy:\t\t82.54%\n",
      "  training accuracy:\t\t81.09%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 115 took 29.744s, currently going to do 221\n",
      "  training loss: 0.908267, validation loss: 0.507737\n",
      "  validation accuracy:\t\t82.84%\n",
      "  training accuracy:\t\t81.21%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 116 took 29.735s, currently going to do 221\n",
      "  training loss: 0.912000, validation loss: 0.497108\n",
      "  validation accuracy:\t\t83.11%\n",
      "  training accuracy:\t\t80.87%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 117 took 29.736s, currently going to do 221\n",
      "  training loss: 0.902597, validation loss: 0.516044\n",
      "  validation accuracy:\t\t82.46%\n",
      "  training accuracy:\t\t81.24%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 118 took 29.735s, currently going to do 221\n",
      "  training loss: 0.911746, validation loss: 0.541388\n",
      "  validation accuracy:\t\t81.57%\n",
      "  training accuracy:\t\t80.93%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 119 took 29.745s, currently going to do 221\n",
      "  training loss: 0.905419, validation loss: 0.499884\n",
      "  validation accuracy:\t\t83.07%\n",
      "  training accuracy:\t\t81.26%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 120 took 29.736s, currently going to do 221\n",
      "  training loss: 0.911244, validation loss: 0.507211\n",
      "  validation accuracy:\t\t82.81%\n",
      "  training accuracy:\t\t81.17%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 121 took 29.751s, currently going to do 221\n",
      "  training loss: 0.903391, validation loss: 0.510284\n",
      "  validation accuracy:\t\t82.54%\n",
      "  training accuracy:\t\t81.36%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 122 took 29.738s, currently going to do 221\n",
      "  training loss: 0.903122, validation loss: 0.506833\n",
      "  validation accuracy:\t\t82.68%\n",
      "  training accuracy:\t\t81.28%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 123 took 29.735s, currently going to do 221\n",
      "  training loss: 0.898366, validation loss: 0.508651\n",
      "  validation accuracy:\t\t82.58%\n",
      "  training accuracy:\t\t81.43%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 124 took 31.178s, currently going to do 249\n",
      "  training loss: 0.896108, validation loss: 0.487603\n",
      "  validation accuracy:\t\t83.85%\n",
      "  training accuracy:\t\t81.53%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 125 took 29.750s, currently going to do 249\n",
      "  training loss: 0.895748, validation loss: 0.489609\n",
      "  validation accuracy:\t\t83.33%\n",
      "  training accuracy:\t\t81.35%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 126 took 29.744s, currently going to do 249\n",
      "  training loss: 0.897373, validation loss: 0.502211\n",
      "  validation accuracy:\t\t82.84%\n",
      "  training accuracy:\t\t81.42%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 127 took 29.743s, currently going to do 249\n",
      "  training loss: 0.893134, validation loss: 0.490736\n",
      "  validation accuracy:\t\t83.44%\n",
      "  training accuracy:\t\t81.57%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 128 took 29.781s, currently going to do 249\n",
      "  training loss: 0.897696, validation loss: 0.501971\n",
      "  validation accuracy:\t\t82.92%\n",
      "  training accuracy:\t\t81.45%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 129 took 29.758s, currently going to do 249\n",
      "  training loss: 0.896309, validation loss: 0.506048\n",
      "  validation accuracy:\t\t82.85%\n",
      "  training accuracy:\t\t81.57%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 130 took 29.838s, currently going to do 249\n",
      "  training loss: 0.889313, validation loss: 0.495231\n",
      "  validation accuracy:\t\t83.30%\n",
      "  training accuracy:\t\t81.84%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 131 took 29.738s, currently going to do 249\n",
      "  training loss: 0.893185, validation loss: 0.498296\n",
      "  validation accuracy:\t\t83.17%\n",
      "  training accuracy:\t\t81.63%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 132 took 29.747s, currently going to do 249\n",
      "  training loss: 0.892105, validation loss: 0.505259\n",
      "  validation accuracy:\t\t83.05%\n",
      "  training accuracy:\t\t81.71%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 133 took 29.741s, currently going to do 249\n",
      "  training loss: 0.893606, validation loss: 0.486118\n",
      "  validation accuracy:\t\t83.61%\n",
      "  training accuracy:\t\t81.58%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 134 took 29.742s, currently going to do 249\n",
      "  training loss: 0.889223, validation loss: 0.495380\n",
      "  validation accuracy:\t\t83.23%\n",
      "  training accuracy:\t\t81.62%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 135 took 29.743s, currently going to do 249\n",
      "  training loss: 0.892043, validation loss: 0.499664\n",
      "  validation accuracy:\t\t82.94%\n",
      "  training accuracy:\t\t81.54%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 136 took 29.797s, currently going to do 249\n",
      "  training loss: 0.896586, validation loss: 0.494533\n",
      "  validation accuracy:\t\t83.64%\n",
      "  training accuracy:\t\t81.47%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 137 took 29.840s, currently going to do 249\n",
      "  training loss: 0.884152, validation loss: 0.497513\n",
      "  validation accuracy:\t\t83.14%\n",
      "  training accuracy:\t\t81.81%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 138 took 29.740s, currently going to do 249\n",
      "  training loss: 0.887324, validation loss: 0.500618\n",
      "  validation accuracy:\t\t83.43%\n",
      "  training accuracy:\t\t81.67%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 139 took 29.839s, currently going to do 249\n",
      "  training loss: 0.877518, validation loss: 0.501639\n",
      "  validation accuracy:\t\t82.96%\n",
      "  training accuracy:\t\t82.21%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 140 took 29.745s, currently going to do 249\n",
      "  training loss: 0.880224, validation loss: 0.502913\n",
      "  validation accuracy:\t\t83.28%\n",
      "  training accuracy:\t\t81.89%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 141 took 29.749s, currently going to do 249\n",
      "  training loss: 0.887040, validation loss: 0.496296\n",
      "  validation accuracy:\t\t83.48%\n",
      "  training accuracy:\t\t81.64%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 142 took 29.758s, currently going to do 249\n",
      "  training loss: 0.885541, validation loss: 0.504807\n",
      "  validation accuracy:\t\t83.12%\n",
      "  training accuracy:\t\t81.75%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 143 took 29.792s, currently going to do 249\n",
      "  training loss: 0.882225, validation loss: 0.501100\n",
      "  validation accuracy:\t\t82.84%\n",
      "  training accuracy:\t\t81.82%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 144 took 29.759s, currently going to do 249\n",
      "  training loss: 0.883963, validation loss: 0.486687\n",
      "  validation accuracy:\t\t83.75%\n",
      "  training accuracy:\t\t81.83%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 145 took 29.848s, currently going to do 249\n",
      "  training loss: 0.876750, validation loss: 0.513324\n",
      "  validation accuracy:\t\t82.43%\n",
      "  training accuracy:\t\t81.99%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 146 took 29.750s, currently going to do 249\n",
      "  training loss: 0.881467, validation loss: 0.507653\n",
      "  validation accuracy:\t\t82.78%\n",
      "  training accuracy:\t\t82.01%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 147 took 29.771s, currently going to do 249\n",
      "  training loss: 0.876307, validation loss: 0.486983\n",
      "  validation accuracy:\t\t83.68%\n",
      "  training accuracy:\t\t82.10%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 148 took 29.739s, currently going to do 249\n",
      "  training loss: 0.878040, validation loss: 0.490225\n",
      "  validation accuracy:\t\t83.59%\n",
      "  training accuracy:\t\t82.12%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 149 took 29.738s, currently going to do 249\n",
      "  training loss: 0.881367, validation loss: 0.511288\n",
      "  validation accuracy:\t\t82.80%\n",
      "  training accuracy:\t\t81.89%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 150 took 29.741s, currently going to do 249\n",
      "  training loss: 0.873214, validation loss: 0.510657\n",
      "  validation accuracy:\t\t82.69%\n",
      "  training accuracy:\t\t82.20%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 151 took 29.741s, currently going to do 249\n",
      "  training loss: 0.875685, validation loss: 0.493052\n",
      "  validation accuracy:\t\t83.59%\n",
      "  training accuracy:\t\t82.43%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 152 took 29.743s, currently going to do 249\n",
      "  training loss: 0.871365, validation loss: 0.493770\n",
      "  validation accuracy:\t\t83.15%\n",
      "  training accuracy:\t\t82.10%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 153 took 29.739s, currently going to do 249\n",
      "  training loss: 0.871760, validation loss: 0.500839\n",
      "  validation accuracy:\t\t82.93%\n",
      "  training accuracy:\t\t82.41%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 154 took 29.744s, currently going to do 249\n",
      "  training loss: 0.868765, validation loss: 0.491861\n",
      "  validation accuracy:\t\t83.47%\n",
      "  training accuracy:\t\t82.38%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 155 took 29.756s, currently going to do 249\n",
      "  training loss: 0.876421, validation loss: 0.487326\n",
      "  validation accuracy:\t\t83.53%\n",
      "  training accuracy:\t\t82.07%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 156 took 29.752s, currently going to do 249\n",
      "  training loss: 0.868918, validation loss: 0.495910\n",
      "  validation accuracy:\t\t83.17%\n",
      "  training accuracy:\t\t82.31%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 157 took 31.201s, currently going to do 315\n",
      "  training loss: 0.871375, validation loss: 0.479061\n",
      "  validation accuracy:\t\t84.05%\n",
      "  training accuracy:\t\t82.26%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 158 took 29.744s, currently going to do 315\n",
      "  training loss: 0.870465, validation loss: 0.497070\n",
      "  validation accuracy:\t\t83.28%\n",
      "  training accuracy:\t\t82.24%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 159 took 29.748s, currently going to do 315\n",
      "  training loss: 0.869920, validation loss: 0.488725\n",
      "  validation accuracy:\t\t83.50%\n",
      "  training accuracy:\t\t82.28%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 160 took 29.745s, currently going to do 315\n",
      "  training loss: 0.867634, validation loss: 0.496701\n",
      "  validation accuracy:\t\t83.23%\n",
      "  training accuracy:\t\t82.41%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 161 took 29.743s, currently going to do 315\n",
      "  training loss: 0.864590, validation loss: 0.485675\n",
      "  validation accuracy:\t\t83.60%\n",
      "  training accuracy:\t\t82.26%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 162 took 29.742s, currently going to do 315\n",
      "  training loss: 0.869737, validation loss: 0.488843\n",
      "  validation accuracy:\t\t83.65%\n",
      "  training accuracy:\t\t82.37%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 163 took 29.740s, currently going to do 315\n",
      "  training loss: 0.866309, validation loss: 0.500257\n",
      "  validation accuracy:\t\t83.06%\n",
      "  training accuracy:\t\t82.37%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 164 took 29.741s, currently going to do 315\n",
      "  training loss: 0.867781, validation loss: 0.495061\n",
      "  validation accuracy:\t\t83.66%\n",
      "  training accuracy:\t\t82.69%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 165 took 29.741s, currently going to do 315\n",
      "  training loss: 0.866070, validation loss: 0.491199\n",
      "  validation accuracy:\t\t83.38%\n",
      "  training accuracy:\t\t82.65%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 166 took 29.740s, currently going to do 315\n",
      "  training loss: 0.862020, validation loss: 0.478260\n",
      "  validation accuracy:\t\t83.87%\n",
      "  training accuracy:\t\t82.65%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 167 took 29.746s, currently going to do 315\n",
      "  training loss: 0.860990, validation loss: 0.489724\n",
      "  validation accuracy:\t\t83.52%\n",
      "  training accuracy:\t\t82.58%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 168 took 30.819s, currently going to do 337\n",
      "  training loss: 0.862588, validation loss: 0.478126\n",
      "  validation accuracy:\t\t84.13%\n",
      "  training accuracy:\t\t82.67%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 169 took 29.752s, currently going to do 337\n",
      "  training loss: 0.855796, validation loss: 0.516851\n",
      "  validation accuracy:\t\t82.12%\n",
      "  training accuracy:\t\t82.82%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 170 took 29.747s, currently going to do 337\n",
      "  training loss: 0.859512, validation loss: 0.490286\n",
      "  validation accuracy:\t\t83.46%\n",
      "  training accuracy:\t\t82.81%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 171 took 29.744s, currently going to do 337\n",
      "  training loss: 0.861091, validation loss: 0.484259\n",
      "  validation accuracy:\t\t83.47%\n",
      "  training accuracy:\t\t82.66%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 172 took 32.281s, currently going to do 345\n",
      "  training loss: 0.858772, validation loss: 0.479515\n",
      "  validation accuracy:\t\t84.14%\n",
      "  training accuracy:\t\t83.02%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 173 took 29.742s, currently going to do 345\n",
      "  training loss: 0.858453, validation loss: 0.480754\n",
      "  validation accuracy:\t\t83.65%\n",
      "  training accuracy:\t\t82.56%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 174 took 29.738s, currently going to do 345\n",
      "  training loss: 0.857902, validation loss: 0.498890\n",
      "  validation accuracy:\t\t82.95%\n",
      "  training accuracy:\t\t82.64%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 175 took 29.735s, currently going to do 345\n",
      "  training loss: 0.856640, validation loss: 0.478993\n",
      "  validation accuracy:\t\t83.96%\n",
      "  training accuracy:\t\t82.81%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 176 took 29.734s, currently going to do 345\n",
      "  training loss: 0.855285, validation loss: 0.492642\n",
      "  validation accuracy:\t\t83.41%\n",
      "  training accuracy:\t\t82.86%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 177 took 29.735s, currently going to do 345\n",
      "  training loss: 0.851507, validation loss: 0.487123\n",
      "  validation accuracy:\t\t83.55%\n",
      "  training accuracy:\t\t83.09%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 178 took 29.737s, currently going to do 345\n",
      "  training loss: 0.859174, validation loss: 0.490659\n",
      "  validation accuracy:\t\t83.71%\n",
      "  training accuracy:\t\t82.67%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 179 took 31.537s, currently going to do 359\n",
      "  training loss: 0.857794, validation loss: 0.480794\n",
      "  validation accuracy:\t\t84.25%\n",
      "  training accuracy:\t\t82.71%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 180 took 29.754s, currently going to do 359\n",
      "  training loss: 0.859162, validation loss: 0.472185\n",
      "  validation accuracy:\t\t84.19%\n",
      "  training accuracy:\t\t82.78%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 181 took 29.747s, currently going to do 359\n",
      "  training loss: 0.857057, validation loss: 0.489151\n",
      "  validation accuracy:\t\t83.66%\n",
      "  training accuracy:\t\t82.86%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 182 took 29.747s, currently going to do 359\n",
      "  training loss: 0.851238, validation loss: 0.486473\n",
      "  validation accuracy:\t\t83.82%\n",
      "  training accuracy:\t\t82.95%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 183 took 29.750s, currently going to do 359\n",
      "  training loss: 0.851801, validation loss: 0.491371\n",
      "  validation accuracy:\t\t83.32%\n",
      "  training accuracy:\t\t82.92%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 184 took 29.746s, currently going to do 359\n",
      "  training loss: 0.860912, validation loss: 0.485721\n",
      "  validation accuracy:\t\t83.86%\n",
      "  training accuracy:\t\t82.72%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 185 took 29.747s, currently going to do 359\n",
      "  training loss: 0.850572, validation loss: 0.484810\n",
      "  validation accuracy:\t\t83.97%\n",
      "  training accuracy:\t\t82.98%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 186 took 29.744s, currently going to do 359\n",
      "  training loss: 0.848806, validation loss: 0.491599\n",
      "  validation accuracy:\t\t83.50%\n",
      "  training accuracy:\t\t83.07%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 187 took 29.747s, currently going to do 359\n",
      "  training loss: 0.850247, validation loss: 0.476606\n",
      "  validation accuracy:\t\t83.88%\n",
      "  training accuracy:\t\t83.09%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 188 took 29.748s, currently going to do 359\n",
      "  training loss: 0.842649, validation loss: 0.474429\n",
      "  validation accuracy:\t\t84.22%\n",
      "  training accuracy:\t\t83.06%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 189 took 29.748s, currently going to do 359\n",
      "  training loss: 0.847685, validation loss: 0.482200\n",
      "  validation accuracy:\t\t83.89%\n",
      "  training accuracy:\t\t83.39%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 190 took 29.748s, currently going to do 359\n",
      "  training loss: 0.848881, validation loss: 0.479062\n",
      "  validation accuracy:\t\t83.81%\n",
      "  training accuracy:\t\t83.38%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 191 took 29.749s, currently going to do 359\n",
      "  training loss: 0.847234, validation loss: 0.490548\n",
      "  validation accuracy:\t\t83.52%\n",
      "  training accuracy:\t\t83.29%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 192 took 31.065s, currently going to do 385\n",
      "  training loss: 0.851212, validation loss: 0.475267\n",
      "  validation accuracy:\t\t84.27%\n",
      "  training accuracy:\t\t82.84%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 193 took 29.735s, currently going to do 385\n",
      "  training loss: 0.847279, validation loss: 0.482334\n",
      "  validation accuracy:\t\t83.86%\n",
      "  training accuracy:\t\t83.29%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 194 took 29.734s, currently going to do 385\n",
      "  training loss: 0.845764, validation loss: 0.491965\n",
      "  validation accuracy:\t\t83.47%\n",
      "  training accuracy:\t\t83.30%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 195 took 29.731s, currently going to do 385\n",
      "  training loss: 0.847746, validation loss: 0.480683\n",
      "  validation accuracy:\t\t83.58%\n",
      "  training accuracy:\t\t82.87%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 196 took 29.733s, currently going to do 385\n",
      "  training loss: 0.839648, validation loss: 0.485846\n",
      "  validation accuracy:\t\t83.51%\n",
      "  training accuracy:\t\t83.30%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 197 took 29.732s, currently going to do 385\n",
      "  training loss: 0.847600, validation loss: 0.471303\n",
      "  validation accuracy:\t\t84.13%\n",
      "  training accuracy:\t\t83.09%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 198 took 29.732s, currently going to do 385\n",
      "  training loss: 0.836495, validation loss: 0.485587\n",
      "  validation accuracy:\t\t83.89%\n",
      "  training accuracy:\t\t83.47%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 199 took 29.732s, currently going to do 385\n",
      "  training loss: 0.838448, validation loss: 0.483731\n",
      "  validation accuracy:\t\t83.63%\n",
      "  training accuracy:\t\t83.22%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 200 took 29.734s, currently going to do 385\n",
      "  training loss: 0.834367, validation loss: 0.482901\n",
      "  validation accuracy:\t\t83.55%\n",
      "  training accuracy:\t\t83.39%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 201 took 29.733s, currently going to do 385\n",
      "  training loss: 0.842389, validation loss: 0.478154\n",
      "  validation accuracy:\t\t83.91%\n",
      "  training accuracy:\t\t83.28%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 202 took 29.732s, currently going to do 385\n",
      "  training loss: 0.836479, validation loss: 0.499445\n",
      "  validation accuracy:\t\t83.14%\n",
      "  training accuracy:\t\t83.59%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 203 took 29.731s, currently going to do 385\n",
      "  training loss: 0.841231, validation loss: 0.473525\n",
      "  validation accuracy:\t\t84.05%\n",
      "  training accuracy:\t\t83.33%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 204 took 29.730s, currently going to do 385\n",
      "  training loss: 0.834835, validation loss: 0.484311\n",
      "  validation accuracy:\t\t83.75%\n",
      "  training accuracy:\t\t83.58%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 205 took 30.878s, currently going to do 411\n",
      "  training loss: 0.839296, validation loss: 0.467712\n",
      "  validation accuracy:\t\t84.46%\n",
      "  training accuracy:\t\t83.48%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 206 took 29.743s, currently going to do 411\n",
      "  training loss: 0.836947, validation loss: 0.478486\n",
      "  validation accuracy:\t\t83.69%\n",
      "  training accuracy:\t\t83.49%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 207 took 29.740s, currently going to do 411\n",
      "  training loss: 0.842870, validation loss: 0.487571\n",
      "  validation accuracy:\t\t83.62%\n",
      "  training accuracy:\t\t83.36%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 208 took 29.740s, currently going to do 411\n",
      "  training loss: 0.833606, validation loss: 0.480825\n",
      "  validation accuracy:\t\t83.79%\n",
      "  training accuracy:\t\t83.57%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 209 took 29.740s, currently going to do 411\n",
      "  training loss: 0.840457, validation loss: 0.489347\n",
      "  validation accuracy:\t\t83.21%\n",
      "  training accuracy:\t\t83.35%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 210 took 29.740s, currently going to do 411\n",
      "  training loss: 0.832531, validation loss: 0.482905\n",
      "  validation accuracy:\t\t83.80%\n",
      "  training accuracy:\t\t83.32%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 211 took 29.740s, currently going to do 411\n",
      "  training loss: 0.840929, validation loss: 0.476425\n",
      "  validation accuracy:\t\t83.79%\n",
      "  training accuracy:\t\t83.13%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 212 took 29.736s, currently going to do 411\n",
      "  training loss: 0.835861, validation loss: 0.475254\n",
      "  validation accuracy:\t\t83.95%\n",
      "  training accuracy:\t\t83.56%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 213 took 29.740s, currently going to do 411\n",
      "  training loss: 0.835868, validation loss: 0.478993\n",
      "  validation accuracy:\t\t84.02%\n",
      "  training accuracy:\t\t83.54%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 214 took 29.738s, currently going to do 411\n",
      "  training loss: 0.837141, validation loss: 0.470025\n",
      "  validation accuracy:\t\t84.05%\n",
      "  training accuracy:\t\t83.52%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 215 took 29.739s, currently going to do 411\n",
      "  training loss: 0.837419, validation loss: 0.479743\n",
      "  validation accuracy:\t\t83.94%\n",
      "  training accuracy:\t\t83.36%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 216 took 29.738s, currently going to do 411\n",
      "  training loss: 0.834852, validation loss: 0.477215\n",
      "  validation accuracy:\t\t84.25%\n",
      "  training accuracy:\t\t83.38%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 217 took 29.741s, currently going to do 411\n",
      "  training loss: 0.832365, validation loss: 0.470453\n",
      "  validation accuracy:\t\t84.41%\n",
      "  training accuracy:\t\t83.46%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 218 took 29.742s, currently going to do 411\n",
      "  training loss: 0.834068, validation loss: 0.465771\n",
      "  validation accuracy:\t\t84.28%\n",
      "  training accuracy:\t\t83.60%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 219 took 29.737s, currently going to do 411\n",
      "  training loss: 0.843128, validation loss: 0.473836\n",
      "  validation accuracy:\t\t84.15%\n",
      "  training accuracy:\t\t83.26%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 220 took 29.738s, currently going to do 411\n",
      "  training loss: 0.827298, validation loss: 0.472646\n",
      "  validation accuracy:\t\t84.40%\n",
      "  training accuracy:\t\t83.66%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 221 took 29.737s, currently going to do 411\n",
      "  training loss: 0.831372, validation loss: 0.468653\n",
      "  validation accuracy:\t\t84.32%\n",
      "  training accuracy:\t\t83.49%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 222 took 29.738s, currently going to do 411\n",
      "  training loss: 0.821370, validation loss: 0.473217\n",
      "  validation accuracy:\t\t84.11%\n",
      "  training accuracy:\t\t84.05%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 223 took 29.736s, currently going to do 411\n",
      "  training loss: 0.822894, validation loss: 0.468365\n",
      "  validation accuracy:\t\t84.37%\n",
      "  training accuracy:\t\t83.88%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 224 took 29.744s, currently going to do 411\n",
      "  training loss: 0.833300, validation loss: 0.477157\n",
      "  validation accuracy:\t\t84.08%\n",
      "  training accuracy:\t\t83.56%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 225 took 29.735s, currently going to do 411\n",
      "  training loss: 0.830841, validation loss: 0.476021\n",
      "  validation accuracy:\t\t84.07%\n",
      "  training accuracy:\t\t83.50%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 226 took 30.817s, currently going to do 453\n",
      "  training loss: 0.831694, validation loss: 0.459817\n",
      "  validation accuracy:\t\t84.61%\n",
      "  training accuracy:\t\t83.62%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 227 took 29.741s, currently going to do 453\n",
      "  training loss: 0.828408, validation loss: 0.468320\n",
      "  validation accuracy:\t\t84.18%\n",
      "  training accuracy:\t\t83.74%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 228 took 29.737s, currently going to do 453\n",
      "  training loss: 0.831002, validation loss: 0.479846\n",
      "  validation accuracy:\t\t84.16%\n",
      "  training accuracy:\t\t83.74%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 229 took 29.735s, currently going to do 453\n",
      "  training loss: 0.826489, validation loss: 0.476371\n",
      "  validation accuracy:\t\t84.39%\n",
      "  training accuracy:\t\t83.79%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 230 took 29.733s, currently going to do 453\n",
      "  training loss: 0.824809, validation loss: 0.474319\n",
      "  validation accuracy:\t\t84.00%\n",
      "  training accuracy:\t\t83.80%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 231 took 29.733s, currently going to do 453\n",
      "  training loss: 0.834234, validation loss: 0.473450\n",
      "  validation accuracy:\t\t84.14%\n",
      "  training accuracy:\t\t83.44%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 232 took 29.733s, currently going to do 453\n",
      "  training loss: 0.830809, validation loss: 0.475012\n",
      "  validation accuracy:\t\t84.47%\n",
      "  training accuracy:\t\t83.76%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 233 took 29.735s, currently going to do 453\n",
      "  training loss: 0.824194, validation loss: 0.470808\n",
      "  validation accuracy:\t\t84.38%\n",
      "  training accuracy:\t\t83.81%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 234 took 29.736s, currently going to do 453\n",
      "  training loss: 0.821843, validation loss: 0.469599\n",
      "  validation accuracy:\t\t84.07%\n",
      "  training accuracy:\t\t83.91%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 235 took 29.733s, currently going to do 453\n",
      "  training loss: 0.825800, validation loss: 0.481932\n",
      "  validation accuracy:\t\t83.71%\n",
      "  training accuracy:\t\t83.86%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 236 took 29.732s, currently going to do 453\n",
      "  training loss: 0.825201, validation loss: 0.465590\n",
      "  validation accuracy:\t\t84.49%\n",
      "  training accuracy:\t\t83.74%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 237 took 29.732s, currently going to do 453\n",
      "  training loss: 0.823314, validation loss: 0.479715\n",
      "  validation accuracy:\t\t83.98%\n",
      "  training accuracy:\t\t83.86%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 238 took 29.730s, currently going to do 453\n",
      "  training loss: 0.818705, validation loss: 0.472611\n",
      "  validation accuracy:\t\t84.21%\n",
      "  training accuracy:\t\t84.08%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 239 took 29.732s, currently going to do 453\n",
      "  training loss: 0.817114, validation loss: 0.470995\n",
      "  validation accuracy:\t\t84.15%\n",
      "  training accuracy:\t\t83.91%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 240 took 29.733s, currently going to do 453\n",
      "  training loss: 0.824054, validation loss: 0.480841\n",
      "  validation accuracy:\t\t84.00%\n",
      "  training accuracy:\t\t83.98%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 241 took 29.733s, currently going to do 453\n",
      "  training loss: 0.822591, validation loss: 0.471698\n",
      "  validation accuracy:\t\t84.10%\n",
      "  training accuracy:\t\t83.80%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 242 took 29.735s, currently going to do 453\n",
      "  training loss: 0.819270, validation loss: 0.476691\n",
      "  validation accuracy:\t\t84.16%\n",
      "  training accuracy:\t\t83.89%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 243 took 29.732s, currently going to do 453\n",
      "  training loss: 0.825861, validation loss: 0.468017\n",
      "  validation accuracy:\t\t84.58%\n",
      "  training accuracy:\t\t83.72%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 244 took 30.890s, currently going to do 489\n",
      "  training loss: 0.817660, validation loss: 0.459721\n",
      "  validation accuracy:\t\t84.64%\n",
      "  training accuracy:\t\t84.31%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 245 took 29.742s, currently going to do 489\n",
      "  training loss: 0.822228, validation loss: 0.472453\n",
      "  validation accuracy:\t\t84.08%\n",
      "  training accuracy:\t\t83.85%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 246 took 29.740s, currently going to do 489\n",
      "  training loss: 0.819361, validation loss: 0.459390\n",
      "  validation accuracy:\t\t84.50%\n",
      "  training accuracy:\t\t84.15%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 247 took 29.739s, currently going to do 489\n",
      "  training loss: 0.819662, validation loss: 0.468528\n",
      "  validation accuracy:\t\t84.40%\n",
      "  training accuracy:\t\t84.10%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 248 took 29.737s, currently going to do 489\n",
      "  training loss: 0.819377, validation loss: 0.468019\n",
      "  validation accuracy:\t\t84.57%\n",
      "  training accuracy:\t\t84.02%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 249 took 29.738s, currently going to do 489\n",
      "  training loss: 0.809353, validation loss: 0.466957\n",
      "  validation accuracy:\t\t84.28%\n",
      "  training accuracy:\t\t84.42%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 250 took 29.739s, currently going to do 489\n",
      "  training loss: 0.820611, validation loss: 0.474530\n",
      "  validation accuracy:\t\t84.33%\n",
      "  training accuracy:\t\t84.12%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 251 took 29.738s, currently going to do 489\n",
      "  training loss: 0.820559, validation loss: 0.474895\n",
      "  validation accuracy:\t\t84.27%\n",
      "  training accuracy:\t\t83.94%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 252 took 29.739s, currently going to do 489\n",
      "  training loss: 0.815446, validation loss: 0.467207\n",
      "  validation accuracy:\t\t84.44%\n",
      "  training accuracy:\t\t84.13%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 253 took 29.739s, currently going to do 489\n",
      "  training loss: 0.814656, validation loss: 0.481734\n",
      "  validation accuracy:\t\t83.97%\n",
      "  training accuracy:\t\t84.01%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 254 took 29.741s, currently going to do 489\n",
      "  training loss: 0.823894, validation loss: 0.462951\n",
      "  validation accuracy:\t\t84.46%\n",
      "  training accuracy:\t\t83.98%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 255 took 29.742s, currently going to do 489\n",
      "  training loss: 0.817406, validation loss: 0.469960\n",
      "  validation accuracy:\t\t84.42%\n",
      "  training accuracy:\t\t84.02%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 256 took 31.786s, currently going to do 513\n",
      "  training loss: 0.813146, validation loss: 0.460483\n",
      "  validation accuracy:\t\t84.71%\n",
      "  training accuracy:\t\t84.16%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 257 took 29.764s, currently going to do 513\n",
      "  training loss: 0.812285, validation loss: 0.466770\n",
      "  validation accuracy:\t\t84.35%\n",
      "  training accuracy:\t\t84.29%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 258 took 29.740s, currently going to do 513\n",
      "  training loss: 0.813098, validation loss: 0.470696\n",
      "  validation accuracy:\t\t84.27%\n",
      "  training accuracy:\t\t84.31%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 259 took 29.754s, currently going to do 513\n",
      "  training loss: 0.817626, validation loss: 0.477805\n",
      "  validation accuracy:\t\t83.95%\n",
      "  training accuracy:\t\t84.44%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 260 took 29.743s, currently going to do 513\n",
      "  training loss: 0.816227, validation loss: 0.460458\n",
      "  validation accuracy:\t\t84.61%\n",
      "  training accuracy:\t\t84.14%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 261 took 29.752s, currently going to do 513\n",
      "  training loss: 0.817133, validation loss: 0.464166\n",
      "  validation accuracy:\t\t84.48%\n",
      "  training accuracy:\t\t84.14%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 262 took 29.745s, currently going to do 513\n",
      "  training loss: 0.812994, validation loss: 0.469649\n",
      "  validation accuracy:\t\t84.37%\n",
      "  training accuracy:\t\t84.20%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 263 took 29.755s, currently going to do 513\n",
      "  training loss: 0.814510, validation loss: 0.471337\n",
      "  validation accuracy:\t\t84.27%\n",
      "  training accuracy:\t\t84.02%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 264 took 29.741s, currently going to do 513\n",
      "  training loss: 0.813731, validation loss: 0.464458\n",
      "  validation accuracy:\t\t84.25%\n",
      "  training accuracy:\t\t84.03%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 265 took 29.753s, currently going to do 513\n",
      "  training loss: 0.813635, validation loss: 0.490261\n",
      "  validation accuracy:\t\t83.66%\n",
      "  training accuracy:\t\t84.21%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 266 took 29.744s, currently going to do 513\n",
      "  training loss: 0.814241, validation loss: 0.470620\n",
      "  validation accuracy:\t\t84.32%\n",
      "  training accuracy:\t\t84.28%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 267 took 29.755s, currently going to do 513\n",
      "  training loss: 0.810188, validation loss: 0.456698\n",
      "  validation accuracy:\t\t84.63%\n",
      "  training accuracy:\t\t84.44%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 268 took 29.742s, currently going to do 513\n",
      "  training loss: 0.808703, validation loss: 0.470211\n",
      "  validation accuracy:\t\t84.02%\n",
      "  training accuracy:\t\t84.62%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 269 took 29.756s, currently going to do 513\n",
      "  training loss: 0.815863, validation loss: 0.463340\n",
      "  validation accuracy:\t\t84.21%\n",
      "  training accuracy:\t\t84.15%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 270 took 29.745s, currently going to do 513\n",
      "  training loss: 0.813199, validation loss: 0.472638\n",
      "  validation accuracy:\t\t84.12%\n",
      "  training accuracy:\t\t84.15%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 271 took 29.755s, currently going to do 513\n",
      "  training loss: 0.812933, validation loss: 0.463491\n",
      "  validation accuracy:\t\t84.40%\n",
      "  training accuracy:\t\t84.35%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 272 took 29.742s, currently going to do 513\n",
      "  training loss: 0.815793, validation loss: 0.466122\n",
      "  validation accuracy:\t\t84.17%\n",
      "  training accuracy:\t\t84.10%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 273 took 29.757s, currently going to do 513\n",
      "  training loss: 0.811196, validation loss: 0.459756\n",
      "  validation accuracy:\t\t84.52%\n",
      "  training accuracy:\t\t84.39%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 274 took 29.744s, currently going to do 513\n",
      "  training loss: 0.805794, validation loss: 0.468226\n",
      "  validation accuracy:\t\t84.20%\n",
      "  training accuracy:\t\t84.46%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 275 took 29.753s, currently going to do 513\n",
      "  training loss: 0.811751, validation loss: 0.463760\n",
      "  validation accuracy:\t\t84.65%\n",
      "  training accuracy:\t\t84.37%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 276 took 29.743s, currently going to do 513\n",
      "  training loss: 0.800623, validation loss: 0.464217\n",
      "  validation accuracy:\t\t84.43%\n",
      "  training accuracy:\t\t84.64%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 277 took 29.756s, currently going to do 513\n",
      "  training loss: 0.808441, validation loss: 0.459304\n",
      "  validation accuracy:\t\t84.59%\n",
      "  training accuracy:\t\t84.49%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 278 took 29.741s, currently going to do 513\n",
      "  training loss: 0.807960, validation loss: 0.469003\n",
      "  validation accuracy:\t\t84.51%\n",
      "  training accuracy:\t\t84.42%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 279 took 29.754s, currently going to do 513\n",
      "  training loss: 0.810504, validation loss: 0.467892\n",
      "  validation accuracy:\t\t84.18%\n",
      "  training accuracy:\t\t84.36%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 280 took 29.745s, currently going to do 513\n",
      "  training loss: 0.806125, validation loss: 0.470424\n",
      "  validation accuracy:\t\t84.35%\n",
      "  training accuracy:\t\t84.40%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 281 took 29.757s, currently going to do 513\n",
      "  training loss: 0.811323, validation loss: 0.470463\n",
      "  validation accuracy:\t\t84.32%\n",
      "  training accuracy:\t\t84.33%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 282 took 29.741s, currently going to do 513\n",
      "  training loss: 0.803124, validation loss: 0.471961\n",
      "  validation accuracy:\t\t83.96%\n",
      "  training accuracy:\t\t84.67%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 283 took 29.753s, currently going to do 513\n",
      "  training loss: 0.807130, validation loss: 0.475969\n",
      "  validation accuracy:\t\t83.93%\n",
      "  training accuracy:\t\t84.53%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 284 took 29.743s, currently going to do 513\n",
      "  training loss: 0.802597, validation loss: 0.466662\n",
      "  validation accuracy:\t\t84.28%\n",
      "  training accuracy:\t\t84.56%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 285 took 29.755s, currently going to do 513\n",
      "  training loss: 0.809705, validation loss: 0.460160\n",
      "  validation accuracy:\t\t84.60%\n",
      "  training accuracy:\t\t84.25%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 286 took 29.746s, currently going to do 513\n",
      "  training loss: 0.801393, validation loss: 0.465781\n",
      "  validation accuracy:\t\t84.44%\n",
      "  training accuracy:\t\t84.63%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 287 took 29.756s, currently going to do 513\n",
      "  training loss: 0.807557, validation loss: 0.460967\n",
      "  validation accuracy:\t\t84.68%\n",
      "  training accuracy:\t\t84.50%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 288 took 30.897s, currently going to do 577\n",
      "  training loss: 0.804695, validation loss: 0.456086\n",
      "  validation accuracy:\t\t84.87%\n",
      "  training accuracy:\t\t84.57%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 289 took 29.746s, currently going to do 577\n",
      "  training loss: 0.805610, validation loss: 0.468575\n",
      "  validation accuracy:\t\t84.28%\n",
      "  training accuracy:\t\t84.65%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 290 took 29.743s, currently going to do 577\n",
      "  training loss: 0.805196, validation loss: 0.472118\n",
      "  validation accuracy:\t\t84.06%\n",
      "  training accuracy:\t\t84.35%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 291 took 29.747s, currently going to do 577\n",
      "  training loss: 0.804396, validation loss: 0.465505\n",
      "  validation accuracy:\t\t84.52%\n",
      "  training accuracy:\t\t84.55%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 292 took 31.000s, currently going to do 585\n",
      "  training loss: 0.805502, validation loss: 0.457382\n",
      "  validation accuracy:\t\t84.88%\n",
      "  training accuracy:\t\t84.62%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 293 took 29.750s, currently going to do 585\n",
      "  training loss: 0.801783, validation loss: 0.467410\n",
      "  validation accuracy:\t\t84.51%\n",
      "  training accuracy:\t\t84.65%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 294 took 29.740s, currently going to do 585\n",
      "  training loss: 0.804852, validation loss: 0.459742\n",
      "  validation accuracy:\t\t84.81%\n",
      "  training accuracy:\t\t84.62%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 295 took 29.745s, currently going to do 585\n",
      "  training loss: 0.804743, validation loss: 0.465941\n",
      "  validation accuracy:\t\t84.58%\n",
      "  training accuracy:\t\t84.66%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 296 took 29.738s, currently going to do 585\n",
      "  training loss: 0.801624, validation loss: 0.477632\n",
      "  validation accuracy:\t\t84.19%\n",
      "  training accuracy:\t\t84.61%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 297 took 29.744s, currently going to do 585\n",
      "  training loss: 0.804628, validation loss: 0.456345\n",
      "  validation accuracy:\t\t84.84%\n",
      "  training accuracy:\t\t84.53%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 298 took 29.744s, currently going to do 585\n",
      "  training loss: 0.806765, validation loss: 0.462570\n",
      "  validation accuracy:\t\t84.69%\n",
      "  training accuracy:\t\t84.42%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 299 took 31.365s, currently going to do 599\n",
      "  training loss: 0.802090, validation loss: 0.455121\n",
      "  validation accuracy:\t\t85.00%\n",
      "  training accuracy:\t\t84.67%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 300 took 29.750s, currently going to do 599\n",
      "  training loss: 0.800648, validation loss: 0.463755\n",
      "  validation accuracy:\t\t84.49%\n",
      "  training accuracy:\t\t84.69%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 301 took 29.745s, currently going to do 599\n",
      "  training loss: 0.799587, validation loss: 0.468237\n",
      "  validation accuracy:\t\t84.59%\n",
      "  training accuracy:\t\t84.74%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 302 took 29.746s, currently going to do 599\n",
      "  training loss: 0.806106, validation loss: 0.466375\n",
      "  validation accuracy:\t\t84.73%\n",
      "  training accuracy:\t\t84.47%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 303 took 29.743s, currently going to do 599\n",
      "  training loss: 0.799216, validation loss: 0.459343\n",
      "  validation accuracy:\t\t84.58%\n",
      "  training accuracy:\t\t84.67%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 304 took 29.746s, currently going to do 599\n",
      "  training loss: 0.799149, validation loss: 0.468433\n",
      "  validation accuracy:\t\t84.30%\n",
      "  training accuracy:\t\t84.76%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 305 took 29.746s, currently going to do 599\n",
      "  training loss: 0.799456, validation loss: 0.458959\n",
      "  validation accuracy:\t\t84.62%\n",
      "  training accuracy:\t\t84.81%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 306 took 29.743s, currently going to do 599\n",
      "  training loss: 0.799200, validation loss: 0.456669\n",
      "  validation accuracy:\t\t84.48%\n",
      "  training accuracy:\t\t84.83%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 307 took 29.746s, currently going to do 599\n",
      "  training loss: 0.798726, validation loss: 0.463908\n",
      "  validation accuracy:\t\t84.48%\n",
      "  training accuracy:\t\t84.72%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 308 took 29.743s, currently going to do 599\n",
      "  training loss: 0.796314, validation loss: 0.458364\n",
      "  validation accuracy:\t\t84.85%\n",
      "  training accuracy:\t\t84.88%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 309 took 29.747s, currently going to do 599\n",
      "  training loss: 0.795685, validation loss: 0.454326\n",
      "  validation accuracy:\t\t84.84%\n",
      "  training accuracy:\t\t84.63%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 310 took 29.745s, currently going to do 599\n",
      "  training loss: 0.802393, validation loss: 0.478355\n",
      "  validation accuracy:\t\t84.45%\n",
      "  training accuracy:\t\t84.73%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 311 took 29.744s, currently going to do 599\n",
      "  training loss: 0.794628, validation loss: 0.471328\n",
      "  validation accuracy:\t\t84.37%\n",
      "  training accuracy:\t\t84.88%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 312 took 29.742s, currently going to do 599\n",
      "  training loss: 0.802366, validation loss: 0.456675\n",
      "  validation accuracy:\t\t84.98%\n",
      "  training accuracy:\t\t84.59%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 313 took 29.747s, currently going to do 599\n",
      "  training loss: 0.799494, validation loss: 0.474002\n",
      "  validation accuracy:\t\t84.18%\n",
      "  training accuracy:\t\t84.81%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 314 took 29.744s, currently going to do 599\n",
      "  training loss: 0.791875, validation loss: 0.461513\n",
      "  validation accuracy:\t\t84.74%\n",
      "  training accuracy:\t\t84.92%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 315 took 29.745s, currently going to do 599\n",
      "  training loss: 0.796348, validation loss: 0.458036\n",
      "  validation accuracy:\t\t84.56%\n",
      "  training accuracy:\t\t84.78%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 316 took 29.745s, currently going to do 599\n",
      "  training loss: 0.798490, validation loss: 0.456426\n",
      "  validation accuracy:\t\t84.94%\n",
      "  training accuracy:\t\t84.66%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 317 took 29.744s, currently going to do 599\n",
      "  training loss: 0.796140, validation loss: 0.464211\n",
      "  validation accuracy:\t\t84.49%\n",
      "  training accuracy:\t\t84.93%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 318 took 29.747s, currently going to do 599\n",
      "  training loss: 0.796615, validation loss: 0.455267\n",
      "  validation accuracy:\t\t84.86%\n",
      "  training accuracy:\t\t85.00%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 319 took 29.751s, currently going to do 599\n",
      "  training loss: 0.794766, validation loss: 0.475325\n",
      "  validation accuracy:\t\t84.10%\n",
      "  training accuracy:\t\t85.06%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 320 took 29.745s, currently going to do 599\n",
      "  training loss: 0.796662, validation loss: 0.464421\n",
      "  validation accuracy:\t\t84.60%\n",
      "  training accuracy:\t\t84.69%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 321 took 29.746s, currently going to do 599\n",
      "  training loss: 0.791008, validation loss: 0.460472\n",
      "  validation accuracy:\t\t84.63%\n",
      "  training accuracy:\t\t85.09%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 322 took 29.744s, currently going to do 599\n",
      "  training loss: 0.790893, validation loss: 0.473680\n",
      "  validation accuracy:\t\t84.30%\n",
      "  training accuracy:\t\t85.10%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 323 took 29.746s, currently going to do 599\n",
      "  training loss: 0.792938, validation loss: 0.454988\n",
      "  validation accuracy:\t\t84.91%\n",
      "  training accuracy:\t\t85.04%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 324 took 29.746s, currently going to do 599\n",
      "  training loss: 0.798090, validation loss: 0.462257\n",
      "  validation accuracy:\t\t84.66%\n",
      "  training accuracy:\t\t84.79%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 325 took 29.744s, currently going to do 599\n",
      "  training loss: 0.796550, validation loss: 0.460753\n",
      "  validation accuracy:\t\t84.48%\n",
      "  training accuracy:\t\t85.01%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 326 took 29.748s, currently going to do 599\n",
      "  training loss: 0.792894, validation loss: 0.461566\n",
      "  validation accuracy:\t\t84.81%\n",
      "  training accuracy:\t\t84.90%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 327 took 30.878s, currently going to do 655\n",
      "  training loss: 0.795358, validation loss: 0.455539\n",
      "  validation accuracy:\t\t85.04%\n",
      "  training accuracy:\t\t84.83%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 328 took 29.753s, currently going to do 655\n",
      "  training loss: 0.792929, validation loss: 0.467556\n",
      "  validation accuracy:\t\t84.62%\n",
      "  training accuracy:\t\t85.08%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 329 took 29.745s, currently going to do 655\n",
      "  training loss: 0.792669, validation loss: 0.457557\n",
      "  validation accuracy:\t\t84.61%\n",
      "  training accuracy:\t\t85.03%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 330 took 29.748s, currently going to do 655\n",
      "  training loss: 0.789768, validation loss: 0.465786\n",
      "  validation accuracy:\t\t84.64%\n",
      "  training accuracy:\t\t85.19%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 331 took 29.746s, currently going to do 655\n",
      "  training loss: 0.793474, validation loss: 0.462300\n",
      "  validation accuracy:\t\t84.70%\n",
      "  training accuracy:\t\t85.02%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 332 took 29.745s, currently going to do 655\n",
      "  training loss: 0.794699, validation loss: 0.464392\n",
      "  validation accuracy:\t\t84.45%\n",
      "  training accuracy:\t\t84.97%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 333 took 29.741s, currently going to do 655\n",
      "  training loss: 0.794323, validation loss: 0.456433\n",
      "  validation accuracy:\t\t84.88%\n",
      "  training accuracy:\t\t84.93%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 334 took 30.925s, currently going to do 669\n",
      "  training loss: 0.796660, validation loss: 0.450296\n",
      "  validation accuracy:\t\t85.09%\n",
      "  training accuracy:\t\t84.87%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 335 took 29.752s, currently going to do 669\n",
      "  training loss: 0.789242, validation loss: 0.462265\n",
      "  validation accuracy:\t\t84.50%\n",
      "  training accuracy:\t\t85.11%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 336 took 29.749s, currently going to do 669\n",
      "  training loss: 0.788565, validation loss: 0.460080\n",
      "  validation accuracy:\t\t84.58%\n",
      "  training accuracy:\t\t85.08%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 337 took 29.748s, currently going to do 669\n",
      "  training loss: 0.791938, validation loss: 0.462767\n",
      "  validation accuracy:\t\t84.64%\n",
      "  training accuracy:\t\t84.93%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 338 took 29.749s, currently going to do 669\n",
      "  training loss: 0.790601, validation loss: 0.467851\n",
      "  validation accuracy:\t\t84.49%\n",
      "  training accuracy:\t\t84.89%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 339 took 29.748s, currently going to do 669\n",
      "  training loss: 0.791264, validation loss: 0.457815\n",
      "  validation accuracy:\t\t84.85%\n",
      "  training accuracy:\t\t85.16%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 340 took 29.747s, currently going to do 669\n",
      "  training loss: 0.793253, validation loss: 0.453593\n",
      "  validation accuracy:\t\t84.85%\n",
      "  training accuracy:\t\t85.07%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 341 took 29.745s, currently going to do 669\n",
      "  training loss: 0.788601, validation loss: 0.465933\n",
      "  validation accuracy:\t\t84.52%\n",
      "  training accuracy:\t\t84.91%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 342 took 29.749s, currently going to do 669\n",
      "  training loss: 0.786817, validation loss: 0.457029\n",
      "  validation accuracy:\t\t84.60%\n",
      "  training accuracy:\t\t85.00%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 343 took 29.747s, currently going to do 669\n",
      "  training loss: 0.789828, validation loss: 0.461765\n",
      "  validation accuracy:\t\t84.67%\n",
      "  training accuracy:\t\t85.06%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 344 took 29.749s, currently going to do 669\n",
      "  training loss: 0.789504, validation loss: 0.459078\n",
      "  validation accuracy:\t\t84.61%\n",
      "  training accuracy:\t\t84.88%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 345 took 29.745s, currently going to do 669\n",
      "  training loss: 0.790941, validation loss: 0.454545\n",
      "  validation accuracy:\t\t84.76%\n",
      "  training accuracy:\t\t85.21%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 346 took 31.189s, currently going to do 693\n",
      "  training loss: 0.794072, validation loss: 0.455902\n",
      "  validation accuracy:\t\t85.16%\n",
      "  training accuracy:\t\t85.03%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 347 took 29.751s, currently going to do 693\n",
      "  training loss: 0.789043, validation loss: 0.455776\n",
      "  validation accuracy:\t\t84.91%\n",
      "  training accuracy:\t\t84.97%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 348 took 29.744s, currently going to do 693\n",
      "  training loss: 0.786585, validation loss: 0.454956\n",
      "  validation accuracy:\t\t85.00%\n",
      "  training accuracy:\t\t85.18%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 349 took 29.747s, currently going to do 693\n",
      "  training loss: 0.789809, validation loss: 0.475517\n",
      "  validation accuracy:\t\t84.36%\n",
      "  training accuracy:\t\t85.13%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 350 took 29.746s, currently going to do 693\n",
      "  training loss: 0.788491, validation loss: 0.470124\n",
      "  validation accuracy:\t\t84.40%\n",
      "  training accuracy:\t\t85.24%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 351 took 29.748s, currently going to do 693\n",
      "  training loss: 0.783500, validation loss: 0.461134\n",
      "  validation accuracy:\t\t84.74%\n",
      "  training accuracy:\t\t85.25%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 352 took 29.745s, currently going to do 693\n",
      "  training loss: 0.793293, validation loss: 0.466261\n",
      "  validation accuracy:\t\t84.40%\n",
      "  training accuracy:\t\t84.83%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 353 took 29.746s, currently going to do 693\n",
      "  training loss: 0.790368, validation loss: 0.460175\n",
      "  validation accuracy:\t\t84.54%\n",
      "  training accuracy:\t\t84.99%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 354 took 29.745s, currently going to do 693\n",
      "  training loss: 0.791127, validation loss: 0.456781\n",
      "  validation accuracy:\t\t84.91%\n",
      "  training accuracy:\t\t84.98%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 355 took 29.747s, currently going to do 693\n",
      "  training loss: 0.790484, validation loss: 0.459352\n",
      "  validation accuracy:\t\t84.71%\n",
      "  training accuracy:\t\t85.05%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 356 took 29.751s, currently going to do 693\n",
      "  training loss: 0.786393, validation loss: 0.460684\n",
      "  validation accuracy:\t\t84.73%\n",
      "  training accuracy:\t\t85.22%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 357 took 29.749s, currently going to do 693\n",
      "  training loss: 0.793709, validation loss: 0.476113\n",
      "  validation accuracy:\t\t84.33%\n",
      "  training accuracy:\t\t84.77%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 358 took 29.750s, currently going to do 693\n",
      "  training loss: 0.782936, validation loss: 0.460102\n",
      "  validation accuracy:\t\t84.69%\n",
      "  training accuracy:\t\t85.44%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 359 took 29.752s, currently going to do 693\n",
      "  training loss: 0.782917, validation loss: 0.454044\n",
      "  validation accuracy:\t\t84.72%\n",
      "  training accuracy:\t\t85.34%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 360 took 29.749s, currently going to do 693\n",
      "  training loss: 0.794270, validation loss: 0.459370\n",
      "  validation accuracy:\t\t84.98%\n",
      "  training accuracy:\t\t84.99%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 361 took 29.749s, currently going to do 693\n",
      "  training loss: 0.784821, validation loss: 0.448721\n",
      "  validation accuracy:\t\t85.05%\n",
      "  training accuracy:\t\t85.24%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 362 took 29.745s, currently going to do 693\n",
      "  training loss: 0.788615, validation loss: 0.449043\n",
      "  validation accuracy:\t\t85.01%\n",
      "  training accuracy:\t\t85.10%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 363 took 29.751s, currently going to do 693\n",
      "  training loss: 0.778041, validation loss: 0.456729\n",
      "  validation accuracy:\t\t84.92%\n",
      "  training accuracy:\t\t85.42%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 364 took 29.750s, currently going to do 693\n",
      "  training loss: 0.785309, validation loss: 0.449408\n",
      "  validation accuracy:\t\t84.96%\n",
      "  training accuracy:\t\t85.24%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 365 took 29.753s, currently going to do 693\n",
      "  training loss: 0.786453, validation loss: 0.459588\n",
      "  validation accuracy:\t\t84.56%\n",
      "  training accuracy:\t\t85.19%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 366 took 29.750s, currently going to do 693\n",
      "  training loss: 0.784520, validation loss: 0.459468\n",
      "  validation accuracy:\t\t84.80%\n",
      "  training accuracy:\t\t85.36%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 367 took 29.749s, currently going to do 693\n",
      "  training loss: 0.788773, validation loss: 0.459524\n",
      "  validation accuracy:\t\t84.70%\n",
      "  training accuracy:\t\t85.06%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 368 took 29.750s, currently going to do 693\n",
      "  training loss: 0.783306, validation loss: 0.448132\n",
      "  validation accuracy:\t\t85.06%\n",
      "  training accuracy:\t\t85.14%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 369 took 29.750s, currently going to do 693\n",
      "  training loss: 0.787548, validation loss: 0.466564\n",
      "  validation accuracy:\t\t84.51%\n",
      "  training accuracy:\t\t85.32%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 370 took 29.749s, currently going to do 693\n",
      "  training loss: 0.778901, validation loss: 0.455924\n",
      "  validation accuracy:\t\t84.87%\n",
      "  training accuracy:\t\t85.43%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 371 took 29.751s, currently going to do 693\n",
      "  training loss: 0.781382, validation loss: 0.451601\n",
      "  validation accuracy:\t\t85.08%\n",
      "  training accuracy:\t\t85.48%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 372 took 29.748s, currently going to do 693\n",
      "  training loss: 0.789048, validation loss: 0.460801\n",
      "  validation accuracy:\t\t84.76%\n",
      "  training accuracy:\t\t85.25%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 373 took 29.750s, currently going to do 693\n",
      "  training loss: 0.785676, validation loss: 0.453320\n",
      "  validation accuracy:\t\t84.92%\n",
      "  training accuracy:\t\t85.25%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 374 took 29.750s, currently going to do 693\n",
      "  training loss: 0.781885, validation loss: 0.453308\n",
      "  validation accuracy:\t\t84.81%\n",
      "  training accuracy:\t\t85.30%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 375 took 29.749s, currently going to do 693\n",
      "  training loss: 0.787529, validation loss: 0.453566\n",
      "  validation accuracy:\t\t84.87%\n",
      "  training accuracy:\t\t85.08%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 376 took 29.747s, currently going to do 693\n",
      "  training loss: 0.779958, validation loss: 0.465247\n",
      "  validation accuracy:\t\t84.76%\n",
      "  training accuracy:\t\t85.43%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 377 took 29.751s, currently going to do 693\n",
      "  training loss: 0.778315, validation loss: 0.450632\n",
      "  validation accuracy:\t\t84.84%\n",
      "  training accuracy:\t\t85.25%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 378 took 29.748s, currently going to do 693\n",
      "  training loss: 0.780342, validation loss: 0.455230\n",
      "  validation accuracy:\t\t84.85%\n",
      "  training accuracy:\t\t85.43%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 379 took 29.751s, currently going to do 693\n",
      "  training loss: 0.773558, validation loss: 0.453108\n",
      "  validation accuracy:\t\t84.97%\n",
      "  training accuracy:\t\t85.56%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 380 took 29.747s, currently going to do 693\n",
      "  training loss: 0.782351, validation loss: 0.459238\n",
      "  validation accuracy:\t\t84.77%\n",
      "  training accuracy:\t\t85.45%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 381 took 30.959s, currently going to do 763\n",
      "  training loss: 0.784899, validation loss: 0.450076\n",
      "  validation accuracy:\t\t85.18%\n",
      "  training accuracy:\t\t85.35%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 382 took 29.749s, currently going to do 763\n",
      "  training loss: 0.780666, validation loss: 0.471695\n",
      "  validation accuracy:\t\t84.45%\n",
      "  training accuracy:\t\t85.43%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 383 took 29.746s, currently going to do 763\n",
      "  training loss: 0.779550, validation loss: 0.452602\n",
      "  validation accuracy:\t\t85.11%\n",
      "  training accuracy:\t\t85.22%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 384 took 29.748s, currently going to do 763\n",
      "  training loss: 0.780656, validation loss: 0.458827\n",
      "  validation accuracy:\t\t84.83%\n",
      "  training accuracy:\t\t85.33%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 385 took 29.750s, currently going to do 763\n",
      "  training loss: 0.774903, validation loss: 0.462399\n",
      "  validation accuracy:\t\t84.59%\n",
      "  training accuracy:\t\t85.62%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 386 took 29.747s, currently going to do 763\n",
      "  training loss: 0.781185, validation loss: 0.459390\n",
      "  validation accuracy:\t\t84.91%\n",
      "  training accuracy:\t\t85.15%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 387 took 29.750s, currently going to do 763\n",
      "  training loss: 0.784185, validation loss: 0.453929\n",
      "  validation accuracy:\t\t84.95%\n",
      "  training accuracy:\t\t85.31%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 388 took 29.750s, currently going to do 763\n",
      "  training loss: 0.782245, validation loss: 0.455636\n",
      "  validation accuracy:\t\t84.85%\n",
      "  training accuracy:\t\t85.21%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 389 took 29.745s, currently going to do 763\n",
      "  training loss: 0.778554, validation loss: 0.460706\n",
      "  validation accuracy:\t\t84.89%\n",
      "  training accuracy:\t\t85.53%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 390 took 29.749s, currently going to do 763\n",
      "  training loss: 0.775445, validation loss: 0.461673\n",
      "  validation accuracy:\t\t84.62%\n",
      "  training accuracy:\t\t85.63%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 391 took 30.877s, currently going to do 783\n",
      "  training loss: 0.778196, validation loss: 0.450195\n",
      "  validation accuracy:\t\t85.25%\n",
      "  training accuracy:\t\t85.44%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 392 took 29.756s, currently going to do 783\n",
      "  training loss: 0.776750, validation loss: 0.466405\n",
      "  validation accuracy:\t\t84.64%\n",
      "  training accuracy:\t\t85.53%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 393 took 29.746s, currently going to do 783\n",
      "  training loss: 0.780255, validation loss: 0.456075\n",
      "  validation accuracy:\t\t85.11%\n",
      "  training accuracy:\t\t85.47%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 394 took 29.749s, currently going to do 783\n",
      "  training loss: 0.772263, validation loss: 0.461841\n",
      "  validation accuracy:\t\t84.61%\n",
      "  training accuracy:\t\t85.75%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 395 took 29.749s, currently going to do 783\n",
      "  training loss: 0.778478, validation loss: 0.453232\n",
      "  validation accuracy:\t\t85.02%\n",
      "  training accuracy:\t\t85.50%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 396 took 29.751s, currently going to do 783\n",
      "  training loss: 0.786604, validation loss: 0.456636\n",
      "  validation accuracy:\t\t84.78%\n",
      "  training accuracy:\t\t85.23%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 397 took 29.744s, currently going to do 783\n",
      "  training loss: 0.777358, validation loss: 0.456955\n",
      "  validation accuracy:\t\t84.69%\n",
      "  training accuracy:\t\t85.60%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 398 took 29.748s, currently going to do 783\n",
      "  training loss: 0.774479, validation loss: 0.449671\n",
      "  validation accuracy:\t\t85.04%\n",
      "  training accuracy:\t\t85.56%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 399 took 29.746s, currently going to do 783\n",
      "  training loss: 0.776510, validation loss: 0.458313\n",
      "  validation accuracy:\t\t84.85%\n",
      "  training accuracy:\t\t85.55%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 400 took 29.747s, currently going to do 783\n",
      "  training loss: 0.776875, validation loss: 0.455577\n",
      "  validation accuracy:\t\t84.85%\n",
      "  training accuracy:\t\t85.54%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 401 took 30.918s, currently going to do 803\n",
      "  training loss: 0.776617, validation loss: 0.446195\n",
      "  validation accuracy:\t\t85.27%\n",
      "  training accuracy:\t\t85.55%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 402 took 29.751s, currently going to do 803\n",
      "  training loss: 0.777534, validation loss: 0.456483\n",
      "  validation accuracy:\t\t84.72%\n",
      "  training accuracy:\t\t85.69%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 403 took 29.750s, currently going to do 803\n",
      "  training loss: 0.774220, validation loss: 0.448804\n",
      "  validation accuracy:\t\t85.05%\n",
      "  training accuracy:\t\t85.69%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 404 took 29.750s, currently going to do 803\n",
      "  training loss: 0.777518, validation loss: 0.462570\n",
      "  validation accuracy:\t\t84.54%\n",
      "  training accuracy:\t\t85.47%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 405 took 29.750s, currently going to do 803\n",
      "  training loss: 0.778787, validation loss: 0.448740\n",
      "  validation accuracy:\t\t85.07%\n",
      "  training accuracy:\t\t85.41%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 406 took 29.754s, currently going to do 803\n",
      "  training loss: 0.778294, validation loss: 0.452626\n",
      "  validation accuracy:\t\t84.89%\n",
      "  training accuracy:\t\t85.67%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 407 took 29.740s, currently going to do 803\n",
      "  training loss: 0.771531, validation loss: 0.456806\n",
      "  validation accuracy:\t\t84.71%\n",
      "  training accuracy:\t\t85.61%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 408 took 29.744s, currently going to do 803\n",
      "  training loss: 0.779115, validation loss: 0.453333\n",
      "  validation accuracy:\t\t84.69%\n",
      "  training accuracy:\t\t85.40%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 409 took 29.745s, currently going to do 803\n",
      "  training loss: 0.772857, validation loss: 0.456704\n",
      "  validation accuracy:\t\t84.89%\n",
      "  training accuracy:\t\t85.60%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 410 took 29.746s, currently going to do 803\n",
      "  training loss: 0.775718, validation loss: 0.450066\n",
      "  validation accuracy:\t\t84.98%\n",
      "  training accuracy:\t\t85.46%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 411 took 29.741s, currently going to do 803\n",
      "  training loss: 0.775650, validation loss: 0.447999\n",
      "  validation accuracy:\t\t85.08%\n",
      "  training accuracy:\t\t85.37%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 412 took 29.743s, currently going to do 803\n",
      "  training loss: 0.775167, validation loss: 0.452897\n",
      "  validation accuracy:\t\t85.09%\n",
      "  training accuracy:\t\t85.56%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 413 took 29.739s, currently going to do 803\n",
      "  training loss: 0.779368, validation loss: 0.455546\n",
      "  validation accuracy:\t\t85.12%\n",
      "  training accuracy:\t\t85.46%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 414 took 29.741s, currently going to do 803\n",
      "  training loss: 0.778614, validation loss: 0.459320\n",
      "  validation accuracy:\t\t84.84%\n",
      "  training accuracy:\t\t85.52%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 415 took 29.743s, currently going to do 803\n",
      "  training loss: 0.773209, validation loss: 0.450222\n",
      "  validation accuracy:\t\t84.91%\n",
      "  training accuracy:\t\t85.71%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 416 took 29.743s, currently going to do 803\n",
      "  training loss: 0.773205, validation loss: 0.450429\n",
      "  validation accuracy:\t\t85.02%\n",
      "  training accuracy:\t\t85.63%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 417 took 29.742s, currently going to do 803\n",
      "  training loss: 0.775839, validation loss: 0.457606\n",
      "  validation accuracy:\t\t84.64%\n",
      "  training accuracy:\t\t85.46%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 418 took 29.741s, currently going to do 803\n",
      "  training loss: 0.768666, validation loss: 0.457475\n",
      "  validation accuracy:\t\t85.00%\n",
      "  training accuracy:\t\t85.91%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 419 took 29.744s, currently going to do 803\n",
      "  training loss: 0.776592, validation loss: 0.468508\n",
      "  validation accuracy:\t\t84.54%\n",
      "  training accuracy:\t\t85.53%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 420 took 29.747s, currently going to do 803\n",
      "  training loss: 0.778657, validation loss: 0.454529\n",
      "  validation accuracy:\t\t84.86%\n",
      "  training accuracy:\t\t85.46%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 421 took 29.744s, currently going to do 803\n",
      "  training loss: 0.770142, validation loss: 0.451519\n",
      "  validation accuracy:\t\t85.06%\n",
      "  training accuracy:\t\t85.79%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 422 took 29.743s, currently going to do 803\n",
      "  training loss: 0.779296, validation loss: 0.447686\n",
      "  validation accuracy:\t\t85.18%\n",
      "  training accuracy:\t\t85.45%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 423 took 29.743s, currently going to do 803\n",
      "  training loss: 0.768769, validation loss: 0.445144\n",
      "  validation accuracy:\t\t85.20%\n",
      "  training accuracy:\t\t85.80%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 424 took 29.743s, currently going to do 803\n",
      "  training loss: 0.771953, validation loss: 0.456580\n",
      "  validation accuracy:\t\t85.10%\n",
      "  training accuracy:\t\t85.72%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 425 took 29.746s, currently going to do 803\n",
      "  training loss: 0.782123, validation loss: 0.447651\n",
      "  validation accuracy:\t\t85.16%\n",
      "  training accuracy:\t\t85.29%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 426 took 29.745s, currently going to do 803\n",
      "  training loss: 0.773056, validation loss: 0.465519\n",
      "  validation accuracy:\t\t84.86%\n",
      "  training accuracy:\t\t85.67%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 427 took 29.740s, currently going to do 803\n",
      "  training loss: 0.766963, validation loss: 0.449820\n",
      "  validation accuracy:\t\t85.12%\n",
      "  training accuracy:\t\t85.80%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 428 took 29.743s, currently going to do 803\n",
      "  training loss: 0.770535, validation loss: 0.457486\n",
      "  validation accuracy:\t\t84.64%\n",
      "  training accuracy:\t\t85.86%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 429 took 30.820s, currently going to do 859\n",
      "  training loss: 0.770954, validation loss: 0.442838\n",
      "  validation accuracy:\t\t85.33%\n",
      "  training accuracy:\t\t85.60%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 430 took 29.764s, currently going to do 859\n",
      "  training loss: 0.760651, validation loss: 0.445951\n",
      "  validation accuracy:\t\t85.15%\n",
      "  training accuracy:\t\t86.09%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 431 took 29.757s, currently going to do 859\n",
      "  training loss: 0.774122, validation loss: 0.450439\n",
      "  validation accuracy:\t\t84.97%\n",
      "  training accuracy:\t\t85.58%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 432 took 29.758s, currently going to do 859\n",
      "  training loss: 0.769129, validation loss: 0.458754\n",
      "  validation accuracy:\t\t84.87%\n",
      "  training accuracy:\t\t85.98%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 433 took 29.759s, currently going to do 859\n",
      "  training loss: 0.772352, validation loss: 0.450471\n",
      "  validation accuracy:\t\t85.12%\n",
      "  training accuracy:\t\t85.78%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 434 took 29.763s, currently going to do 859\n",
      "  training loss: 0.769299, validation loss: 0.446148\n",
      "  validation accuracy:\t\t85.22%\n",
      "  training accuracy:\t\t85.93%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 435 took 30.971s, currently going to do 871\n",
      "  training loss: 0.769003, validation loss: 0.445796\n",
      "  validation accuracy:\t\t85.35%\n",
      "  training accuracy:\t\t85.81%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 436 took 29.750s, currently going to do 871\n",
      "  training loss: 0.774221, validation loss: 0.461153\n",
      "  validation accuracy:\t\t84.85%\n",
      "  training accuracy:\t\t85.88%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 437 took 29.749s, currently going to do 871\n",
      "  training loss: 0.776760, validation loss: 0.451537\n",
      "  validation accuracy:\t\t85.19%\n",
      "  training accuracy:\t\t85.59%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 438 took 29.746s, currently going to do 871\n",
      "  training loss: 0.769153, validation loss: 0.448148\n",
      "  validation accuracy:\t\t85.27%\n",
      "  training accuracy:\t\t85.76%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 439 took 29.753s, currently going to do 871\n",
      "  training loss: 0.771491, validation loss: 0.450759\n",
      "  validation accuracy:\t\t85.16%\n",
      "  training accuracy:\t\t85.73%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 440 took 29.745s, currently going to do 871\n",
      "  training loss: 0.772351, validation loss: 0.450474\n",
      "  validation accuracy:\t\t85.07%\n",
      "  training accuracy:\t\t85.53%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 441 took 29.750s, currently going to do 871\n",
      "  training loss: 0.773048, validation loss: 0.456188\n",
      "  validation accuracy:\t\t84.65%\n",
      "  training accuracy:\t\t85.86%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 442 took 29.746s, currently going to do 871\n",
      "  training loss: 0.771611, validation loss: 0.451460\n",
      "  validation accuracy:\t\t85.02%\n",
      "  training accuracy:\t\t85.74%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 443 took 29.750s, currently going to do 871\n",
      "  training loss: 0.771532, validation loss: 0.451389\n",
      "  validation accuracy:\t\t85.14%\n",
      "  training accuracy:\t\t85.56%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 444 took 29.745s, currently going to do 871\n",
      "  training loss: 0.773756, validation loss: 0.450214\n",
      "  validation accuracy:\t\t84.98%\n",
      "  training accuracy:\t\t85.63%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 445 took 29.751s, currently going to do 871\n",
      "  training loss: 0.772659, validation loss: 0.458499\n",
      "  validation accuracy:\t\t84.96%\n",
      "  training accuracy:\t\t85.56%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 446 took 29.745s, currently going to do 871\n",
      "  training loss: 0.773866, validation loss: 0.452763\n",
      "  validation accuracy:\t\t84.81%\n",
      "  training accuracy:\t\t85.66%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 447 took 29.747s, currently going to do 871\n",
      "  training loss: 0.768349, validation loss: 0.452187\n",
      "  validation accuracy:\t\t84.80%\n",
      "  training accuracy:\t\t85.69%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 448 took 29.745s, currently going to do 871\n",
      "  training loss: 0.765789, validation loss: 0.450788\n",
      "  validation accuracy:\t\t85.03%\n",
      "  training accuracy:\t\t85.75%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 449 took 29.750s, currently going to do 871\n",
      "  training loss: 0.771720, validation loss: 0.457737\n",
      "  validation accuracy:\t\t84.97%\n",
      "  training accuracy:\t\t85.75%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 450 took 29.747s, currently going to do 871\n",
      "  training loss: 0.765856, validation loss: 0.469190\n",
      "  validation accuracy:\t\t84.38%\n",
      "  training accuracy:\t\t85.98%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 451 took 30.842s, currently going to do 903\n",
      "  training loss: 0.768821, validation loss: 0.447733\n",
      "  validation accuracy:\t\t85.37%\n",
      "  training accuracy:\t\t85.91%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 452 took 29.756s, currently going to do 903\n",
      "  training loss: 0.770046, validation loss: 0.462886\n",
      "  validation accuracy:\t\t84.60%\n",
      "  training accuracy:\t\t85.64%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 453 took 29.754s, currently going to do 903\n",
      "  training loss: 0.765927, validation loss: 0.443186\n",
      "  validation accuracy:\t\t85.17%\n",
      "  training accuracy:\t\t86.01%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 454 took 30.822s, currently going to do 909\n",
      "  training loss: 0.767721, validation loss: 0.444216\n",
      "  validation accuracy:\t\t85.46%\n",
      "  training accuracy:\t\t85.88%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 455 took 29.762s, currently going to do 909\n",
      "  training loss: 0.770816, validation loss: 0.448457\n",
      "  validation accuracy:\t\t85.10%\n",
      "  training accuracy:\t\t85.70%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 456 took 29.750s, currently going to do 909\n",
      "  training loss: 0.766123, validation loss: 0.451267\n",
      "  validation accuracy:\t\t85.18%\n",
      "  training accuracy:\t\t85.91%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 457 took 29.755s, currently going to do 909\n",
      "  training loss: 0.760505, validation loss: 0.453529\n",
      "  validation accuracy:\t\t84.97%\n",
      "  training accuracy:\t\t85.95%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 458 took 29.748s, currently going to do 909\n",
      "  training loss: 0.761459, validation loss: 0.447069\n",
      "  validation accuracy:\t\t85.31%\n",
      "  training accuracy:\t\t85.98%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 459 took 29.755s, currently going to do 909\n",
      "  training loss: 0.763998, validation loss: 0.450508\n",
      "  validation accuracy:\t\t85.30%\n",
      "  training accuracy:\t\t85.99%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 460 took 29.751s, currently going to do 909\n",
      "  training loss: 0.766413, validation loss: 0.461174\n",
      "  validation accuracy:\t\t84.67%\n",
      "  training accuracy:\t\t85.82%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 461 took 29.752s, currently going to do 909\n",
      "  training loss: 0.763477, validation loss: 0.446952\n",
      "  validation accuracy:\t\t85.09%\n",
      "  training accuracy:\t\t85.96%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 462 took 29.752s, currently going to do 909\n",
      "  training loss: 0.768965, validation loss: 0.449576\n",
      "  validation accuracy:\t\t85.19%\n",
      "  training accuracy:\t\t85.86%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 463 took 29.755s, currently going to do 909\n",
      "  training loss: 0.771267, validation loss: 0.453748\n",
      "  validation accuracy:\t\t84.95%\n",
      "  training accuracy:\t\t85.60%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 464 took 29.752s, currently going to do 909\n",
      "  training loss: 0.764344, validation loss: 0.452223\n",
      "  validation accuracy:\t\t85.27%\n",
      "  training accuracy:\t\t85.88%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 465 took 29.755s, currently going to do 909\n",
      "  training loss: 0.763738, validation loss: 0.451205\n",
      "  validation accuracy:\t\t85.04%\n",
      "  training accuracy:\t\t86.07%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 466 took 29.757s, currently going to do 909\n",
      "  training loss: 0.764947, validation loss: 0.447457\n",
      "  validation accuracy:\t\t85.38%\n",
      "  training accuracy:\t\t85.89%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 467 took 29.751s, currently going to do 909\n",
      "  training loss: 0.771453, validation loss: 0.447297\n",
      "  validation accuracy:\t\t85.41%\n",
      "  training accuracy:\t\t85.67%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 468 took 29.745s, currently going to do 909\n",
      "  training loss: 0.769796, validation loss: 0.454512\n",
      "  validation accuracy:\t\t84.86%\n",
      "  training accuracy:\t\t86.00%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 469 took 29.760s, currently going to do 909\n",
      "  training loss: 0.763376, validation loss: 0.466109\n",
      "  validation accuracy:\t\t84.82%\n",
      "  training accuracy:\t\t85.96%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 470 took 29.750s, currently going to do 909\n",
      "  training loss: 0.769326, validation loss: 0.453685\n",
      "  validation accuracy:\t\t85.18%\n",
      "  training accuracy:\t\t85.77%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 471 took 29.759s, currently going to do 909\n",
      "  training loss: 0.765992, validation loss: 0.458743\n",
      "  validation accuracy:\t\t84.78%\n",
      "  training accuracy:\t\t85.98%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 472 took 29.751s, currently going to do 909\n",
      "  training loss: 0.766310, validation loss: 0.447860\n",
      "  validation accuracy:\t\t85.19%\n",
      "  training accuracy:\t\t85.60%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 473 took 29.763s, currently going to do 909\n",
      "  training loss: 0.761520, validation loss: 0.454516\n",
      "  validation accuracy:\t\t85.03%\n",
      "  training accuracy:\t\t85.91%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 474 took 29.748s, currently going to do 909\n",
      "  training loss: 0.767189, validation loss: 0.449307\n",
      "  validation accuracy:\t\t85.40%\n",
      "  training accuracy:\t\t85.94%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 475 took 29.752s, currently going to do 909\n",
      "  training loss: 0.763516, validation loss: 0.448780\n",
      "  validation accuracy:\t\t85.10%\n",
      "  training accuracy:\t\t86.00%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 476 took 29.747s, currently going to do 909\n",
      "  training loss: 0.761926, validation loss: 0.445339\n",
      "  validation accuracy:\t\t85.02%\n",
      "  training accuracy:\t\t85.92%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 477 took 29.754s, currently going to do 909\n",
      "  training loss: 0.767586, validation loss: 0.452776\n",
      "  validation accuracy:\t\t85.06%\n",
      "  training accuracy:\t\t85.85%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 478 took 29.748s, currently going to do 909\n",
      "  training loss: 0.762131, validation loss: 0.454922\n",
      "  validation accuracy:\t\t85.09%\n",
      "  training accuracy:\t\t86.09%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 479 took 29.755s, currently going to do 909\n",
      "  training loss: 0.767024, validation loss: 0.455383\n",
      "  validation accuracy:\t\t84.64%\n",
      "  training accuracy:\t\t85.87%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 480 took 29.749s, currently going to do 909\n",
      "  training loss: 0.758226, validation loss: 0.450509\n",
      "  validation accuracy:\t\t85.15%\n",
      "  training accuracy:\t\t86.16%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 481 took 29.759s, currently going to do 909\n",
      "  training loss: 0.764604, validation loss: 0.466498\n",
      "  validation accuracy:\t\t84.51%\n",
      "  training accuracy:\t\t85.81%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 482 took 29.756s, currently going to do 909\n",
      "  training loss: 0.763770, validation loss: 0.459367\n",
      "  validation accuracy:\t\t84.65%\n",
      "  training accuracy:\t\t86.03%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 483 took 29.752s, currently going to do 909\n",
      "  training loss: 0.768608, validation loss: 0.456630\n",
      "  validation accuracy:\t\t85.31%\n",
      "  training accuracy:\t\t85.89%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 484 took 29.750s, currently going to do 909\n",
      "  training loss: 0.765004, validation loss: 0.451403\n",
      "  validation accuracy:\t\t84.67%\n",
      "  training accuracy:\t\t85.96%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 485 took 29.754s, currently going to do 909\n",
      "  training loss: 0.762390, validation loss: 0.448511\n",
      "  validation accuracy:\t\t85.23%\n",
      "  training accuracy:\t\t85.93%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 486 took 29.753s, currently going to do 909\n",
      "  training loss: 0.763556, validation loss: 0.452939\n",
      "  validation accuracy:\t\t85.20%\n",
      "  training accuracy:\t\t85.86%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 487 took 29.754s, currently going to do 909\n",
      "  training loss: 0.761192, validation loss: 0.447579\n",
      "  validation accuracy:\t\t85.38%\n",
      "  training accuracy:\t\t86.08%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 488 took 29.749s, currently going to do 909\n",
      "  training loss: 0.765266, validation loss: 0.446871\n",
      "  validation accuracy:\t\t85.29%\n",
      "  training accuracy:\t\t85.99%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 489 took 29.754s, currently going to do 909\n",
      "  training loss: 0.761425, validation loss: 0.443226\n",
      "  validation accuracy:\t\t85.41%\n",
      "  training accuracy:\t\t86.01%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 490 took 29.748s, currently going to do 909\n",
      "  training loss: 0.759196, validation loss: 0.449743\n",
      "  validation accuracy:\t\t85.41%\n",
      "  training accuracy:\t\t86.31%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 491 took 29.753s, currently going to do 909\n",
      "  training loss: 0.766540, validation loss: 0.447731\n",
      "  validation accuracy:\t\t85.14%\n",
      "  training accuracy:\t\t85.89%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 492 took 29.747s, currently going to do 909\n",
      "  training loss: 0.760266, validation loss: 0.444972\n",
      "  validation accuracy:\t\t85.26%\n",
      "  training accuracy:\t\t85.90%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 493 took 29.754s, currently going to do 909\n",
      "  training loss: 0.758184, validation loss: 0.448145\n",
      "  validation accuracy:\t\t85.27%\n",
      "  training accuracy:\t\t86.15%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 494 took 30.835s, currently going to do 989\n",
      "  training loss: 0.764720, validation loss: 0.442078\n",
      "  validation accuracy:\t\t85.53%\n",
      "  training accuracy:\t\t85.88%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 495 took 29.756s, currently going to do 989\n",
      "  training loss: 0.770571, validation loss: 0.446913\n",
      "  validation accuracy:\t\t85.27%\n",
      "  training accuracy:\t\t85.87%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 496 took 29.754s, currently going to do 989\n",
      "  training loss: 0.754546, validation loss: 0.451717\n",
      "  validation accuracy:\t\t84.90%\n",
      "  training accuracy:\t\t86.38%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 497 took 29.755s, currently going to do 989\n",
      "  training loss: 0.762351, validation loss: 0.441727\n",
      "  validation accuracy:\t\t85.43%\n",
      "  training accuracy:\t\t86.14%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 498 took 29.750s, currently going to do 989\n",
      "  training loss: 0.760602, validation loss: 0.447631\n",
      "  validation accuracy:\t\t85.25%\n",
      "  training accuracy:\t\t86.25%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 499 took 29.752s, currently going to do 989\n",
      "  training loss: 0.758163, validation loss: 0.449184\n",
      "  validation accuracy:\t\t85.24%\n",
      "  training accuracy:\t\t86.22%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 500 took 29.750s, currently going to do 989\n",
      "  training loss: 0.764108, validation loss: 0.447479\n",
      "  validation accuracy:\t\t85.07%\n",
      "  training accuracy:\t\t85.90%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 501 took 29.753s, currently going to do 989\n",
      "  training loss: 0.759825, validation loss: 0.454941\n",
      "  validation accuracy:\t\t85.23%\n",
      "  training accuracy:\t\t86.26%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 502 took 29.749s, currently going to do 989\n",
      "  training loss: 0.761676, validation loss: 0.440012\n",
      "  validation accuracy:\t\t85.34%\n",
      "  training accuracy:\t\t85.94%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 503 took 29.753s, currently going to do 989\n",
      "  training loss: 0.762540, validation loss: 0.446002\n",
      "  validation accuracy:\t\t85.18%\n",
      "  training accuracy:\t\t85.81%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 504 took 29.749s, currently going to do 989\n",
      "  training loss: 0.760278, validation loss: 0.448697\n",
      "  validation accuracy:\t\t85.09%\n",
      "  training accuracy:\t\t86.07%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 505 took 29.753s, currently going to do 989\n",
      "  training loss: 0.761365, validation loss: 0.444234\n",
      "  validation accuracy:\t\t85.22%\n",
      "  training accuracy:\t\t86.18%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 506 took 29.750s, currently going to do 989\n",
      "  training loss: 0.763109, validation loss: 0.450023\n",
      "  validation accuracy:\t\t85.02%\n",
      "  training accuracy:\t\t86.02%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 507 took 29.753s, currently going to do 989\n",
      "  training loss: 0.759875, validation loss: 0.443881\n",
      "  validation accuracy:\t\t85.40%\n",
      "  training accuracy:\t\t86.17%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 508 took 29.753s, currently going to do 989\n",
      "  training loss: 0.760634, validation loss: 0.447419\n",
      "  validation accuracy:\t\t85.27%\n",
      "  training accuracy:\t\t86.13%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 509 took 29.752s, currently going to do 989\n",
      "  training loss: 0.756145, validation loss: 0.447940\n",
      "  validation accuracy:\t\t85.20%\n",
      "  training accuracy:\t\t86.20%\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Epoch 510 took 29.751s, currently going to do 989\n",
      "  training loss: 0.760509, validation loss: 0.445307\n",
      "  validation accuracy:\t\t85.38%\n",
      "  training accuracy:\t\t86.13%\n",
      ". . . . . . . . . . . . . . . . . . . \n",
      "Keyboard interruption, user stopped learning\n",
      "Learning ended at 18:18:43\n",
      "Setting network parameters from after epoch 494\n",
      "Test error rate: 0.148300%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f299aa2e290>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEACAYAAACpoOGTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAp1X+/pflQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f299aa93ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "i=0\n",
    "e=0\n",
    "\n",
    "best_valid_error_rate = np.inf\n",
    "best_params_epoch = 0\n",
    "best_params = snapshot_params(net)\n",
    "\n",
    "train_erros = []\n",
    "train_losses = []\n",
    "validation_errors = []\n",
    "\n",
    "number_of_epochs = 5\n",
    "patience_expansion = 2.\n",
    "\n",
    "base_lrate = 1e-2\n",
    "K = 10000\n",
    "\n",
    "# training loop\n",
    "\n",
    "try:\n",
    "    print \"Learning started at %02d:%02d:%02d\" % (datetime.now().hour, datetime.now().minute, datetime.now().second)\n",
    "    while e < number_of_epochs: #This loop goes over epochs\n",
    "        e += 1\n",
    "\n",
    "        epoch_start_i = i\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        start_time = time.time()\n",
    "        for X_batch, Y_batch in cifar10_train_stream.get_epoch_iterator(): \n",
    "            i += 1\n",
    "            X_batch = random_transform(X_batch)\n",
    "            net.learning_rate.set_value(base_lrate * K / np.maximum(K, i))\n",
    "            batch_loss, batch_acc = net.train_fn(X_batch, Y_batch.ravel())\n",
    "            train_loss += batch_loss\n",
    "            train_acc += batch_acc\n",
    "            if i % 40 == 0:\n",
    "                print '.',\n",
    "            \n",
    "        val_loss, val_error_rate = compute_error_rate(cifar10_validation_stream, net)\n",
    "        if val_error_rate < best_valid_error_rate:\n",
    "            number_of_epochs = np.maximum(number_of_epochs, e * patience_expansion+1)\n",
    "            best_valid_error_rate = val_error_rate\n",
    "            best_params = snapshot_params(net)\n",
    "            best_params_epoch = e\n",
    "            pickle.dump(best_params, open('LasagneTest.pkl', 'w'))\n",
    "            pickle.dump(e, open('LasagneTest_e.pkl', 'w'))\n",
    "            pickle.dump(i, open('LasagneTest_i.pkl', 'w'))\n",
    "            pickle.dump(number_of_epochs, open('LasagneTest_number_of_epochs.pkl', 'w'))\n",
    "\n",
    "        train_batches = i - epoch_start_i\n",
    "        validation_errors.append((i,val_error_rate))\n",
    "        train_losses.append((i,train_loss / train_batches))\n",
    "        train_erros.append((i,1-train_acc / train_batches))\n",
    "        print \"\\nEpoch %d took %.3fs, currently going to do %d\" % (e, time.time() - start_time,\n",
    "                                                                   number_of_epochs)\n",
    "        print \"  training loss: %.6f, validation loss: %.6f\" % (train_loss / train_batches, val_loss)\n",
    "        print \"  validation accuracy:\\t\\t%.2f%%\" % (100 - val_error_rate * 100)\n",
    "        print \"  training accuracy:\\t\\t%.2f%%\" % (train_acc / train_batches * 100)\n",
    "except KeyboardInterrupt:\n",
    "    print \"\\nKeyboard interruption, user stopped learning\"\n",
    "\n",
    "print \"Learning ended at %02d:%02d:%02d\" % (datetime.now().hour,\n",
    "                                            datetime.now().minute,\n",
    "                                            datetime.now().second)\n",
    "    \n",
    "print \"Setting network parameters from after epoch %d\" % (best_params_epoch)\n",
    "load_params(net, best_params)\n",
    "\n",
    "_, test_err_rate = compute_error_rate(cifar10_test_stream, net)\n",
    "print \"Test error rate: %f%%\" % (test_err_rate)\n",
    "\n",
    "# subplot(2,1,1)\n",
    "# train_losses = np.array(train_losses)\n",
    "# semilogy(train_losses[:,0], train_losses[:,1], label='batch train loss')\n",
    "# legend()\n",
    "\n",
    "# subplot(2,1,2)\n",
    "train_erros = np.array(train_erros)\n",
    "plot(train_erros[:,0], train_erros[:,1], label='batch train err rate')\n",
    "validation_errors = np.array(validation_errors)\n",
    "plot(validation_errors[:,0], validation_errors[:,1], label='validation err rate', color='r')\n",
    "ylim(0,0.4)\n",
    "legend(loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
