{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 27 days\n",
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 27 days\n",
      "Using gpu device 0: GeForce GTX 780 (CNMeM is enabled)\n",
      "/home/i265983/Dokumenty/nn_assignments/libs/Theano/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "The streams return batches containing (u'features', u'targets')\n",
      "Each trainin batch consits of a tuple containing:\n",
      " - an array of size (25, 3, 32, 32) containing float32\n",
      " - an array of size (25, 1) containing uint8\n",
      "Validation/test batches consits of tuples containing:\n",
      " - an array of size (100, 3, 32, 32) containing float32\n",
      " - an array of size (100, 1) containing uint8\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import skimage.io\n",
    "from scipy.ndimage.filters import convolve\n",
    "from common.plotting import plot_mat\n",
    "import theano\n",
    "import theano.tensor.signal.downsample\n",
    "import theano.tensor.shared_randomstreams\n",
    "\n",
    "\n",
    "from fuel.datasets.cifar10 import CIFAR10\n",
    "from fuel.transformers import ScaleAndShift, Cast, Flatten, Mapping\n",
    "from fuel.streams import DataStream\n",
    "from fuel.schemes import SequentialScheme, ShuffledScheme\n",
    "CIFAR10.default_transformers = (\n",
    "    (ScaleAndShift, [2.0 / 255.0, -1], {'which_sources': 'features'}),\n",
    "    (Cast, [np.float32], {'which_sources': 'features'}))\n",
    "cifar10_train = CIFAR10((\"train\",), subset=slice(None,40000))\n",
    "#this stream will shuffle the CIFAR10 set and return us batches of 100 examples\n",
    "cifar10_train_stream = DataStream.default_stream(\n",
    "    cifar10_train,\n",
    "    iteration_scheme=ShuffledScheme(cifar10_train.num_examples, 25))                                             \n",
    "cifar10_validation = CIFAR10((\"train\",), subset=slice(40000, None))\n",
    "# We will use larger portions for testing and validation\n",
    "# as these dont do a backward pass and reauire less RAM.\n",
    "cifar10_validation_stream = DataStream.default_stream(\n",
    "    cifar10_validation, iteration_scheme=SequentialScheme(cifar10_validation.num_examples, 100))\n",
    "cifar10_test = CIFAR10((\"test\",))\n",
    "cifar10_test_stream = DataStream.default_stream(\n",
    "    cifar10_test, iteration_scheme=SequentialScheme(cifar10_test.num_examples, 100))\n",
    "\n",
    "\n",
    "print \"The streams return batches containing %s\" % (cifar10_train_stream.sources,)\n",
    "print \"Each trainin batch consits of a tuple containing:\"\n",
    "for element in next(cifar10_train_stream.get_epoch_iterator()):\n",
    "    print \" - an array of size %s containing %s\" % (element.shape, element.dtype)\n",
    "print \"Validation/test batches consits of tuples containing:\"\n",
    "for element in next(cifar10_test_stream.get_epoch_iterator()):\n",
    "    print \" - an array of size %s containing %s\" % (element.shape, element.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# These are taken from https://github.com/mila-udem/blocks\n",
    "# \n",
    "\n",
    "class Constant():\n",
    "    \"\"\"Initialize parameters to a constant.\n",
    "    The constant may be a scalar or a :class:`~numpy.ndarray` of any shape\n",
    "    that is broadcastable with the requested parameter arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    constant : :class:`~numpy.ndarray`\n",
    "        The initialization value to use. Must be a scalar or an ndarray (or\n",
    "        compatible object, such as a nested list) that has a shape that is\n",
    "        broadcastable with any shape requested by `initialize`.\n",
    "    \"\"\"\n",
    "    def __init__(self, constant):\n",
    "        self._constant = numpy.asarray(constant)\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        dest = numpy.empty(shape, dtype=np.float32)\n",
    "        dest[...] = self._constant\n",
    "        return dest\n",
    "\n",
    "\n",
    "class IsotropicGaussian():\n",
    "    \"\"\"Initialize parameters from an isotropic Gaussian distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    std : float, optional\n",
    "        The standard deviation of the Gaussian distribution. Defaults to 1.\n",
    "    mean : float, optional\n",
    "        The mean of the Gaussian distribution. Defaults to 0\n",
    "    Notes\n",
    "    -----\n",
    "    Be careful: the standard deviation goes first and the mean goes\n",
    "    second!\n",
    "    \"\"\"\n",
    "    def __init__(self, std=1, mean=0):\n",
    "        self._mean = mean\n",
    "        self._std = std\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        m = rng.normal(self._mean, self._std, size=shape)\n",
    "        return m.astype(np.float32)\n",
    "\n",
    "\n",
    "class Uniform():\n",
    "    \"\"\"Initialize parameters from a uniform distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    mean : float, optional\n",
    "        The mean of the uniform distribution (i.e. the center of mass for\n",
    "        the density function); Defaults to 0.\n",
    "    width : float, optional\n",
    "        One way of specifying the range of the uniform distribution. The\n",
    "        support will be [mean - width/2, mean + width/2]. **Exactly one**\n",
    "        of `width` or `std` must be specified.\n",
    "    std : float, optional\n",
    "        An alternative method of specifying the range of the uniform\n",
    "        distribution. Chooses the width of the uniform such that random\n",
    "        variates will have a desired standard deviation. **Exactly one** of\n",
    "        `width` or `std` must be specified.\n",
    "    \"\"\"\n",
    "    def __init__(self, mean=0., width=None, std=None):\n",
    "        if (width is not None) == (std is not None):\n",
    "            raise ValueError(\"must specify width or std, \"\n",
    "                             \"but not both\")\n",
    "        if std is not None:\n",
    "            # Variance of a uniform is 1/12 * width^2\n",
    "            self._width = numpy.sqrt(12) * std\n",
    "        else:\n",
    "            self._width = width\n",
    "        self._mean = mean\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        w = self._width / 2\n",
    "        m = rng.uniform(self._mean - w, self._mean + w, size=shape)\n",
    "        return m.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    n = 1\n",
    "    def __init__(self, rng=None):\n",
    "        if rng == None:\n",
    "            rng = numpy.random\n",
    "        self.rng = rng\n",
    "        self._parameters = []\n",
    "        self.n = Layer.n\n",
    "        Layer.n += 1\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return self._parameters\n",
    "    \n",
    "    def fprop(self, X, learning_on):\n",
    "        return X\n",
    "    \n",
    "    def name(self):\n",
    "        return \"Base layer\"\n",
    "\n",
    "\n",
    "class Conv(Layer):\n",
    "    def __init__(self, num_in, num_out, filter_size=5, weight_init=None, bias_init=None, **kwargs):\n",
    "        super(Conv, self).__init__(**kwargs)\n",
    "        if weight_init == None:\n",
    "            weight_init = IsotropicGaussian(0.05)\n",
    "        if bias_init == None:\n",
    "            bias_init = Constant(0.0)\n",
    "        \n",
    "        self.weight_init = weight_init\n",
    "        self.bias_init = bias_init\n",
    "        self.num_in = num_in\n",
    "        self.num_out = num_out\n",
    "        self.filter_size = filter_size\n",
    "            \n",
    "        self.W = theano.shared(np.zeros((self.num_out, self.num_in, self.filter_size, self.filter_size), dtype='float32'),\n",
    "                               name='CW'+str(self.n))\n",
    "        self.W.tag.initializer = self.weight_init\n",
    "        self.B = theano.shared(np.zeros((self.num_out,), dtype='float32'),\n",
    "                               name='CB'+str(self.n))\n",
    "        self.B.tag.initializer = self.bias_init\n",
    "        self._parameters = [self.W, self.B]\n",
    "    \n",
    "    def fprop(self, X, learning_on):\n",
    "        return theano.tensor.nnet.conv2d(X, self.W, border_mode='full') + self.B.dimshuffle('x',0,'x','x')\n",
    "    \n",
    "    def name(self):\n",
    "        return \"Convolution layer (%d, %d, %d)\" % (self.num_in, self.num_out, self.filter_size)\n",
    "\n",
    "class ReLU(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ReLU, self).__init__(**kwargs)\n",
    "    \n",
    "    def fprop(self, X, learning_on):\n",
    "        return theano.tensor.maximum(0.0, X)\n",
    "    \n",
    "    def name(self):\n",
    "        return \"ReLU layer\"\n",
    "    \n",
    "class MaxPool(Layer):\n",
    "    def __init__(self, filter_size=2, **kwargs):\n",
    "        super(MaxPool, self).__init__(**kwargs)\n",
    "        self.filter_size = filter_size\n",
    "    \n",
    "    def fprop(self, X, learning_on):\n",
    "        return theano.tensor.signal.downsample.max_pool_2d(X, (self.filter_size, self.filter_size), ignore_border=True)\n",
    "    \n",
    "    def name(self):\n",
    "        return \"Max pooling layer (%d x %d)\" % (self.filter_size, self.filter_size)\n",
    "    \n",
    "\n",
    "class Flatten(Layer):\n",
    "    def __init__(self, dim, **kwargs):\n",
    "        super(Flatten, self).__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "    \n",
    "    def fprop(self, X, learning_on):\n",
    "        return X.flatten(self.dim)\n",
    "\n",
    "    def name(self):\n",
    "        return \"Flatten layer (%d)\" % (self.dim)\n",
    "    \n",
    "class Affine(Layer):\n",
    "    def __init__(self, num_in, num_out, weight_init=None, bias_init=None, **kwargs):\n",
    "        super(Affine, self).__init__(**kwargs)\n",
    "        if weight_init == None:\n",
    "            weight_init = IsotropicGaussian(std=2./np.sqrt(num_in))\n",
    "        if bias_init == None:\n",
    "            bias_init = Constant(0.0)\n",
    "        \n",
    "        self.weight_init = weight_init\n",
    "        self.bias_init = bias_init\n",
    "        self.num_in = num_in\n",
    "        self.num_out = num_out\n",
    "            \n",
    "        self.W = theano.shared(np.zeros((self.num_in, self.num_out), dtype='float32'),\n",
    "                               name='AW'+str(self.n))\n",
    "        self.W.tag.initializer = self.weight_init\n",
    "        self.B = theano.shared(np.zeros((self.num_out,), dtype='float32'),\n",
    "                               name='AB'+str(self.n))\n",
    "        self.B.tag.initializer = self.bias_init\n",
    "        self._parameters = [self.W, self.B]\n",
    "    \n",
    "    def fprop(self, X, learning_on):\n",
    "        return theano.tensor.dot(X, self.W) + self.B.dimshuffle('x',0)\n",
    "    \n",
    "    def name(self):\n",
    "        return \"Affine layer (%d, %d)\" % (self.num_in, self.num_out)\n",
    "\n",
    "    \n",
    "class Dropout(Layer):\n",
    "    \"\"\"\n",
    "    https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, prob, **kwargs):\n",
    "        super(Dropout, self).__init__(**kwargs)\n",
    "        self.prob = prob\n",
    "        self.rng = theano.tensor.shared_randomstreams.RandomStreams()\n",
    "    \n",
    "    def fprop(self, X, learning_on):\n",
    "        tmp = self.rng.uniform(X.shape) >= self.prob\n",
    "        return theano.tensor.switch(learning_on,\n",
    "                                    X * tmp / (1 - self.prob),\n",
    "                                    X)\n",
    "    \n",
    "    def name(self):\n",
    "        return \"Dropout layer (%f)\" % self.prob\n",
    "    \n",
    "class SoftMax(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SoftMax, self).__init__(**kwargs)\n",
    "    \n",
    "    def fprop(self, X, learning_on):\n",
    "        return theano.tensor.nnet.softmax(X)\n",
    "    \n",
    "    def name(self):\n",
    "        return \"Softmax layer\"\n",
    "\n",
    "    \n",
    "class Predict(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Predict, self).__init__(**kwargs)\n",
    "    \n",
    "    def fprop(self, X, learning_on):\n",
    "        return theano.tensor.argmax(X, axis=1)\n",
    "    \n",
    "    def name(self):\n",
    "        return \"Prediction layer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAACjCAYAAACuViRsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsvWmQHed1JXjfvtWrfQUKQGEHAQIkAXABSZHgbpFaLMmb\nZLdbliesthzTMWFN9ETb7p4eT0x09FgejWfs7rbd7pYs25JNSrI2yyIpiosoruACYl9rQe171dvX\n+XHOyadMvBIp25BUPXn/ZL1X+TK//PLL/M6937nnBur1uvnmm2+++faTb8EfdwN8880333x7Z+a/\nsH3zzTff1on5L2zffPPNt3Vi/gvbN998822dmP/C9s0333xbJ+a/sH3zzTff1on5L2zffPPNt3Vi\n/gvbN998822dmP/C9s0333xbJxa+xsevm5lVq1UzMwsEAk13CgYxbzz++ONmZnbp0iUzM1teXjYz\ns0gkYmZmR44cMTOzQ4cOmZlZKBT6gceVvfzyy2Zm9txzz5mZWaVSMTOzQqFgZmaHDx82M7Ndu3aZ\nmdlTTz1lZmbFYtHMzPbv329mZrfddpuZmaVSKdf/FxcXzcxsYmLCzMympqbMzOyRRx5xtSPc1obz\n7BwyM7N3PXyrmZm1t3aYmVlvusvMzAY6Bs3MrKO128zMouEYfh/k7QoEucE2HA67tuqNQB1/1XAb\njB+tUq/hM7Nca7Waa6t+qZbxOZfPmZnZidNvmZnZk995Ev/neUZGxszMrFQqob1R3K8K7/vszAx2\nzK64+uPm9+1XS9H+Gq4nk8mbmVkk1IL+6N9oZmY37b/BzMwuX7hoZmZLK+j3m28+xP0xHpbmF8zM\nLJXAferr7sf18Xr7N6B/db8GBzaYmVlvTy+OE4lxf7SuWCjjOH04TpDtjYQj7Af2UyljZmbDI8Nm\nZvbq68fMzOz4qVfMzGx6DuM6FMF9+u7X3nL1x9TkgutzhPst5XE/Fubn0U/8vqOt08zMKrwR5QLG\nY1sK/RaLRs3MLJPLmplZPreKHSvo32oR7Z2fGMf3HB9t7O9EJ/oj3tKKduuO1zRuNALq/HmI/RN0\nHY//thrHnUzPvXbcsLHL9f87b7sR173AcaPxynHV1ov9y2xGItVuZmZ79x00M7PDh7GNptLc4nkK\n8jlZWcBzevnym2Zmdv7cG2ZmdvL4cZynjPdEnPe5jf1QruA6lpfRriz7d/fu3Tg+30djV/BclPlc\nLK+g/8Nh9FN3d4+ZmaVbEmZm1hKPsp9wPY8/+cJVL7Zr/cL+oWxwEA/SmTNnzMxs27ZtZmbW2oqO\nGhgYMLPGi1ovnLVe2HrxPPvss2Zm9sYbuCFHjx41M7POTgx4TQB6kZfLeEA3bsTA1YtQL2q92HTe\nri4MnJ4e3IDrr7++aXs6enC+W46+z8zM3n33L+B8hvNVQnxx8YZVME4sFsMf9Sr+XwxhhBYz2Obn\n8aCuGF6swRoe2FIJ31f5YGngVNn+Ok8U4ghpTyTNzGygE9eT7ML3LzyNCWx4Dg/4bT/9MTMzmxo/\nh+MG8QJfWcEAnueLpb0D7egf2GJmZm99z/2CCgbdL75yHv3vTBxVHO/s+TkzM7t46QT+X8X/Q1E8\n8OOPD+Mz3wwt7K+2VjzA1SJfqDn0TyjICYX3u6+/z8zMYrE4v+cEVsXxevsw7nbvxAM5O4eJorcX\nv8vk0S9T03hAJ6aumJnZ5DQmqkoVD2p3Dybm6hpyEHoB6kWm8VXhGykU4oDge6/ijENO3HyRBziO\nilWMq3wJ1z0/iYnuwosALuffwv0YncaLK8/rjrUCWOy98WYzM9u2+zozM0u3Ynxs2oL72dPby/OF\n2H42z7k+bWuezwHPtnl/VEu4P6k47ovGrTOO+bPdu/eh/UXsPzmFCejiZfT35u1of0sHjtPbixf3\n0twI9jt7yszMLp3DeC7lMaG1teBFH+b1ZbK4zwECp3IZ7dAEonEfi8Vc7axUcB+CAd7fAI4XCuIC\nihyXPe2cEHgdzcwPifjmm2++rRO7pghbSPVP//RPzcxs69atZmZ2//0PmFljJg4EMHMm6cpNz8ya\nWcMFfeihh1zH8wpWCZF5LUqX8Dd/8zd/qHZ/4hOfaPq9EJms4dKZq13e72VxItjzF86bmVm1yhm6\nhm2YyE8uWDqJ9q8uYeZuTQD5pEL4PhrBdYfhUVmWSMqCDClU0Y+z00AcHR1AHIMD6NfNfUCI7ez3\nLnoySYY08gxRDJ+/wPbhvHUi48w8kG9QripdSH0uF3ldqWTT/uhoh8dRIBLJZ4q8LoZ4Qjh/ugXI\nqEwEKo8hRASaJKIulnDdYfZbLYLjlkrwtJJt+H5lDsi9JY3rXlwGEs7TI9G4qTDWMDF32czMLk2c\nxnmImBK6Lg6/bA7HrXCcBugBtMSxXyiG6xJy9FqAiMs7vnNZtCvE+y7kVqdnFKDHFYqiP6r8XChg\nv2wR/XLhDEKDJ598zMzM5iaXzMxssozjzK7CEygX0f43n3+BxycijKP9W7ZvNzOzO47eg+299/L7\nHWZmlud9D0UUykO7HFwdUGhPn5s/L3re1B31mjuUF+Pz0NUHz7wsyM1+HJ2YxPGj8LS27bzBdb7W\nNO5Lawu2gQp+F67TY+HzWHVCqLiucjnnap888Fw2y/0w3kIcv3XGIoPsxzhDH1UnpARbXcX4qVXW\nFuTzEbZvvvnm2zqxa4qwMxnEfC5fHjYzs9HRUTMz6+sHwmtlrEwx6WeeQax5fByI8IYD++37Tfut\nhWB/4k3IkwgpEsbMm4oCImtG1nZuGotiL33vu2Zmtm0zEMzBmxBzp2Niy3kgo/PnsHiy7wCQRFsK\n/dXfhZjjls2bzcyspxMxvA4hP3k6DrIDwlpcwOceIuFYBMjg5TdPmplZiYsocbY/uzLGduG6chkg\nkRUusnjtqb85xn7BJkgk8u734TrLXOyrcDGrREiWyQNxpsJoT1sCwzhfRztfegoeQT6PfhaiqnkQ\nmmLE73w8jbo+6Th1xtTrnsV1IeAwPRZ2y1UI2muBoDu2q0VfreWY67/fdz4et0JPp1QE0isREV6Z\nwnhaKaP/SkTiq4t4ToNl9EMijHFRJvKuVxQ7BoI8/ZoW5zAOHvvCF83M7LrrsWi/aTMWcY/e+6CZ\nmW3ehRhzJImYcMjTD2txBmLstywXoavsZ+2eSGMcT8+j/e1duP+5ApDq7r0479AQtqkWeFT5PMgM\nL7/0PTMze/1VLApXCkTMAXgGSwsY3yGtLXH8a9Ex4Cz+c82AnkULz5NK0TMs4z4E9Rjwd/L84rzO\nYg6fI/Skmtk6ffP55ptvvv3/z64pwhZrQKuppRJm1P/2X/+bmZnVRediDEgskQHSrLLZnOt4ogeu\nhVC8yOmdFmdYa/+3owv+sBbkFDs9DhZBTw9ia3nGrkKGGT6fBaJ47jtPmJlZqYDP8RhjYGHMszkG\nT9tbwV551603mZnZnn1gqfQm6vxd1HU9irEZWQRGhFAlZhOyunARiHKZtMVEkjFJxtyLGbS7mGOM\nlavniv3lchlui037Q+1xtvQYkhEgk3wJX1QZ04twv3QU/0+TZhUlgp9eZgyWl2V1N73sh0fUzc1B\n1twO0XO5/WbQNMUaeuNNINHnX3zRzBqsDbEIvNYYb7xu9vMS+z/C50TtF6IPR3G8ihPjJyJmrD0e\ngQd0+MjdOM8kkParjFGLPROuY5wICcaI50SDK5kQPGPoZK+MDQ+bmdnoJbAsNg9grWT4OK7/4J33\nm5nZXe/5GTMz6+kDm6oW/MHPVziE87a34zlZJY1Oawh33XufmZl196L/c/QoLo+cNTOz/o2bzMxs\n2/ad6Ic4+uHkCSDq144hpl+v4rkLMbYu2mu1qveJaLNcY9J48rRXMe1INMzz8XkhG6tWR3+JfRTm\nfmnST0PsTy/98fvNR9i++eabb+vErinC7u5GjGloaMjMzK5cAbKcJj+1UBRPETPTnj17zKyBNHp6\nul3He6eI950i7Xd6vH8qpK0ZOhJFjDCTwSr92RMg6t96I2LPrZ1AjkffdbuZme3YDnbN4AbEomen\nkWAxNQPkdeutB8zMLJ0mgiYJIc4YaiXHL3gZ0SBibDUiqVyFiImIJsvPwxPTZmY2xkSQDQO4H9u2\ngJ+eagWCOHMOsUytbithQEChVvvBHpH+GyK0qzHGF0kAEQWJTCIB8pCVMEWkmWWse3GZPG7y1b3k\ng38yj4nXc+C6vWZm9s9/4cNmZrZrF2LvQXoa27eBTbFtJxDeiy+9ZGZm586fb3rYalWsCCE8fL/E\nBLI4+6Ozo5P/Jzskwv7gdReINHU/UnGsFV1/wx1mZnb8iWfMzGx6kZ4bY6hdacSYFUMViSHIzzNM\nfMpUGANXe8WGMBynQLbPzGVc57c4jvIcmB/46K+YmVmaMfm1ns+egY28DvxueQUeW7iO603GgEw3\n9g+ZmVlLF8an+ONhJpxFYui3Wg2exNw0+Oj9XeiXlkF4RAtzaOfMLNhV4Sw9IrJj6lzbUeJUyFmr\nwP2K0LNLxfA5HqTHzPbXCswTaIMHkqviPi2uYm2gqwX3VR5xM/MRtm+++ebbOrFrirDjzFBSTE8x\n7dlZ8HfFq1YGoVLRV8kH1arr3Bz2b2Nqtxc5vx2ifruYt8z7+3/qGPbyIhB13wCQxego+L0bN4A1\ns2cnkHQ4CgSx77rtbJhScvE9gZTFO9Bv0RjnXfKAY0ESs2uYqSO8zYppnjmDWGOIKbEXR4fNzKy1\nC7HFjh4gm0gSSHzrbiDHnVsREwwyhn6eEgJbhrD2MH8IKf6f+9znzMxsnCnP2WyhaX94eeu6Gwsc\nJ0lKEohNU2LsNEe+dI2/qzElNLdadB1X/XZ1tPEfZmUipcMHwdL53d/6HTMzG9qANZevfOXLZmaW\n4drLJiLsT37yk2bWkFz4nX/zb8zM7LXXXnIdv5DTmg1jnERaem56mVkoE088ZG5WSpU8avHho8ys\nSyeAoHs2YpwFuWhwYCfua4ZIbzmH34foEYYi5C1HgADzNSDzwjLaW6dnlK+Thx/CuNy1EZnKq1yT\nefyLf21mZps3IeZ81yPvMTOz0hqx7DjZFldGkJFYoacV5nM50I9x18kU73oY75sAWR4hLWFwHCzO\nI3Y/fmUYx6OHMDWN987szDz3x/MinrfWHDIZvJdy7F/lESR4n0QCKVJKIMTx2ZJAe2NxIOsSn8dV\nesh9zIdIt+D/WqtoZj7C9s0333xbJ3aNtUQwsywtcZWbGWyaUSJc3d6xAwhOPGutWksM6tw5rPo+\n/PDDZmbWTx730hIQq5P5pBx+Inchk3xePE5qcFC0SbxWIRdplSjT7Z/a5DnkC5fYTrRjzx6wO2IR\n9FeZMcJy1Y30l5fxfZCry6F2IJkr5GtvTmL+jcaVSea+vTmyUd564zUzM6sy9pkpoL8HyHNNxhlL\nI8JZXUbs8DnyVrW6/dWvfM3MzFJcfZfGxCBX58e4ZlEquTO6ZMkkYvmFvHiqaH+ZiKgYqrN9jMlS\njCpI5Jegx1Vcwn6lHNZGHE2O5vTvH9rE304yhvxJZs7edz/YD0Uirw9/GNowUfLSo+w/sSHEgvr4\nxz/OrRthSyxLsVECQMtw3EhDJU/WUJIZcxLVqJJ/rQzTGD2UZIKZikKoRMxbtmC8334Y4++JJ6Ex\ncmUSsdwykV6CGYsb2hEjHkzjuSkAmFqhguNVAxhH2aIyMfH/nduGzMxs5GWwZU68/qqZmR244060\ni5m2XuvpxnO5Mr/o6gdB2XgbPHeteYTpMSgTscB+iiTQD4vUTOnqwO+u34c1CJGlXn0RrJYiPbhG\nhADX3ca8kYBSW4mgU+SXFxijn50DUp+5grWd7DKez0Vm2C5nMJ77+uCZ3XEn1haKK+TLj4417Q8z\nH2H75ptvvq0bu6YIu0Qke4HaGUvLmHmiRNa7mQGVySB2JnaBkPDcHFZrT56CStsctSuE0FuopqVc\nf6n8iZ0yQ1nPUglTqJC7Zs4DN9zAlgKhdHYihvTgg9Au6SPyVs5/UJlN/8DYNgGO1Zlh1tFJNTn+\no0QtjMkpaCAsrQLCdFMVrlymSiEzFF+nytj2ViKBQbQ3xv9biDFRtjcUw/3YtQcx6iBT76JEIMlW\nII9FrsYH2S/jk2jPo3/1l2Zmdvg28I0nqfkyQXnVxLHX0d5usXsYc68055UeIW/5299+0vV9khli\nVQ7PYkFaGfh/PIn/B8lLn1rEfc4VMI6kyfF2sWvvGojXdJ81Ho/cfIuZmb3rVsj8ZlbRT1IJHKC6\no9grJXp6GWpMFKkdc889d63RIsby2WzRxeUhqj1ZHi8WkUqeMjixlYeYpNZJOE72Rg4e6co8EHSN\nJ5qfw/eRQJzf47hZekZVshniVey3Y/tGXg/2W5zCOA0FcN4S2zMyi/P0bwWS79sERLl1L9hg0kZZ\nSztjE/ntly/i/VGgJ5glQk0SKRfpkQ5fxtrM9DQ8u9wC3jdbN8Mjn5nDONZoDEW4dsbxnikIoeP/\neWYk5wp470zN4Dor1GYpcw2hu49ytIxBpzrR7qEU3nOzo7zOENqTLWNtZ56ewxNPfsfMzHra8Nzc\nc/da48NH2L755ptv68aubaYjY06XLoP3GItjfqhUMZMnk4j1nT4NpCgELF1ZzbtiEUgw/Dh1fBUD\nrRBBq1CBMqOENFoYc9OqeoKxyCUeT7rM4u1eoED+L//yL5uZ2dDWIbTnH8kecQouSF2QiEi8z41t\nmJGrDKp59awDzCDU2fNEFpUgfrc8B6SZ6kSsrUBNBfWrtF2iSfJnV/D7pRkKsS8DQYUiQPS1srvA\nwYaNiMFet28/24PzvvAsYp9i+2gNIZFkoQexO2zJ1R/vYYGHF15Axl2WCDlcx7DMEPkEzK33LE2H\nvNhEZCEo0897e9a6b++UPaTY9YP3QxujxblO6XfjegsLaL/YGnOzuB9lBqN7NwBptramm55XvOcQ\nY8faVhi7VuZcjjH/uoffrkxaeZAa5+ao9wEhFvO4D1lmoC6vov9CxJ4k5ViYmXciIW3cgOdqyxYg\nwVMsuFCp0SPjfalS1TFLffGuvShE8MEHoQPfOQAE6qj6VZsvNhSpargwh/NkqF1TFQ9azy37v1TE\n9T377W9h/3n0/9gQEHD/ID1zrn2kmCkbTwIZF1/EOJxbxPMY5RqAVEU1DoY24znI5aWGiOtfoCcU\n5/O2pR/HT3fhvseJoBNt6MdLZL/sP4A8iiBfx8FI80xY7OObb7755tu6sGuKsLNZzIhL5B+3tQFZ\n9PeBRaDYnJCyEKgyIgUlhRCFNIepXaDfbxsCr1SIQpmV4nULManCjNgaQoSKlU9OIrYkvqzO+6/+\nl39lZmZ9LCGlChNryoytYUKeNSLoFmaWXR6BZkdXnLxk8XCJKHO8TiGu1jSQi3DJyAT6KxFEu05O\nIaZcLOP6FfMssoRUntcVzJE1w9hgogV81htvgF55kHrYJaqISbtjaYH0AM73m7YMof2MXet+T3EN\nYY1ER7vpJrATNpDHfOYC2EClLJCLNEV03XUVXKFnIpXDGDML9b03gu0tJectjdbgbZtrP/2/vx8I\nSaXktGZSq2H74vfAnilRVe82xrqffQoZhQtLQIi/+Ksf5e+as2ZKqiwTceTszMyRerFQ2K2n7LAg\nIu4KTLpeWY6qcHMzGN+z48NmZhZmT2WziKWmOP62UuNmmXzyZAzPZ64MNsfTLyN/YHwWx41FgFiD\nZPVE2Z6Wfjzn84bnLMBtMId254sYH23pjqb9cYV61vOL867+kF53ZhEx8gtn4HFfGcZzOzuB5ynN\ntQ7xruMtGCdDO8GPP8K1iLkFjNeWFAZY0PBctvN9MTEOlke1ina3d9NjZ+x/mfz1FEuUFUt4PhaX\nMH4G++hR0MMZIisunsRx9tEDCRNZL3GNoZn5CNs333zzbZ3YNUXYUmvbz+KpJ0+iYkcijhlshDEc\nVaKZZSxXvGjFPsVPVQxWyHjvXvAohbDHxoAsVUz36aefxvmohuXlV2v/3l4gy7ErOI/YI8rUe+zR\nR83M7Dc+8Rv44T8whn3XXVBLqzL23EF+57Fj4EVnpoEQalqd5vVv3Izru+U2VPgIkne7gRleT3wL\nMeRlahesSnCYrBNBTjVbusJa1RdCsxBm+JL0kFlctJPIeuwi7tf0NBDZDFfhe1gMNcL7oxSzPvLa\nxbN/5htfcvWH7mMfWTDnLgJhp9uB2JThWCFffdXh07MWZBS/lxqgrkuCy46qtHSqnRKD5HOrIaoR\nukZtwV7W6uxTRp00NKi5Ms5x1EFe/xmyovqYwdrNWp413s9AsHkFHrEYOskekrZKZxeOOzl5xbX/\ntiHw3qVqJ/aR1OIUO88yA3TkLFgUbUY98TzYDzsH0c5oD9rVH8OaxmQO/y/kyfZhjHquhH63NM7T\nG6Red0LnRTuWZvD7F779bTMz27AVyLaLNRWlh7+BsX2v5RmrVxFusXVizCz868/+Cdozi+d0N5Hz\nzQfx/M4zQ7peY6yeeRtLHLdBekimCj70nFao+ihd8UpRmiI4bzxBJF1ZYv/g+H3sv8oCPKpADe+5\nAEtCBcjaWuZz8v4PfMDMzNraMa4uXITn0lJqrm5p5iNs33zzzbd1Y9cUYSuz8ZZbbjMzs2oVn7dt\nhXqZeNniVSvGvEj932VmKm5hBp10nIWUlfl08SJYHWKX6PMEY2BC6NIJFutEVdQPHTpoZg2tEh1H\nfOIXqGd8lDXs9rCcvWKc3pjhWvbQQ4gNq1qyNBFuvAExrOwsYm9CYoLEUveSmpuqLO8YZGzsCDLG\nwozpFckSaCESVX/FuWofImLJsV+SCfw/FsN5CtkYT492bNs0ZGZmP/0erPKvsrbdayeRyXXrEWhr\n5InIr4yj3+URHboR1+dF2EJOHbzvMfKF40npdzMmy1qFWSJtIWdlumZ4XidmTRyyjWsZtx9BrDJB\nfvqJE4h5vnUC/P7FFcQWA6r4I20TxkxTXGNJJsj/1gUwOP/Qgw/y+nFf/td/92/NzOyeo+DTfuC9\n7zczs4r41dHmLIDzVPHbtAUeVZ2aGF2spLK0jOfi0E0YrxtZm7PuaHi48VdAevNs55WLqMRTK6O/\n3vMIxs2hm8H6eeNxsKzyZHN1bATyHRvHc/jiCBBgibHaCj3ogTQQZEcHYtwTC2hnpYjnc+IKzreU\nRT+nO+BBtzPvYY6I12vywPRcZljbtMyMwrlxtGf0CvqtNYn3y4H9GI/Km+jsbWeHYLz/3Id+1swa\nGYzPPIVKV3nyu7OrzLytib9ONgt56nPzuJ7MKo6Xz5LtNYn2VYiQk3F6vNTSUUxcNVZnZ4HEBzfj\nfai6AEFfS8Q333zzbf3bNUXYUVYGuYmI4PQpzPBPPIFKKo+896fMrBHLfuYZrKoLsYrH3dcPBD5C\ndohqprWRz7jImJEQcYkxKSHLXYxxrxLxjfJ8Ym2cPYvYaQ9ja0Lge6l3PDKK/Z9l+3YyJvvD8rHH\nxth+rkYvsPJHOgQEl2DljGpdlWeUuUe2BmO4OSKXVSKnLZ1YjY/28PdsV4wsgioz2iI1Vg5RBt00\nEH1mEscL9uMfGSKNAFX/0m2IoX7o/e81M7Ml1mq8PIZ+ec/9qPyh6utvnETG6d99+2kzM5ucmmna\nH+o/8YtTLeShs9LKMllG8jTyBVUPV4afR5WRHk8reff/0//4L83M7Bc//BHtYWZmM/MYL1//BrRQ\nvvA3f2NmZidOAnErM1Hta9QSdbNNxOKRbrs8u6VlHP/UKeic338P1i7S7Yj1B0LNcdLYGMZDmDrP\nqTZqulDXOamMVnpcisl7PUdlPMa0ZpPHuL9yAWskIWpWHP65d5uZWbmAfl5eUTVwPBe3HEYsuH8j\nayBeQkZenhmMXUS+3a2s6ZnPsj34fVFsmAjGd5aeUC24witGf0apsue1kydRGSZDFcq6KsJQ7zvH\n2oy9fUDsGY73S1xT6OqCBxKOSncb/fKlr0CjSBnWZ85hvHYMIJZcEdINoN09g7jOMFUqa9T93rEX\n/OkoY+pBtk9rPno/ZVXhyeixduB5NbKbvvL1p8zMbOQiPP7MIsbBJ//FR6/qEx9h++abb76tE7vG\nethACtJ53UbVri99+TEzMxseAeIWghFLZNMmzEDtZAsIOUj9TQg73MUZmkhi/37E4tLkN586hQzK\nGxlDVdXkz372s2ZmlmXMUTHzHBGCeNyqVq0q56+wuvL734+YpFQD36klGZsNczV/lgi1IwGEliWP\n2rjKf+Es+qe3AzN1KyvVrJIfmyJ/dWUJ7Y6SpVCmhkuVawRVIsPuJBBejgi+RvbA8jAQcEsL7le9\nyEo17Fetap89i/sjjYUVxipHzgFZXn8vYvzxg/CogjHch0sXgWD+0tMfUpeTRxEny0Ax5aLU57Ra\nL7W+kBAk2RYkaA+SbfCRj/yimZkdPXoUxyHC0TgaZOz3o7+ETNZ778J+LzDT7XNf+LyZmT33XbBv\nFFt01irEi+ZnVb9emAayu/UAPLNuskqKWfRfkh5IjM/FVcYalGXy4oMVHLfVqcKN30mjJxpRu9wx\nd8fzIDviygWws+bGgYxD5A1fOAf1utYOIORSDf2Z6iRbZAgeWyQJj2HfUCf3I/shjvE2zgxbldIs\nS5MjIPYNTDxyvXYi5Nlr6zUhcmmyiA2jDNqDhxCrHqaee5iVZVKteF6klZJhHkGKvwuQDdXdi+vY\nxP6cW2HsvQqPI8B2trR0s53o5yTXiNrb8ftWxuLDzPyN1N21Stt4/6JcQ4rRo4wzArGVEYDTnRjH\n33niK037w8xH2L755ptv68auKcLu6iSiY+z1ppsQE7vxRsR+jr/1ppk1VoE3U51L26FtmHmkNdFK\n5KyMR2XwKeNRlW2UGSeWyTIRWz8z6jZSVU3IXLzvrfQAjhwBq+XVV4/hPMzMMsMMrExIZeiJH/p2\nMe0OxoKNFTtirJLeT13r1TqQxBwRUJxQLkt93XkijEl6IgcOonZdawIztjL9Wloxo5eZGSj+cr4A\npFcJCwHgeIqVlqiaFpCGAjPXAlHxmllBg0jxltuApGMx9TeQWI2xubFR9NP01ETT/tBaQ1VsDB53\nlbzqAmt95IswAAAgAElEQVQ1Ojrm/BxPAAFWA0SgCfzu1z/2CTMz++WP/nMza9TQnKWqoGKYQtoR\n/n8rPSrlA+zZCxXJT3/602Zmtn8/qtArVildalXeKUkFkrf/brJSQsy8FQLWmklUWjIe6+3Ffejq\noNYFVRTDLUCM0rqpVVVZR2weaY6gn+QRSiNnJQfEGAqwP+mRPPp1PFcHDqAyzIYd2ArRzy7jeFdm\nMG7SjAnPLaHfpxZxv+fJGsoTqZapsSE1xQp1qo3kGLFaIszobG9vrod93V5kwr75EtpZIX88wBqU\n1+/De0QIPsl+2rZ9L78J6oS4fvZHmu8bsaa6u/HeWGXm764h9NccMxkL0rhR5SM+RxfPkA3FtRWp\ncRo9VPG6a6YMZraK7ydpKSnjeXAQHuJ91FxpZj7C9s0333xbJ3ZtWSIxZigxo2jzFsSmt+8Akplb\nAPIR/7pcUi05rsoTmUjTQ5mNk9RnlorWMiuptDFW2BLAjO2o3RF5rFBbRIj8AFWyVHlGM21nB6uD\nbwXiePNNeAKKZYq/LS0MxRZrayAn2StUE7z9Nvwus4DY3xwRT40xMi7SW5yx55C0SxiLq7P9QfKS\nw9LZlgRFCf0iDYmlVSCFuGZ+IpswEXWNscY8M7qKIVbFViYYY+4jk8NmZradVcAHNqCferrFX8f1\nFImwn30WrIIr5O96TTzrOMeJWBdSY9Nl11XenUglnxWiw/Xddxf47R/5eVR8aUu5PbFesn+8lW3q\nJi0RnQefbzqAtZD/+1OfQjt533X/axxXQlBVtitGFb6wYpSsxBOmJ1fh/hVmSHptxw54lp3kXbdx\nDadSZn/wfgTD9Hy05uHodhPhMpNWnma6GzHWXbvgWc4MYy1obA5I8uRJ8JgXNsJjXMygfSNfw/M5\nT48vS1XEIhF8hbHyQkH8eLSnhR5fkPeXt9VqbG+I46mzE8/p9u2bmvbHgw//NI5P1cbXn38e52c+\nwt9+6as4Tg+ur7cPKnrygGam8Z6YpIc3R0+1Tijcxlj3AFUopdoXJatlz07kf0xNjfI68f6YZ/X4\n1hj6PUV+/xSrwxvXWtL0BGOeKuh6b1VK6P+FaTyfC8wr2Ld3e9P+MPMRtm+++ebburFrXNMR5mTa\nEXloFVs1GIWgpdqnGfw1amyI/TF8GUhNsboEV2sVC1VMW7UchXil2hcIuOcnxfqeoeaIznvpImKv\n994HfrFiq0LoL72EWnwPPYTKNDuJON9OLztPDyDCGOpbrwFxT6cxgy9l0O4z40A2Ytlso1pcghmf\nEV5XoAzE2JGi9gb7L8KY2FQG/ZtnhYxgiednpl1c+sWMzRXC4s/i+FKjSzDWli/hPhUrOF6CtQJb\nWCFmgJobM0REZcb6wmskgq5mqLkQYKxPNQ0V8xNfmbHHpPSwqZe9dz9izb/8z8AKaaUOuLQsIjxx\nQqyEINkIbI9T+zGox8DNtlCNTyEiZTLqgoSwVV28hZ5ZWNokjJk7yJ7XVag0ryIvdpJXz3p1RRm+\nOI+eG5li4/IkK1KFpOdQ4HOxnZVi3nUDxuvLL73M31P7g7HnU6ehOXJynBVSmKEcospkK9lOUd6e\nCHnXnR3yKFhbNYTrKPNzmJ6U1oyuvx5rA/KcvXbw5tvNzOwsPdyXnkFGomqQrlC/PUKkmyOb6fw8\nWEmvvorakTVmOEbpcQR4f1b5+5lZsGXU7wdvBPskFQMCf/ABeMR796HfpsZmeZ243mPHwbf/9uPQ\nTKGkj9O+IGP2adX45HjKGmuVchxKp3v7jl1N+8PMR9i++eabb+vGfiQIW4hFCHrTJsSMTrHSjBCJ\nYslTU5jxvJoRyuiSRoV+p5lRWyFtxfa0/worVqgijXjdOq/YKSOjQLzS5RbSmWHV5WPHwB6RLvc7\nRdjG2FqOGVaqeGM5Vv1m8FpV4vNEPOnbgDS2kfe9wpj0s08iY7Q9jesZvQKNggRj8TVm/EWi6KcB\n8j5DGXzuoupYKApEngq7tUcWiaSXyLPdsxsz/1lmhtVYEaRdmiAt5PEmgahCjFkGrXlsX+yRRbIN\npO4YC8GzaOnANssYao5shK5OILQH74UHtPs61Ah0MhOFpHgesWcatlalGWyDHi2RukczJsCYeo18\n8LBTnTzJ3+H7RY5bsVGEjOfmm2d+ahzq/LoPDqAOuNuh86iSkqPv7VwQ2SxEwL09QHD79yJTt6eH\naodcS5pdJjspjvve247zXJ6A6l0kifGSYIw6wvZ0tiEGvYmqf+Oz8ESPj4BVVWY/pql2N0SVwd3U\n5JGWkNf+/e/9npmZFagPHSNCLZNdVSyivaMjGD+LzAvYtQdsNKliiiFeqbs9NGUET/K5KRSW2D94\nD7Sm0U/lIjyN0UtA9jMTOO/kFM47zfG7bQjvtcIKKyAxg7REjyqX1RqGKgBJz5y67vQ0n/8uPIlf\neu/VtR19hO2bb775tk7sR4qwhRiuo0bH86zU0dGB1VkhBCHW44wNKSOxhzHS6WnMuFq113GL5IFK\nU0SIW4i9vR3nUabk5AQQ3s23oEKIMiKlky31NPG7xToQ8p6j3u47NSE+xexbOnA95Qxm1knG0hTL\nSncw1sYY9LlLVFvjKnm6jfxV6n2ffAvslROsSZkjot44AES6tw8IKJPHzJ9m1er9N99hZg0kd3oE\n/TLKzK8Hf+peMzO761bE9qZZ4eYka2vGueo+yX7btgf3t1QUf715hZWFJSCxySnczww1SlqopdFL\njY75CBDMwhz2T7IyR1srNTUc3OFGzl5kHbhqr7Wqprs9JCF3Id+aKtMEVcHGXNtiSTUGySbhuI4q\nJs3r9Jra4cSiGSNv6LhXXO1R7FPPjfZXjLTK8+ep8pck0p7hfQ21kO9NvnQcANHCzOAb2oJxUMiR\nP05VvihVC1XsPEmWVLWEdix89zj7iR1FD6Sb7Bchaz2Pa6ldzjMG3CK2RQvatczrCdbhcdXomQbY\nP0EiavG8w9Qq0fuiTDXMcpEZttSDb0/jOc9SCybGdpWZKXvpAp7P8VH8f1I8ba4ZFJg/EA/pfNRE\n4v32jjO9ryK83wuzw7juXHMWEa7NN9988823dWE/EoQtZCK76SYgWelcKyasGVA6yZqBDlKbQjFj\nrTIvUKVPiFmxbm3F71bsXKv+U+Rxb2LMWsfNMfZ9x53QCdYqszIxdT4dRzHHt+Nfe/thdZXVy1uB\nsGshzNCrY0Cuy+S1KkOqm3zryRVcV5084CtEusu9ZFswVtySonpahrxc8merjInvIRuhk7FIq5KF\nwNXtl77zd2ZmNseajr/ws+DDJrgq/p4HoPJ2B2sXipUwPYlY6JlzYBlUqlLXax7TXyF7YmlJFT7I\nVlGFlBUgdiNSSidxnzs76UEl0P+BgHj7bqQmpKl+DAmZehB03cQW0Th1/1/fO8iWx1OVdq09FMm/\nLZDPHic/d1EZt2RjrFUV21l7oQkxx2MYf3VqjeSJeAtkHQUYSw4nVUFIGZnYb5Ie09QC1kYqzEgN\nhtF/C4sYHxs2YTz2U/980y6ws3JZXG9mlVoyjMVOz2Ctp0Q1veFhastMYluny5amat3+6xFbHqJ2\nhhCo8iK8NjWF2LLU+VRjMsb3w8IiPNwWZkpuZKagaktu3sRMZN4nb5V5aQVFw3hPbNyA60+n8VnP\nj2WlaUMPm3rvw1eorkhPvsbnJVzDfayz//PSslF+CcdXRR4g2V56jpRn0Mx8hO2bb775tk7sR4Kw\nZUKi7Zxx3/de5Myfpqqe9K+1mj44iKCakLb41UIeyjAU4j5HZCcEHePMN0SNiA7qCAtJaxVfLBCp\ngp1kJRVVtFFGo9TRBqj2pgo4ap+XH+u1OufHNFkd2Yy7ZuHwNBDDYtmtS7ybPGhjFegNm8CnHSdf\nvET2ifSAEynq+EbQPyusYl7twWr85WEgoyFWGjl2Hv1/5wHwmg/uwer4m5NAYmOXgHRfbwcfto81\nHHdfh/0KRSCCljSQr0WlvsYY7xqkmSeeeBLXy/aFqJUyx9h2gJV5qgTOHYxty2OKO1od7kxIR7Xu\nqti0q1nfp6stD2kt9kjzKutC1sqsEwJXLcUKWQoFZjZqzeMCdbOvapaHXdSIaTMm7omNR+iRKlM0\nQE0XxyPg5SzPon9L07ifm7sQCy4xk/aJZ7H2EU1h/N59P9YqbqeneWUG9//kWxhvM1fAmojG3Pzy\n197AuMoxo7aNWkJH7oaK43sehv69tDy8novXlkZx3mqdaxsUOYzTMxyfwnX19sFTkCqoEnTbyYtf\nIIsjX8RxpDFTo8eimqlisZTo4U6M4/zTrBDTQt3vqRmsuYwTaWuYVaVDHqanw/tTVWYsr6vueGZc\no1CFGbKPFhgbb2Y+wvbNN998Wyf2I0XYMiGHm2+G2tynPvX7Zmb2x3/yx2bWqNwh5KuYttgaylyM\n8nvxOKWit8T/x4lEhhgrFw97lkhnmuwRxbrF1xarZIBqfLffDh70TlZlPnsGPOTvfAdaGffee6+r\nvWvFtAMhIqEgtksZVvpYhOcQTiMW1xsBArl4Gf3QQqQyN492928Awk7y+ypn6oIyqIj8M3nWsuTc\nvsqYcaaA851nde/j1N0eZMZiJz2XWw4CebS1o39OnUF7VpjJOEYEcoRI7M0T6Jd5Ipra2yDsZ55G\nBR/xelVZJ8zajtKUCXAVXyE/qfs5NSqZqVhvQBj+4eYl61uvuqJ39d4BfPra0379TvxqVSsXa0QH\nWCEbaI5rHznGth9//HFrZmI1yTTudb4YY/WJJPWoxRKRpglZGgxhW3EV42VletjMzCpL5FOnkGF4\naRL38cw8tnWq8A0t4DhbF/D8zPD/b7xJlhLV/47ciufh2GvQ215lxZoY2Tt9XCu5//77zcxsI/XK\n6+zQgMMnb+7ZLBHJ9g3AI71+Hzy6jV14Tv7iL75hZmZdZFtt3wZ22RXGlu9jJSRVwpmeRgx+cmKc\n+xE5E7rv3g7toJdfhjrgzBzeAxcv47rleZeY+ZnL0oMiglYNyXay3lRzM8ZxqshAiJmfYocI8U9N\n4f5MjIw27Q8zH2H75ptvvq0b+7EgbAeJVDCT7yLv+mc+9DNmZva7v/u/mZnZWfKkFSsWAtlLveLZ\nWWSMTbE6epLqaGlqf+zbh/2ko33mNJBATzcQ44MPYOa/QKT5ve9hZl1ZRruECEZZ0WL7NszAjz36\nqJk1WCMO/9UT4/RasYQZdXgMM/vgIPiolzmjhhhD6+wAcj53DjO7+K4FzsglxnrznG8XZjEzX+E2\nQt5uroyYdo3IdYlIoHsACH2aHkdLF9YAJsnyECJp60YGW4Ix904ibbFKPvVpZKL9ex5vlfzRi8NA\n3iGyISq55rxjyklba1o1C1lJKM5hWZd6IfWw2c/SDxYLQ+wJQWGxJsyJZfO+eBC1kLY3s5GhXasT\nYjvVx5VBGWANv5D40MxgJZuhqoIvrFpf5jhfoC67VNm8ttb4aWGtyyJ5w6qZGOBWWisBIj9jzDy7\njOdnExMJ26mWmWIG6fnXMO7mGHPeux+ZrF1bgMDnCnjexlbIsy/gPNtZHX3XEMbp5CW0b5V5Azl6\nALfeequZmQ1Sf77CWL+JjcP7udbzIvVOabHsvQ7P8+H915mZ2Wf/HJVZtLYUpvbMqVNAwvKMthI5\nyxPfuxvvm3lmRr5xDGywiUn0hzSPJsfRf8UiMxNzUq9049wS13Cke14g62X48gh3d8fqvdfb0Hun\nR/wDWGc+wvbNN998Wyf240HY5q5GLdtGNsdGxmiXyRa443Zk4o2PA5luIA/6gx/4gJk1Mg8Vg/7t\n3/5tM2uo/AkZ/dZvjbvON8+YsBD83r2YuS9cALI9Ta2Tt5hxKXaJqr6LxaLzKhNTM6bXIjHVggMy\nec8j4DPvZwWeU2fAwhi/TJYLM7TyWbRvZg6IvsT+S3ZhFfwSVQxnyWqJMOYrvWKp72U4sw/yd1VW\nFGlVLHye2g9lxsKJHKqMsV3kqvgcV81Pn8eawUsvQ1Vxx27WzmStySqhZmQN9kx3N5BaVw+1TJi5\nmed5tdwvHq1q+rUQ8Uc9fGap/QWC74wX/7baL97gNc1hl9TdmYdeNkmFtSiFsBY43lQDcs32eM4j\nfr1i86qFKY2WiAnpC7nhfME8xsvencpcxJrMKG6zXRhFjPa6GzD+fuVXP2ZmZju2A2kXyFOuRlk1\nPInx3VvH/Y+HgEB3bwZLo0gEvfkI2CCHjt6rK2PzlZnp9ohUGcdr8qgV461UxM7hUTm+urukY492\nTo7jfTA8jOeijeNK+RpeNcS7734X+okaK89QFfDSMBBymBnBCdawFLssx/dGneOuvQMe6K5du9hu\njFexeuTJrbUN8TznzjZnEZn5CNs333zzbd3YjwVhe02IxFu55QzZGPpeM6OQtirGSJfaq73gRU63\nUDPki1/8opk1WCXiUYt9IqSs6u0zM4iVnzhxwswayEeqfzrv21nRqahDFTayIHayAs/mLThvicg3\nm8EMfuxNZIKOX0Fs+LnnEWvv70VMboGZk6qOXiQboS4Hhkg0QyQQIxKYmcTxBrbDY8nNgj1SoppZ\nKzMLE7zOLsYmX2CNvTYe5/QZxtoNMeUxrr6XiATFb/fa0HasokdjwA1F8pYzy24Nkji1K7raEWsf\n2gx2QpLta/Cu8SuFsBv3X7FtxRKZqXjVfQt4frcWTcSpzuf5Pz1H3get1UQ5blczuK5wtDlOipHe\nodi5kFdVixhX0W2oikikb/QsStytODdsZmbtZLGUqKFxaQzIuW8Q4+5nfunDZmY2RBXNCpFjjLHh\n3az1uI8aQOVxeFS5Nx8zM7PeFPbbtQXt2X8zMpPTnQyeVzLsF9aerPA+KPa+BsJWTVYJTGsto8BY\n78d/7VfNzCxFTZRxatlkqfq4yue5vxvjt4+Vd6RloturKvV6r8yQTTI6guPVqqzdSWhf4hqBxp08\nP3lSygORpy0PXu816Zc7fP6SVAWZ6VtY+33iI2zffPPNt3ViP1aE7Y39KVNQvOg02QBCvEK0ik3r\ns1c/2BtLFCIW7/trX/uamTXU+TQTvvbaa67jSEVQvGxpmtx2G6qqK0Y1P4/ML6kMrmXpBI47ch5s\nlRJZBaEaYnQJVkSJJclKIBvh1sPwDHqYYXjsDcTUpSq4Sq2QQJCIi8i9WpeGAs5fl9octyNzCGZu\nZmbiSXoSc1QNvImxuCwRfI1IaHYGSOTdj7zXzMzOE2EfJw97xy4gMtXIrJRSTfsj1U6esbQVyIJI\nUVdb/GyxLYYGgaz37IT+tXjKTuxXbBEiYEc7gq5Go+KQO8btjWV7x483xurQvHVcE8LC/Qor041s\ngyTZA+3M8Et0RJr2hzw9L5AOkP2k2LV0sFVzMxCShggblsW4CAdZ7ZyZoXNLGCcL1EP/8K/8upmZ\n7TsA5CxkXfVUX89zG4qKtQFEmlkAAq6Tl59mfkFhGeOojRWKpNVSrOm+MJZdbr7WIxNLJEG1vnay\npyyMfj18CBmZS1y7ef678PwKXFNqZ17Dz//sh8zMbOvWIZxXNRXZn3MLeH4X54HIR0cQA58gS0Rs\npYEBeCDibc/OAImrpmyWOve3HMZ7ZhNZOeLl632h95HW3l566UW0m+8Dq6/9WvYRtm+++ebbOrGf\niBi2TEh5xw6s1qrGnaqU97PiipDyWtodoTUyqFQ77k5m5n3rW98yswai2L4dCE4xc6mnCXkJQcsD\nEFKXmp+Q91qZjqrQUchhJpcudjwGBBEmQgsyBqqaleIF37gfamc7mNE1PQPWwRnWoJuiTvjyEpDz\nwhw+jxCJh1m9uYs6xGVmXnawOvdYFkhlhbHd/g1ACK3UMMkWpZamWLDYEuifsVGsCRy4ATHC1RWq\nlq2BpHIl8U5V/RvHbU2jP67bBd7tru3gBd+wG57V5v4t7C83UnXud839ucHaUZB7Df414UuDD+2O\nfXutsbqPfogxg60ghM3q20Y1xhupUjk8DQ/r2NPHXceLKkVRpSwdlogyKHkVvL4QtUyqzGgt5Yj4\nTv69mZllh8FyWqoBIU9zjWHLLuQfHLgBz1GF6nIR1owM1yNsP7ZC2tLKKNbQzvEMGpqZ5RpFKz63\ncA2lu6wq9fh3jfdL/HupJ67Vv42q94iFR4islxbQ3g2dfP55v8QKyefwf2neFDiuL12AWmGVvPiV\nVTyH4QjZWz1gp2WZT6A1mFZWbrr+AFhkbWQpvfTSK2Zmtkx+/cYBsHAOEfl39yIy4PD5lSHLft3A\nTOpperRLi0D6szO+lohvvvnm27q3nyiE7dTQ41a8SSFRsTiEmLwx67X4tEJM4l0+8sgjZmb2yiuY\nIUdGwLe84447XFuxVKSyJt717CyQzDe/+U0za+hpv/vd4FWLXeK1FFX36kVqZ7CGolTEanXEMDXj\nByPS1HBXVGmhB5Dahhj/FsbKykQERmSyQqQ9zfa+xQwwxepzeXcGaZG/0xr109T6kO7z9TcC8Sqz\nbIKr4UWqDVaoKrfKmF6csdMw+91rIV6nEJEyxYJkRfR1or8fvg+x8n5mZEYCOL+Qfd2j0teoyFJz\nbRusD7f2h4Pw6u4YtszrMXn13fVZCDVEz6VO9bVCQfrG6I/t25pXCdfvax6WiOgvqlVZczIycdwC\nawROjcPDmXzxKTNr6F4HqHJY7aUmxzbcxxL1tKt1bC3gzotorA3gc7SG87f3w4Pade9HzMwsS15y\nK1khiQ1Yw6gyjyBCDyMiNoXYOPaDn9uODrR3aDM8qoxqe+YxQrtT8AxjURz3Pmr67OMaV4L9meN1\nLswjhp/lmo9qiOaZybicxfNxZXSSHYCN+PavUGOkQs0WY0y+kx5qgeP4q3/7ZbSLz3uMazFiNSXp\nsca5diQetzROqlX3ffh+8xG2b7755ts6sZ8ohK2ZtlRy6weLraFYoWLZQiDi03pn6oATI3MjJ2kK\nqOKNENRWZlpK/7rBk0R7xEpR7EnqgeJnKyYufW6vLZFt4Ry3JoRLTQzO3EXG/mrkJScSimUTgXKe\nFe6LRNxVwinH7NS27GQ7NwwiRvfmcWRUipXw1a98FZ/JElDM9DS1V6S10r8J/Z5kjPnOO7DWsLwE\nRC1PSMhb90nt95r6XTHCMmOyh26AOuK77kSstTXlZgNV6uKxCqmJBeK+z16Nl5oTkwaiiUg9MSCN\nEPKeyb4Ieo7XiHU3R9iOh6BMSPbj1Bxik+MzYAWoP70WDilDlRVkxCpgCF4qd0kHwWMbTdDz4hpH\nb/LXzMxsdhKx0TB10Xu24H7FOjB+VSnGWQrwZN6JXxyNqX/cuuPRFsTk2zUQK8qsJTTlc1NhBZhQ\ntOo6j9gT3v6UfeLXfsXMzDq78Pyn6LFFqP8d4XNDR8327cN+1/M+qPaptGSUCSsPXSyipWX0w8lT\niHG3pNQhYq/Rc2qIzPC4dfdxPWsojmestQiVuCTyl7pfRxs1UpjxHI8190jNfITtm2+++bZu7CcC\nYXuRtVZRFaMWot2zB/xbsUe8v387E0JX5ZpV8jcVm1atRsV0vTUkhbCFxD/4wQ+amdn3WP1dmVJ/\n8Ad/0PT8j3/722ZmdudtWEU+cQ5Vx3fv5OpzDDGuSF3VnVU9mzxYfh8kwgo5sVdspM8cDrgRhmLL\n4rV/7GPQjDh1AjG7N98E4p4lD7sgPjAnesWox8kbVcWbtjZqSDjIHPYWq6m/8frr/L65GlueiDoR\nFrIFNDlyG9YQ9u4FOyRYorYJ+bVh7q+KIeLJSh9dJoRdZT8KIFaoYpjkGomQbdXcCEzjxavq52Qg\nVr3qeu7YbLXG2pRj4Km/cYKqcNPnmvZHiKySII+n2oxZ9tPc8pzrfO1tnbxO9g/56m37UMlp8A4g\nzhLbkWNFIkcDg+3sSHNNhOcTUizT0yhxHFWLbhXEIGt8Ssc8EpQH0LxyjvNZon3Ofs2f37/868+a\nmdkG8p/F2spSZbJ9sJ/txf733IO1qcFNQKzf+Coymqfp2Rw6Ao/tQz//z8zMLBzBD8++CF37RVaP\n38nnc4ksrNOvYzxrrWV+gaqYRN5pjiPVbpRnJJshe8tZe3DYIujvFGuw0lF2Iguf/sP/dFWf+Ajb\nN998822d2E8EwhZiUUahYq9CvGJ3CGELESs2uVYtPJn20wwtloQQmPjXYneo4o3aI16l+NZCXh/+\n8Idd7Tl7FjGw3Br6zznq5E5Rt3pyDplUiRZc30AHkHxnCvxNaY4oplx1YrJuBKbgmHitdcbwxFOO\nMeNOes27diKDccsmVI1XzF7aKtJOWWY18ywz2y6PACnOL4F9IE9ldh4slCQRvNQCFSNfJGLwmrRD\nIoZ2inf7zSdQSWSGNSV3bUV7pXWxyMzSScZo91EfXayiAmvySSVNscc4MwaVsVmgR2eMiTuaENwK\nCSqDLUwEH3dilYyN8nqcaupkFZSpG14ogkUxM0vtmnKmaX84Kn8Vd0UcXY90oYXgrqo1WXOzLjRe\nSkVV48bvSxWMw5Y26opHtD/us5RfcqoCT+2LUMXtaYTpsgTIlhB5IlBpvnbkfS6DVbfH4jX9PkuW\nh0LjToYrPc8cq4xfugDPZbAfz/Odd8JTm5rGmspyAdeRIULfvBnP2cZ+vG/efBP36YknXuf14nwh\nelLbtw2xYegHVbaSep94+Ho/KJNSz2nR0QyBabxHmU8SNK3F+SwR33zzzbd1b4G1qj38kxxcsmi+\n+eabb779UFavX10N1UfYvvnmm2/rxPwXtm+++ebbOjH/he2bb775tk7Mf2H75ptvvq0Tu6a0vj/6\no98xM7OSpxST6HRh0qBEu5K4TZClhGqOLCbpRKTLqOSS6GyKzAdV8oeJBipCK5pWwEmFdRctFatI\nCQgN4Xp3eXpvIoW2DXohm0Va3a9//N+5rntmCnTCnj536rtDS6y5EzDqDk0M17NIMZ9ogsVoSdcL\nMDFkeRr0OZU8El1tfgq/G76IlOjxMdCfVhZB6J+dAi2vpASMPEWoSAsMViS2hfuWL4JmJVnYKFPH\n25xzLS4AACAASURBVHpAj+olHXPz1iEzM9vCElO7Dz7s6o8pJsTEme+iUeKkU5D2VMiDthVlP8Xi\nuP5VJhJNs2RUWULxKtTA41RJVIvywB1MMEpwhwzFgJQwkmTCVgsTdCJcO69yK/peNofffetbEPv5\nzOf+i5mZLZAGGI+if8qky7UkcN6/+fJLZma2MepeU/q5B25F+/kcKIFLCRUS/ndEq1R8V4k6THAJ\nhSVCpVRqPgcBT4IRx33ZqWqrjcY1S2E5erUqOOGWL26IY/F3pDV66Xp6Xiqe0nE1XtcXnnjLtf8X\n/kop37qffC55HcMXZ9gf2L9Byww13/I9o4SdAF8YkZBKu7FbnBeKnn9zbUPO7/Xck7Zo2o/vGYde\nSXokE2v0PopR7thZWnRS3m1N8xG2b7755ts6sWuKsFvamAAiUR1mIlRFwA9wJtbMKLEbTnEVlghS\nkUqVXgpH3SnImsl0HAECIehAUIhACQnGzx6Eq/M6YlLBNX6nMxMJMzdWiGGtRIC2rkHX56tS6j2l\nqISgQixFlaTYjVKzVZoqyH7r3ChZV3omEoDfjONspzjQwjwKGpw+juK+o8OQl80yscKIoIIqCsqC\nC7UakGJHJ5D0ls1IZOrdyNJJHUhVb+2kWE8rElkC4eYlsVZWcF+zQTdiiVB2VoUS5BFVCEFylCtd\nUcq0ucWXnNRpQRYdl9cTVEIJE0PK3K1QVoIHxyeRoxC2kJQQ7mUK4n/9a1/H+cNI8b5+HxJ55Lno\nOoyIdWVZ/ey2T/7Pf2xmZmHuX6fPIUTsLczhyLqyJFzEEZ9if0isKKCUaIoe8XzO/2l1JwGr+P0/\ns3pdCUdFHofItK77iuOUq25PsyqRLlVFJpQM1t3n1aj/wr5tru9jcYl21V1bXXc8IfEutsJB1Eoc\n07ig5yVkHNL7Qv2grcSc0O6A4/nruMbjuOWOnTwXXaY8AXnyYXyOx1mgJOQuBl3Xlv1ddd4vVyfQ\n+AjbN998822d2DVF2NNZIDGnBJRnCmmleFBA8wZDaQ7wFHKO4/9KmbWaEBk/a0Zyfu8uqeTE5jwi\nPY55fq8U31rdjbjqtZrne3cJKv2uukaJsFrdLTPaKF3lNXfD6zVcedyJSfLCKfbjFMCiB1N3fs3Y\nPT2PYArb7gSQzA0sJrrnRsRi8zkJ7RPBMEY+vwAEnssjNrtlCwTsO9qArANEIIGIEAORhTySNUpA\nzc0Dsau/qPNuqRQ9qVYgu3gs7uqVahntTIZVe4obqXbqKnjdQuBR9luFMf9cFoiR+vUWirgLS9SD\n7vvtIDGetlRkv7F48HV74cHMs5hrlSXQQkxZlvjS2JXmqfphBqsjUSKwoNZeeD1Bd0xWCE4OneNp\nBlW6jUiYHphS8ctOMV/3GlI4JCkDtoM3JGDYRtgeyc+WOf6ClBYIxjT+iDCZeh6ouxF2oH41cmxm\ncdVu1v2tuq83GpNMKT4LCUuESg63F3k7/RZSkW7sJzXUMj2vECUWolH9Dv9vrCHoPjVvv/c11CiU\n4Y55K4bt1Iy+Ol/GMR9h++abb76tE7umCDvsxJYUG+IUwplNyCrgFYUJuBG0ZC8D3vnFAbKCcs3b\nEVoDUF89X7nlI6X+0/i5OzbqrFo7n3W+5g0JmmKIXH13YuNqh9sTqddVZJixS6rRCME0zsK/nBmd\nMTvn+qTKI6iGWHh799am7fRa/9Dud7Rfg7XAfnHua3OPY3YWspclIqcYkWBPD0S2KhSHqlMONUhP\nLUXPbHYBIlCRdhRoqAhS8bTLyyiR1smCCwXG6AdY0CHFGGhmAd+XWTgiSWQVirlj+aGA5FTh8QxR\nNOzo/Q+amdkKCzl0tSKG39fF0lFE1m++hrWDqemRpv0RZqkrIbuAc9+4kbyr1jCc4Km7iLH2U+z7\nwiWImVU97A2Jdy0twiMo5/D/lTwLUlC8atMgRMIGuiAW1dsHz7mrHzK7QuiSF421YNzWyQIK1Rm7\nlWdobte4ugYtIhGnp1PTlr/mz53CAnzehLClbioHrFFYQrFsfRaLTPvh/wmjR6e1AMW+PfchwPGg\n2+DFxbrKteSfnaejLtYav/cRtm+++ebb+rdrirAD5uZfO3hPCLImxClE7ebPBjXzOjr9HjlVz8Qc\nuOpyhFT1Ox1IyFnIBJvGYq+Qs/u8DiJwglKKRTFWqfOtEZsOO3KpWn3W6cUK0PUr1qfr0Sq/+7rW\nMiHdqzySH5EFrzpv8/aqCGqdHVGrYLu8QDncVfzuzOnjZmY2OXrZzMweuB9C9I89+piZmd1+P4Tr\n011gJVXJ1pmfA0tjhTKiZZ5v8MgtZmYWIwG8NU15S/ZvMkaEyvsbdjwFslTIUz95GiyRouRLWUy5\nzNj29BTkcyXzurwMPnwk1Py+BBSbFuQTa8NB1G4ErWaFAoppkx1BOc/RMSD6fAnIdy/ZK/Jsjx9H\nv8rx3bYNJcRCLUCYF68AmY8NQxb22a9TdpT99h9YqOPvv/G4mZn95ef/3MzMfvGjv2RmZg/eA8+D\nSzAOUm74W+7r81oiwf3dDq+DsOOMtQeJdMPO9bNfwrx/Tiybv/fErhXTbvyf7BOuYeh2OR6O1gzc\nlc6ugthenOwt5OGMKh9h++abb77992fXFGFXxJ5weJRuofWwSi+FhDA195L9oNBszT3jrMVzbtBE\nPN96YtJXxVSVIen5uhFa0++rrn/o/+J7O2ySenOE7cycDu/SHeOtmvjG3I3QJOwQW4VQeB7F0ISo\nvSlZHnu7Qg9r2TstwbaWrXWWt15+Hn+Ir8rrSzD2umkrYqcLLPhw4i0UOy7kKMRPpLs6i4y3qSso\n0SYev65v5vIlfka/7d0JlkzfBsRgw+Qnh8nDDdaEdN3FjYVvwiEg8tlZxNBPn0KpNbEWlheBpPt6\nUJBidhrtU8Lv8ZdeaNofGh4hxWbD8pTWMA/rKcig7dQMCjvMsZTV/hvAXjFlOJIl0sFCIUvLEPQf\nHRs1M7PDR99lZmYTs+hPIzsoxgza5VV4EH/2x39kZmZnjqNY8x03oSjvsedRMm/30E4zM2tpQSmz\nFsb2xUZZ+zmGKaHZ+5w5CJtLPPKMIoxJh6Nu5N5A0op1C1G793OQs7O/eyvErUxLh+auFGtP5rXz\n2NTf5rlz8kY0bm1N8xG2b7755ts6sWuKsMW/bvCT3cizVhMfVARXN1IMOrE6d0biWvzltZBgzUHY\nagc/rsHHrjlsEJhiZMG6SkLRU3CKsPJ7JwbVfIr0lv5x9vMmPDoaK4RkJWWGRtUgns/DB/eUTAtF\nIq7PXqu/TSzcaffaGO8fZf/1D/6DmTVYEWWWlmonEuseAALOV1lKLArINT0NVsPHP4ZiqqywZP/5\nD/8Q+5OtoNJM5QxYD5uGhszM7OGfQgy8RsSdICKTJ5PPAnGWCaHa2tAe8fCD5GvffBil4zq7oKXS\nQ0R9+tQpM2tkyq2yJFWdRPE/+8Pfb9of0QSuT5mrGi51h8eMTSOjE5swx0OWRWJPs1Tdbbfdhv8T\nilY4ootkuWzaCk9jYQn9efZ1FGM+exaIeYJFqKfO4fPUaXgSBZYU+8wfvmFmZu1JsHZ6mck3NoHY\n/TNPPGVmZrUw+PRtXX1mZnbXXXe5rjsSaZ4Jm0rRk/XkRYhnnqAYTEgeUtid0SjPPcjvIxHGuvnW\nc4oqM6btZIgKYYfd/HvnvRTSc+Z2yZ1MWCFtx6F2P2c1z2eHXeU8z1f3hcxH2L755ptv68SuKcKu\nVZUp5o5dCxGWa1qFdccO6+beT+ZFim8XAwt4YkqNVVm27yqE6W6nkznHYHrV3DFw8cMbGZA8fnWN\nKbLuXVb2tJf9FGF/TI0j9vrUN/7ezMy2DoIPfQORkxGZCqGExA8V26bmRQCBpp//8TFq7/V6Ynlr\nIPQ62QtVsmbCkQT/Ac9ifgbFU4NUNQu1U0slgu3YFbAgPvqRD5mZ2cn77zYzs7/8/N+YmVleWjBE\n3GUVs2XG36uvvsrzuT2qs+egZrj3uuvMzOymgwdd7V5cAr9bCXtbtwOp5lgkd++BA2ZmNsfYuhDy\nwIZ+/KDUXEtEyNrNSWlk6nmL2jrjl9+/9jpYHPuuv97MzJLMZFW7VqnB0krWzApVBS9eBvtmZg6x\n77Gn0O7+Nvz+9CsvmplZOgNPoUa1yN407lcHi2SPnQISj6agIXP5LPrR0ohh72oD//0kPYAYM1hV\nZNtrqaSbp91Q0VQsWep3GC8JskZi0v6g5lDAQd5E2Ix1i5cddFgkOr7x/zX3fkLQbhKPky/SeN94\n9mcMu8G71hWKLaetvvdZIr755ptv696uLUvEo4MtxF2hylqYM6zDnqi6M/+CXvU6L8J2eKnuGext\n8aJntblBGvHE2PmxogM76nCKXXM/ZxnbHbO/2tzYSTOvw7smP6RewSr8y89928zM/uoz0FnubEVM\n99CxO8zMrL0HyKW9FTHUzk583jAI1b7ejRvMrKGvrNhfNObmg6/JFpEmiAdB67Y0PBZvTM6N/NY6\nfMUUuyQfmtehWLVUHSvUN19dAUshwgzFkRFkDF6izvf73/c+MzPbthMqgs+/8LKZmR37HrZZ6mr/\nx//4n8zMLEO+tDyTbAbHd/IEiMRGp4BAlxjrHR9HjHZiGh5AheO6kJcYDX4XF8+e0GluZpb/XsPD\nkqfpaFtwnFCXvO4RTtZ9OH0eiDVOZNu/Cfd/cRGewGXGosuVEo+Phqn/pqeBrItkjyiIe+kiPLxa\nFAi4TvU8qR0mKtKtZ6uSQO7xTsSqo2kg6usOItbf0QcPIyzND6UiUh3Qa0mHh+1ee1LmdKCO+5dZ\nAVunUsT3hTw8gfZOnD/Zjhi7dLhTcZw3xth7RBmmYa2diT1i/Mythz1yVaza68E6+RTu69LamfPc\nuJfYfB62b7755tt/D3ZNEXZRutL8XGHlhXgixM/KNBTC1OqrmsWZ6KrQr1uLIORoZHga4Cyuu2cy\nJ29RGgQKHgmxS7dbh1FlGY96n8xB1J5Ym9e8GZP1mufCgkCSEyPIMDt1DMgwSH3eK1eGzcxs/DFs\nUykgn1QCyKqbMcI+6mJ3DQJht6Tx/3gc+2/dutXMzAY2DZlZA4lEqSrnaC8wNl52III7o8wcdUB3\nLHwt5O21EJG+08+6TbwPxQpj3ETYrW1AaLv3gN978AAy8yYngXRXVoG099+Aij4djNV2phDzfvZ7\n4H2fOgU2hBFZJRP4/0AnKuV0s3LOHJH15fOozDND3vVSDsi1RK0NyrU7Ot1pxnZzFbEYqLtNbZQI\n2SC26O6PKCvdBBjDF8JuQD1BdvTzwjza8+2nnzMzs7vvOWpmZn//FNgZ09NA9K1pxKLDvH/z1GDJ\nZRHDrhJ550v4/2A/2C7nyXZ5+CP/A77vhjbKd/8W+t8Xz6K/c63ov/QgxtV1h8Hj3r4DWitaY4mQ\n7xxlv5eK6L/ZmSvWzBIJqQ7ic5U8ZWmX9FKrpd4hVhTGyV/8+V+bmdmZ82hfqgMZsP3d8EAfOAoP\ndd9BrDUkU2ABNTIdjedxe/BXZzYS6Zvne48F6u4XUyOEXWv6fb2+No72EbZvvvnm2zqxHwnCFoJK\nE1FlMoiNxeNYXdfUFVbsmrzKmhCGMxOJl02+pCrJaOoTol5Tj7p5Ln/Zoy0ScDQ93JVbvJUvJPjc\n0EYRr7z5+deKYYfY8JGLZ8zM7Iuf/YyZmV0+AYSzcxDIb3QCmWtLVFmr5NCuPPWdp6hGNzUNRLjy\nPGJ8Mac2IG53WyuQiWKdm4a2mJlZK7/v6wPC2rEHLIkBqtIJeWstIuAJZtc8fPmrKvp47D3vvtPM\nzEqMLV4aQyxVseT2PsS0S+JVU+PinqP4XV+KNSYZs1RlouGLYCdEiFh/9ud+2szMDt6CjL/xKSBy\nCSAPsmJODxF8mZCubyOQWZy841eOAbm+ePxJMzNbyoOlks0CoVY4Hlpa0a5CRpVbpIuN/T7wPrBZ\n/ug//5WnR8SSIa9YyJqbqpNJi/a1t6N/PvQhsGRm54CchayXVxBzX+F2if8fZexafPW2Ntz33m6M\ns2gKsd1ECt/vYqUi1fIM04M7zLWCLQfBSunehHGUiMCjCzk8ZzynUi2cY+bq7OwUjztlzcxR0XMq\nLzGTkf3RSlXAcJi6+mSNPHgfxsfcAjI1H/vql3Cd9Eh3bUOM/Z53gw+u14dTkcZB1G6B9YDXQ1ZN\nx6t4aLCg8/0a7yPPWprz2vK879zH9M0333zzbV3YtWWJiGdNZNDWgtN9/nHMeB88+i+xoxP7lDgA\nkaozA5HloERBxo5KVdWg8a6eu5FvMOD+v5BtIKDabZxRiZAqnirNNbJDGkiaR/Os2mv/6poI27gf\nW82ptcBV7me+/kUzM3vtuWfMzKyvBbHB/vYW7sfYaZ6xNUKQOPmmquKtdkntMCmEw/9PLOA4k+NA\nWsdeRAw0yszAKI/Xwcy9n/nYx8zM7P4HHkLDHXqNePMOBMH1reHheG3PEGLsoq2XGdNM7wDi7e5G\nbH12Du0dncd9qBSofTEPT2KBMdldu3aZmdnICJBvmR5ensh76xBirNvoUSSSGG9i2SwsAEE++pVv\nmJlZJAVE//5H3m1mZjcdAHJ77gVoZZw/AU8nQG0MsVumxvB9nbFheRjzc/j+pz7Q27Q/JJkToVZJ\nkOyQGvXTncoohJgRVqhJtmB8bNqC69p/YL+ZmRWL+F1mFdeVI8tGCHdpacnMzLI5fN/GtYxZapGc\nvYx+/OwXwGvvHQKyvvHuo2ZmtrEf98/SzNCkBxbhDc0yRi62yjJZNnWyOSo1rQFkm/aH0dMOejxT\nWVJy8ULIlOm7611AzqvMWP3630FNsEi98yefe9rMzI7ch/0O3bjXzMxqFa8n72a5OVJAqjjDG+Yg\naWUgc/+3ewoc8tlVe+q94iNs33zzzbd1a9cUYRtZIH19iIV9/UXE7HYNQIVN1dRrzozG6uiEEhFq\nE4QYyxNSEF80lgQC1XwUDkprg7Ezj3aJ5qeAVL2qObYTSLvMVfJaCMd1NAzEg3X0uTXDElHzPFUi\nurVmQW9NSc3UsxOI6c+MQo2unRleaVY8yVDXOc6Mrv5OxOwoWucgSFUH16p0NODuh3ZWMa8mgYik\n31zk72vkJWeITCbGsXo/+XvIfCvnsf99Dz6M4yfAPnCqYntC1W+XQSl1PiGjNrI5tg1hfPR0d3BH\n3J/XqYr32Oc/a2ZmO7ci5jrO6uT1ICDXJGPUuSzae/oc+nfzZiDEtjT6L01kumc32CZaG5mawvWe\nOEee91kc7+EHbjUzs009iHWPt7HmJKFetgCkWC5gnC7O4/pWMxy3zLAs5JzqpC5LttEjJEIN8L5p\n7cHrQQpBVzmuKlWxmPD/RBz9mSSLqNSC8dPeidj84gJUBbUmUud9yDIj9NCtyKi9+TBYN1t2I9M2\nHuGaCIdzhs/P9ATGS4Tsngz7v0jPyRmX1BapFDFuSoxte03ItSoP1kMGY+lPp2apamKqu6T1smvH\nkJmZnbkA1sgLLyHD9VO/D7XBf/uvf9PMzPJZeAAF9uvGwX5u4UkoP0TvgYDjYcu1bLT8B5sn9l3z\n7P8DnhsfYfvmm2++rRO7pgg7GcRMdW4KyLElc8HMzG7ZilXl515GrLarBzP+ri2YyUJlIMvxCSCn\n0YlhMzM7RV5oiM2+5Qj4niOjmDnTbcz060csL0X+aYUzfIE8WfFb40TaRa6Wt7YhlrmcRQxPlTwS\nVI8r8DjLq4zFMbbd3zfALVafvRmeXhNyqDEWX6sCgW0dwvlXZ+l5rAKhbBxATDdfgacyv4TrGJ8E\nQsrX3OcLk42TZExV7SmW3bFAR+85QDaP+ObKKCOimBwGH/mP/9//h79Hvzzw8Hvxe0EaISCPyuJa\nNr0gnWiccHEJyH5+AbFVVWkXEgwbkNzsFFb/tw4i5pop4PszF0bYfhxvZhqxWtHmp6aAJOP0MGKU\n+RufxH6bt2xytUetV6bgY48iw/HgQcTCb97/Lp4P/ZcrupF0nuXYV7M4b6G84rpurx17E+yT7jaM\np+2br+N/VBEH/S5VRt0vZQBWHYRHZE/1vhIr4hQK2H9lmawRxrCFTGtEdr0DiLE//F7c3zbyysXj\nL1IPe5laJEuruK7FRXgiqsVYrSpzl+OKHkB7L3juqxk8T9u23dS0P4pOwmzw+66qYfGo2Er4HIrR\ncw3jfBs24Xm89bbDZmb2ymvH8H+yev7ua9/CD8vwKHoG8Hy1kd/9yENYu9hAFtFViJrm5o58H7tM\nDvkPyFzEfp78BWVWNtnVR9i++eabb+vErinCXgkAGaWWnjYzs/ftAgKejCAW9p2n/8TMGnzZaFy1\n64AkFueBWBxNEX4v9bKxLyImXmMMTci1To2CFCt3VKn/WywyxqyYF9knQqDRJBBE0Al9S+uAFUh4\n3FIJCKMtCQSvDMEE1dEOHbi5aX84vGQPqyXJWOiWHUBWtTKQz+jJOfYH9k7yfNPTrIVIBKOMx/wK\nvl9ewe/jjLW2tgMxXJkY5/XiApMJZAKGGJOss+ROWZovWjVn/46y+vZn/uzPzMysqwce0cFbb+Z5\ngdykFZFmrNipUeixAtkBut99Pe6YdYkxzsGN0FDZOIgMx2wOiCjHWHFsGghvagqeUboF5xVZR1Wy\ni4zR5xlrjlDL5tib5AcTeSq2HzRWbWeMPpNnzLWE47W1oH9VsUTjqKY1DSJvIS7xmOdHmmf2felr\nnzMzs1/4IFg5wShj04UK+wOItMKalWLBKGG4xvEqdoaDwLldJb89w5i6NDTE0w/F8DmqGpJkyZTY\nX3MTqEijcVamCmCZz1WM/eRUBCJyzfNzDzNIP/MZaLko8/c3P/kvmvbHhWWM194oxmlbmLQQrW0F\nqf3iAF8+7+zvKD2p+x9CbckvPPoVMzObncV4yWdYzf511Lb80D5o0ezch3FW5LAdFm9fuvd8Liq8\nv6pGL82dBl/euD9ZbbxvVenoa41MEjSEz6kurDnctmPvVX3iI2zffPPNt3Vi1xRhb159y8zMsmcQ\nszueR+zvRATfq1JIGzPY5hcxkwfJhmgVv5Mx5yxr+ElvesMAEE40yP04/yRaGaNkbHU1i9+VBUWk\ngVH1sBuIaKqMdUuFzaluHpLaIFbf40RoBeobL2cwg27e1tm0PwIOP1uZgGhPS/eQmZmlepE5toG1\n81JBIOeZMSCalSz6JcNV/BARUjTGih4p8rrnuPrPGGV7B2LjijWLPVEpox1t6Xb2izJNpb9MfeaA\nOyZ5/jTu33/5o0+bmdnhl8GeyFAvuYX88UOHoSN96NZbm/bHdtb86+5GzDQYces+t7TIA2Bma1S8\nZLTjiSfBh5ZWRSYDhLwqZMn7LT3kMhFf2ak1KkSM7cUL8CAc/WlltlYxHlrSuK6ODmyjIXmEYj+4\n9dwL9MSqVRGs4SFt6Bts2h8dHYjJb96MDOBLF4HEw3UgSnkqYk2VxTohuymbL/P/ykPAcfPkWefJ\nC0+RLRSRXjTPX6DHorWVZdaELOYUm9e4wXHqJfYfWRXSflF+hDwCeZaLc0CqZ05Dt7tEpPrNr3+z\naX9MVMCvX8mCxx1ZwvH2bce4iRneF45aZpnqj0F5wjj+GDV4VJFHDl8f2VbXkSUkT6xCD+/MZay5\nnThzhr+Tp0jPh55nifs7/akMTT6fKpC1uLzE9lL3nnkPWa5VBaL44dBevCd9hO2bb775to7tmiLs\nBz74v5uZ2cU9qESxQDbE2W/8uZmZ3XEEalnSHHAqt0gVjkhBsZ+uLiDq3/gV8CYPHj5qZmYx8kdX\nZrCKH+XMHWRMuRbGTBbmtqIMNMbqxJ+Ox6lOR6RnnKErjIFLx1vVy0tkJ5R4vLBTchHH/T/+9f/p\n6o8q+c6qrBJwYm1Yzd6w43ZcTwgxtjQBg2rKlceAMOL0PMLUPy4Xxdvmaj9C1racR39PTiIjsFAk\nX1s8XrJjMnXycImEokSsRfHN2b9hskkq9ChefBZ63a88C7ZPZwdi0G3MzDxzDAi4xsxErxXrOE62\nzJgo+7NIDyKyRP47x8HcCjy1mgG5LuZ4H4V4mMmWYw3HCGOeYbIcSoxhF4vy1HC+uFPD012zsU51\nvXwJ7Q/W2e8BqRZinBQ5PhW7F/JdXgJCrDmeGpFfrXlm34YNO7g/xu2n/69PmZnZGFk6hw6iKrnu\nU18/nof9B+DJ5Bjrnp8HMp6ZwX0XD/zofdAw6eoCslRsWzrZeWqfzMzP8DP6scb/F+tE6uznGvMh\nAkTctZJbJ17sjXQaA/LsabDF7j4Kfvd3nwMfemlppWl/lOjZZBljn1/A9WSn4UHevY1rCFwzUOZv\nqA4PiI6qnXntu2ZmFjWOQ+Yr9LThubtuB3j/YR5neQ79V6MnE1RGaSzNCzPXBYboAaVYoSeWwGeR\nQ7LkmXfG8HxoTUqeUqoN7TV6kpFY8zUfMx9h++abb76tG7umCPsSa8SdYG0+qah1t4LvumNoyMzM\nak4Kk3v+0Oq6+NU33QgdW61uHz+Bqs1L1CrIDrNCBpF6Xcg5KOTDGHVAOt1UAWvFzNnKGGLbNrQr\nSCSt2He94tY1XlwEgookgMhaeJxyvnkm28glxMR27T/s+l4TdroNfPTwELQg6mXOzERo+SBm/pUy\nZuqZKa7SE/EKwSmWFq1ipl9hLFuh1A4i4dUFqdy5NS/EdlBGXZwsmEqVOublrGu/EmOZs6VZfq+M\nVZzv0c9/vml/nBs/y47BRnx5tUex5TyrxltEGhr4PhLA/bIqxw2rq2dXcb0JZmImWYNQaorSfy4X\nMB7kUEl9rUrtjuwq7m+Zsdt4GLHnGtuXJVJXbLnuVM3Gto0aJU4GLF2l586/0rQ/NvUBYS/N4vhJ\nsjTmloAslxjL/evPP2pmZgOsKv97v4/xMjEB7Q/x4Lu6cJ+XqUFDR8Vi1Oo5fw6I96tf/bKZmd18\nyxG0n56VPIUqEXSxjPGi2K3GbZyLUR1cKwnTQ1uih7FK1srwFSD3vWRh7NqL4+VzS03748SzOucO\nKQAAG79JREFUr5mZWTs1baqzuA8nXkA+xt0fJBuLaxTGcW85ss44Xn7hQayhdMRw3c+/jOOKLTNy\nHmsy8ljjnRg3rbyeJNlO1Q48j2GyVOos6lki3z5KTy0WwnHkseWo197QwRZrBL8rluQhoL3ZWQql\nH7q6T3yE7Ztvvvm2TuyaIuwvf+0xMzMbuYQZsVTlzBHCjD01/6Jrfy8/OU1+8J69mPlnloBATp7C\njNXephqAmOHLEfEzxcfE8WZqQEIMZVpfP/jO4vOGWAFEkcXhtxBzn5sDslnm6m6FiGqgF7Evp1p5\nFPPePBHr/OJs0/44ewJ8Ty/CblSiIa87jQy3RDe1KcgbrYeY8UdIKAQqrYZ6TUiSMzZXzyP0MAJO\nrBYWI089zOKDQhyK8WrH/6+9M4mR6zqv8K16NVf1PHAeJREkRdGxZNmKgcSJ4SAaEgiQM3iVRXYB\nssgq22SXTRBkYyT7GF4lgYMAgSLZEhVJcTRZEkWRFMWhOTbZc1dX1zxk8X/nNt9T0V41kAru2VRX\nddWrN9V75/73/Od4T4d2J7Zc2ZVLV9qkRl/L2H4osJ4X6xeG7o8+NUbpv3U6ljieYmrjfE+LEVIb\nNcOBfcawVwZ2Pm1V7fMtRjwpas0Navkt9MSDhN+wVA+poj0fpxbZwBVxm87bCZJ7BtLVMrLJwbhU\ny5arY76g2qQ9SGVQSJWH7o+vPUktumrn4/Mv/o5zzrkzT5kf+eqaqWD+4Ad/7Jxz7rFj9ntQivsY\ncwdTk4zAlozRFtEj19CZr+FS+fd/+zfOOefOf2qM88JnlsTz/T/8I9sf3rPEtrPEHMkE+6dIUo86\nL9dwgVxZse+tN9QvkGM9rJY9M2cjlTu3TNftBrWh++P1f7Jkm5T6Jaow3Abuh6dtRNrP4UnD+Tyg\nBtwju/Gxadsff/ryS845537rGZsL+OLGPdbblru4auu/esvUOWsLNmLpMzLKoH4qT+G/Te16Gz33\nGCoih5qsBMOfoqbdouN0g9+ZOno3alQCGBGWx6iV/8lX90lg2AEBAQEjgl1l2DcvmQ9tOoveGMaV\nieyOX1anD0yox9r05VfdtzvXxY/MY+E6+t+5w1az66ooC0PtUotUzTmCCUluncWF7y//6q+dc85t\n4/73F3/258455y5dsZpqZ9u+d2bO7nhHjtgssmp1C2Uy8riDNumM6+D21WisDt0fqw/uDn19J6EF\nYXrKZr/nD1rt7bOPbIRy+yYdapENFfKoWqQPbtSplba1vahGYKwpVC4NdNgR9+spGEPTM1B5VsRr\n92LUPmrQe6KgmumJAcMkmFuYmJoYut3FtDHCyrRtz/iErcfaujGPnJKIoBXbdMylUP+U6UzdhKFs\n4fc9MWHb24cBVbB1qxTt81s1PCjwkqmUbD/NTtv6zM3beji2ezVn+3ceVUaF/d7iuPflu40aQLXK\nLD7ZXpcNAx/LVIbuD6lvZkgdz+SMWR87YoxUqeybG3YetKl9tjnfpYPepgNxhpHg6dOm5y2iQnj7\nLfs9Xbtxne8zBnpvEcaJSmIvfQ5TE1ZDzlDj39zET33xLs9tBKjjPmDuKc3+7VGr9SMy1CRF1B9p\nuWYmcONTm/PqdOPqoQwj6H/9qe3HlDJI5WsPo9XkhGTa3sVTvu/8PsYRTrd5fxv1zDLeNjWOW5H0\n9TYeKmlGtJmULa+BN4oyMyNG9t86Y/u/zn66ft0mbVbxJ9/id5ujr6M8Nvz8cC4w7ICAgICRwa4y\n7Jlp69iS37I8PHJZOgVzzK7SgVemZqkaYFsMTiuLb+wmTCBDZ5Bquimf4g24c2YHqvXanfEf/+Hv\nnHPObZEwUt2w2nAafe/kvDG3kyes1p2lAzIj6orKQB4ARVQBGXkxZJUociO2P9bRifvkm0QSjle3\n0GHYRff7i18YE2ot2h381Okj7BfbX0uLxkibDWbb5QIo18BevKYdSV+tjjZUBBmobJa5g3qjwXLx\nsGB56hCVm58yMaUXL+AWqKSQVn247niaRJmLF62T7OB+G8mcfspqjH3UGRvL92LL1cDqHtmVqZSt\nb5/1mYTRb9fRK8+bymjvnB3P5eV67P1zU/Z/pXnnOY5diN8WOuwVao4TnG+yuKnCOFXL9UkinXgG\nYwfd9/Hjjw/dH59+YrXkfXO2vy59YSooddzu22vqqgPsp3wON0qOY6Orzkp7//i4McIStd2NJWPE\n775ruvkT+FuvkDDTXMfFD4Y4i8rkHiOl6qbNzbRwUex04hmmESOKSlkdoVaLXV2193/wPnM4J62j\nV2rjSZhrEhOsvxKcpMLpMfJ57Zr9LjSXJHVRGbWH5gx03qrzVeonXY/qjIx0HrfpQG6zH9sc1y4e\nKgNGqBMVvG84j/zx5gRtNu1zF69arX6dWvdKFR07zFx+6roeSJ0zDIFhBwQEBIwIdpVhHzz6pHNu\nx82rR6JMllrw8SPGwH3mokKKfQeRvDvs83KRe0D6szryUghM07KFlicAnVLcmF2VmvXFjy25ZJlZ\n9CYeE72+rdfqCjrrOVvO8WPGaCbwYCgUlD3JCEDJNko/9sbE78X2xwqdZ1Kwigmp9pbNKBvSGMnP\nXjWPhU8/tI6w55446pxzbg5mWmMWXl4X6uCsb0snrQQSmC6z/dr/WZjX1pYxyDK1+TFmqTcXqg+t\nrXP9nhgKHhpi6ix/etI+V6nYCEUqgVp1OMNW5+kWHin/8m+WSv71577rnHPuyWethvvOG5axOJAX\nCPv7wD5zC6xTE5XuVqnwbZjxNnMSzTL6aDxKpO4ood8tl/AugSnumbXtu3zTzrdPPra5hMJZy46s\nUGuUuqbLeuXYvzXc8cT05OZ24oR8ruO4cMHmaOpHU7HnCwvG0Ap5Y64vv/yKc865s2ee5vWI7aHD\njw7WNVLJr5JYVF01dZVGUr/7vGV0XrxoKp73/9tUWxpx3rq54JzbSa1PocaRjl0um1OTNkKZnTE3\nvohi9RpeJF/S4Xj4gI1w6lIj0YqYmVQ4Yxz7D6F7l0uez1TFi4OavdYjrfNTJkXKguVzvn9Qma+c\nx9h3u0KkvgtGDk7+8P3Y6zqOUcZGdm6Qjb1epLPT8diUTHzKfl97SfxRFmrKF9m1fY/2kQ8MOyAg\nIGBEsKsMWzXSArPwaScvD7tz3blFQoiq1JGn2Pb+npgcNSLeJ3WCZse9ixaz2MrE69BBqeSYMp1j\np08ZQ0qfshqe/IWlo21S06rCBNZqa7HHPIxMOlQll5SychccnjDRoLOup2xJ1DEdaoLVujG5y59Z\nMsYbP/6Rc865PYwk0pFtb71ptdRsyhjnZMmWt+5Ua7f9HeXTfC/qhY6SUchwhFFLx95CZ51GbVEh\n87ApVQmMRKndVZh5gdrv9IQ8KuiAbOAm1xy6O1wPl7MOHZRt9Ngffmx64Bd+3xjgnsvW0bfw5SU+\n1489bpN4IqZfZLY9E9nxK5VsO4qoBzqNOOPqoUKoaXvy6OGVcYgLYAeVQtNnKTJ3IPdEqRIYOYmZ\nbTKy03m+ujZcp79Ap+7CNXXGsX861NyZNNnaspryF1/aSFF+3Fn6AVTLlS92nYzOBnMVG3To3mfE\n98w3rC/g/m3TH8tlr6csRtZ7Gl/1PXuNSVfKNiJZIxHoGiqrxbu32E+23Zcu2u/80GH73R2hk7jA\nXEG99ogRmJJweC6m7YOMoMY7fcVSe9CPkJbOXuoVQ1p9CRop+k5VvkdujSmdJ4yAE3NOA+bUBr+C\n9yqyMdJcle8DYGm9OLP+ZTlNgWEHBAQEjAh2lWF/dN5qsDK5czCoDCqIqCdPD4P8ocXkmET1aykV\nhhi63MYimJDeN+CPLv/P9FXj4w6t2eN23PMjGsRTmiPu1PLtVVRbo0ZnYyK7rddmZJDx1bIY6vhF\nR9Sob103hnTlgvkDb6wb47l2xVQTTTos95CB12Mz7z0wBjZFAo2Y7UrFmF7XGfPfhDH69Hf2RwvV\nhxhIGSatGt3KstUe85oj4AiVSKnf8Rqx9VF2Zh4Vx+oqnhMc70exggeoPNZQJzz+hNUsT50yFYUS\nSwolpdjb59TJquNXpLMxy3Et0bmq80q15Mw+2858CQYlP2uN7DS3kFKiiGrQ6Ibp8JsiGaexrTkE\nap1Ovu22f1t4rKhWLgq3eD+uHhL2zE6zPNu+O3dv8zm8PBiqnDtn/Q35nM0VTE4Y002nbD2O4NEj\nF8w2Ki0x5meesdp3Bca8TlKQVDKz6LK/9c1ned3Wv92w43rtmmWovvGpuTUuotpSJ2yJ5KiSOk6h\nxPfwpT5Zt5HtrVu2H44fnBu6P+Re55kn6guNYHtF3DU7cVVFSpFRUpVk4ynlac+ceV2BVtJxqy/C\nj8F4rjfKJ13/TaVij36BUs9wnZAeP6VEGj7fl++80tiH7gxDYNgBAQEBI4JdZdiOWXP5BsttrUct\ndXLM7ty+hp2WbzVp3vKXhlkqqy1LR2CS6eUjJXOYDnqzabW0SG5uGWqf3TiTF9o+hI0FMjJQSnuK\nFyIYmLZPq78zUojXqIQODKWP//Py4k2WZ8s9fMBUD6t3rZZ4h5ro/ONHnXPOzewlNf2e/X/bd0jR\nMThmDKeK14bUDh2YnjwPdmQfA62wc+4hdz5q8p2Ea16Ojr8+unYxnQq1cB0P+W5LnZLPyV/ch2U6\n55yr0fm1SmfdvjPGvCbH7XvefO1V55xzLWrIqs1KjaHa4kTJPGWKJO9E1PCly+/15FfOyGobNUFf\nzIsRX1YZoLYdD9Afz5BMMiChRynkGXyzc9TIpWZS5l+H/RbJ40WZnvGQe4/Ll61GXykZw634kQK+\n3DD3MrXbVpvUcrJPl8lcJHDJZfkdteVbze/j5KmTbJ+N4C5dsfNwcsLOr8OoM6pkg3523tQqlz63\nuYUHD0x90qKWrxFOWjpmfMqrHHYl82xQUz9Hp+UzZ00tM+g9glMm5oL0cxPNrDEC8yotzt8snjOZ\ngeaw7N+RRlJSc2nOy7ssxkdaej7wP5N4dVm6cKfrQYJhq/Y/SKxfKuFKquvHIB1n8MMQGHZAQEDA\niGBXGXa5YIwxSy2qhI5UnXeVPC5bGdUUSYxA1eFr1DDNLAxdOlKfccedq0HK9hbeEpWc6afTXe68\n1Fg1y9/qxOOKVcPNU7Pzuk/dodWRWTLGVUcdoOJ2lvXuDkQFpLvma3SnzVrN8cTXSZjRyANf4M9R\nSXztOUvmePGVl+1zGVu/y+9ZR9y9y+a1QOnStTprrLetcA6daE+qGXk6ROrUk4ufandpPm/7UZ2F\nHWrR8i7JcDzrZP2p9tckc1MjGB1XHX8/CQCKBWPEXXysb9+xkYMSVmr4Wk+UjcG1u/HEHPk+N9Hz\n5gs6nW1752asJtz2+mjbnhSqgS5Mub5lDF5qGWXtNfE1L6Bv3qyZumIdV7o8zDLDHIr8yH0aNueB\nRipiaNvV4brjiPdfuWgdgWV5pozJO0ZqHvy5qWHP49s8x4i1tm7ngdRTdTJK19GjX8cl7+RTZ5xz\nzn3jaTNe/vx/rG/gtVf/0z5XtxGh3CoHHCcRRHmwKBlKHh+T6PhLHLcCqed9RtBj8zYiGS/gWth5\nxIiU/ZHyvJKadE+TRvag7FGdhwMfwhpXnfX9c31c+m57nu7Ha9hf6Zx2cQYtv/6Up+DxEYEfcffl\naRSfQ9Ny1MkpVZEehyEw7ICAgIARwa4y7N/8zgvOuZ3kF/kq+ztaRrIOubLBnPm8VBrSTUpFohtZ\nT7O1vgPKXvd3WnS+IrzyV47ktdHzxaPYeg98piTfqxRu1ixPrbSdSGaR2kA10x//6K3YcvPotgfe\n99qei+E+uGedlz2K9y98/wfOOef2HzvmnHPu5++cc845V9+mY2/C3NSuX7VZ+w06CrfRP29tGHOs\n1yWEjjNrHQ/5T2tEQ0SkT/Yp43Y3P2eM1bvp5VSbpXaJGiHrk2E0UhGzjs/mZ0l5n5m3/VGg83Fl\n2fbDoYPWGdeorfN9cXWHauB5jdwYarRx0Zui83Jp3UYCBTxs+ml073ivKENPIx2VJgddqU5sRLWd\nWWd78C9Gr61U8rxc4Did7rN+0rOrI09ZhUkcmrXa9R46ahcWrLZ8BX92XzOnQzXPcUvzg8o4jVjZ\n/zy2pD5AN/3SSy+x3nZevPvx284557r4WC/dse9VDRZxlsuV2D72l/oQlG5fwhND/Q5FavBFRiga\nofZ9liQ1/2g4o+x2dN3Q759/qNQrFYdKyZzXfY28vHqDt2mEq+sPr/vrjvo9NELq92OvS5fta9k+\noQmmnVCL6H0Drz4z9PX+ZMJWLz7HNgyBYQcEBASMCHaVYV/5wjq3okheGXQ6Mpv+zbPmFSGG3JMK\nQ51GXiepOxoL9rrMuI5Srn+6D/n7djrOKKU2UZKFZpl1Z+zpRgwzVCZfkzt+Cxs370+8ZbXBe4tW\nO+z1h98h9+OdInWnT9Nme3MZY+5nnrGEnflDpkfu9uVtYUz75sfGqD94i1RyarIrJJI8WCbDEV2s\n7vDS04qBjeFqNjeDNwmz+LPTxqS3VKPGz3yczEr5/Uoloow/qUT0PQX8jv0BWo53tK1TE55H/TI3\nZm50q8vWCXhwn+lz5Ztcrdp6LN23uYEMNckctVDPjKhxKpW6QS1aLm/qBB1Hh6ySoqJh2h37fB1/\n5+1WPMMy4nxaJqFE59UE2X86rnlq2x3mTKSLXrx/yw1Dq2HnlRidvFnkerhJR2GWOR3p3lWLdwkP\nCq1nj/2Ux/NDv4wPP3jfOefcrz9reuufXTEmL2+SAh2jhZJth3T4Y9TWizwvoDNXlmghH6/pC2LW\n+v33cC/sP+L34vXtXu0T/52m0Xtr7kXiG9Wed9iodNXx/dPn9U6CefsRuy47casPz5x1PDsawfDG\nnYqAi2+fX75UZo71Z6TaG8TfPwSBYQcEBASMCHaVYb/+5jnnnHNRojMoRy3u0H6SFbizSBeboxa4\nUwtCdaBEiIRO0fvbepmlElMSHiWeqOMGmIrXnNOJWnZPDBs9bZPZ/mZLumarAd68Y7rUm7et46vG\nbHwSB3H9E5SkooHD7KwxyvFxYzxNGJdqmMs3rLZYXTamVSURQyMR1ZA9Y5S6pq+5AHu5TK3xwB7r\noJyCOcv9MIMOuy6dq2qZ6lxjxKROUnVySY/rPSA4TuqETGJt3RjW2prtxzSp6xspqVTsew7h8hah\nIx4njbyYU5YiDAeVwhguaa260uBhPN14J5kYYp/Xlzes5nx3yZjzMh2YtZq9Pla25WySFHJ3yTpO\nxbQ0MlNSjpiYarEaqbVawzth5f0hJinXvb177LwolWzE0+C8kA5avyzvu+19uB/+r3ObnB8XzpvP\n9rNkG3Y6dr6urdl5PDdn+y9PJ+GkXBjLNoLI5Yx5a2So7ZceOR0largwUJ0vO7Vd1rc9XJi+U8uV\nK2ai1u3bIDTSls5Zr3NdieJM3C+H/aPrQBMVkmTVfo7Ne33wPf54MwLoxRlxlLiqep/7hApEbp3q\n79D6B5VIQEBAwP8D7CrD/t5vPB17rllyud1NwcikyqAxz6sLdD/pJTrxKt7tLq7HTaXid+SdhAl5\nRiQ8ArwOki9WJ5pn9izO30Cl+4VBm0jDHT5inZVP45Gwvm7M94c//OfY9u87POPiiDP/HN4grY59\n/r23zjnnnFu4YD7MTfS/fWrGk9PGNJfwO05n6FQs2vZtwzDTUPkSGYiHDth6zE+pFonaAL30MuqG\nrNLkt4zpZZA/zM7a99ZJna/AuHrU0pXgIf3z3H6SOc7HPTSUpJOmplw5YiOu2clS7LFZN6bbd3F1\ngmbnP/ncavrrMOT0Sav937hjCSuVCfv+AefB5ra9b+muLfcucw93UOnUYLaqIT9x1Grrs+i61XEo\npr+xaZ+/ituesjSlCiqRwNLEy+PGwpIbhg77T3MMmguY4TjnkGtsbthxrurEpFNQHZZZzoM2TLvr\ndcD2/N3/OmfbyXp/fsE8bY7vR8+NV0qlYudFnhp1ytnzKKURW1JdFWfU3ldac1S+ds16MfLQ+5J4\n5fmfsLw4Q9Xv5gbugppLkapL57FGAP76wKNGBJrjUK0/o+sJIzK1SHr3Td8RyVp417+E/tp3Oupj\nwxnzV5l0KvH4VQSGHRAQEDAi2FWG/Z1vWy22q/BDP4st1QK6V+7Y0jl7VQPJFZkonjixcwdSbQqG\nITWIrECkk1YNi0/19TnfucTrPakApOOO67yFAh16ugPrzu5rlQeGz/JOwUy/An9DZUTRtceJKatd\nfvfF33POOVdkfzXxz776pTHLn/6HuSJeu2LP5RZYIvmlj7fCJLXkM0+Zl0TBjzDwXKBGf3/VGHtX\nHiTUyptk2s1OGBNOH4D5UEPeogY7wKMhx3bN75sdutlVdOLz87ade3isFKXegRFv2nJv3zdGuLph\nKpjqltVyF5fs9RyJPW//3Dr2vrxmDCyL18c1GHAdf+/uQIyUjj1GdmePH3HOObeXWm6fhBXp9707\nHsd/lk5DMeQay1/Bi2QTtc0YNfNFvDiSSI4Yi0U7ftmsHYcMKeTlghJySOtGB9727pOqZaPCkLqB\nEYp836+QNHPqhKmX9s3GVR9KPX+oWPxL0fM12jiz9rV8fo/+d/IrOvu0HvqvdNQpfucFeZjIbxrG\n7Dugo/hIQI+eiXP85DEi1ZFG5LqQpBIZqJ5hy6TEy7LTD3/soTmzOBL/fmgL494lwxAYdkBAQMCI\nYFcZ9goubL3EHTbyHUFKionXbtK+Iw+9I7VpLWfnzhn/nP+/76BMqEm4k/bVQaVORv7f8x2ZBn/f\n12yydK2oR7qJGp2vXUXDVQDj08kadhwDvAzGx4xpPvvt32bFxZhIACF55uivnXXOObf3mDGk13/y\n784557apTSr9ewVmqprlNjXmAh116ojsU0seSNFKrfHgvBXre6Sod/GmyHJc7vP5iFr23F5S42H6\nh48/NnR7jxyw9z111rI/91A7XVk2ZvrmO6ZmWFoxRr1RJZtR+nIxGmr0bWr75y9etfWlY7TfJTmI\nkYIiQGamjSmffMyOy4G9e5xzzpXz8rIh8YUs0pZ3b4Q5wlRLuBVKHVJCZdPAtXBRWZ6aU4mG1yiT\nnXKZSLVseegwh+NTyW0EoPOwnUjb9ioezlvpqMslJQ3J79wgP+209wMXY5eaIe6J4b0xPJOWblqq\nBzHGOJNOMu9H6Y7lX6/fYderOhzrH2e0YspevZJQsUgX7mva/EwzqoF7P2y+0Neqk8yaf6d9Fk5s\ne31NO+ExopGF/i89fd8zdKlo4hWEhxEYdkBAQMCIIJX0eA0ICAgI+L+JwLADAgICRgThgh0QEBAw\nIggX7ICAgIARQbhgBwQEBIwIwgU7ICAgYEQQLtgBAQEBI4JwwQ4ICAgYEYQLdkBAQMCIIFywAwIC\nAkYE4YIdEBAQMCIIF+yAgICAEUG4YAcEBASMCMIFOyAgIGBEEC7YAQEBASOCcMEOCAgIGBGEC3ZA\nQEDAiCBcsAMCAgJGBOGCHRAQEDAiCBfsgICAgBFBuGAHBAQEjAj+FwLklcKfrrAwAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f72083a7350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Transform(object):\n",
    "    def __init__(self, rng=None):\n",
    "        if rng == None:\n",
    "            rng = numpy.random\n",
    "        self.rng = rng\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X\n",
    "    \n",
    "    def name(self):\n",
    "        return \"Identity transformation\"\n",
    "\n",
    "class Shift(Transform):\n",
    "    def __init__(self, shift_size=4, **kwargs):\n",
    "        super(Shift, self).__init__(**kwargs)\n",
    "        self.shift_size = shift_size\n",
    "        \n",
    "    def transform(self, X):\n",
    "        res = X\n",
    "        for i in xrange(res.shape[0]):\n",
    "            res[i] = np.roll(res[i], self.rng.randint(-self.shift_size, self.shift_size + 1), axis=1)\n",
    "            res[i] = np.roll(res[i], self.rng.randint(-self.shift_size, self.shift_size + 1), axis=2)\n",
    "        return res\n",
    "    \n",
    "    def name(self):\n",
    "        return \"Random shift by %d\" % self.shift.size\n",
    "    \n",
    "trans = [trans() for trans in Transform.__subclasses__()]\n",
    "def random_transform(X_batch):\n",
    "    global trans\n",
    "    return trans[np.random.randint(0, len(trans))].transform(X_batch)\n",
    "\n",
    "# example of transformation\n",
    "for X_batch, Y_batch in cifar10_train_stream.get_epoch_iterator():\n",
    "    X = X_batch\n",
    "    break\n",
    "X = random_transform(X[:10])\n",
    "plot_mat(X, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeedForwardNet(object):\n",
    "    def __init__(self, layers=None):\n",
    "        if layers == None:\n",
    "            layers = []\n",
    "        self.layers = layers\n",
    "        self.log_probs = None\n",
    "        self.predictions = None\n",
    "        self.error_rate = None\n",
    "        self.nll = None\n",
    "        self.weight_decay = None\n",
    "        self.cost = None\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        for layer in self.layers:\n",
    "            params += layer.parameters\n",
    "        return params\n",
    "    \n",
    "    def initialize(self, X, learning_on, wdec_const):\n",
    "        theano.config.compute_test_value = 'off'\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            X = layer.fprop(X, learning_on)\n",
    "        \n",
    "        self.log_probs = theano.tensor.nnet.softmax(X)\n",
    "        self.predictions = theano.tensor.argmax(self.log_probs, axis=1)\n",
    "        self.error_rate = theano.tensor.neq(self.predictions,Y.ravel()).mean()\n",
    "        self.nll = - theano.tensor.log(self.log_probs[theano.tensor.arange(Y.shape[0]), Y.ravel()]).mean()\n",
    "        self.weight_decay = 0.0\n",
    "        for p in self.parameters:\n",
    "            if p.name[1]=='W':\n",
    "                self.weight_decay = self.weight_decay + wdec_const * (p**2).sum()\n",
    "        self.cost = self.nll + self.weight_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X is batch_size x num_channels x img_rows x img_columns\n",
    "X = theano.tensor.tensor4('X')\n",
    "Y = theano.tensor.matrix('Y', dtype='uint8')\n",
    "X_test_value, Y_test_value = next(cifar10_train_stream.get_epoch_iterator())\n",
    "X.tag.test_value = X_test_value[:3]\n",
    "Y.tag.test_value = Y_test_value[:3]\n",
    "learning_on = theano.tensor.lscalar('learning_on')\n",
    "\n",
    "net = FeedForwardNet(layers=[\n",
    "        Conv(3,  50,  filter_size=5),  ReLU(), MaxPool(2), Dropout(0.2),\n",
    "        Conv(50, 100, filter_size=5),  ReLU(), MaxPool(2), Dropout(0.2),\n",
    "        Flatten(2),\n",
    "        Affine(100*11*11, 500), ReLU(), Dropout(0.5),\n",
    "        Affine(500, 500),       ReLU(), Dropout(0.5),\n",
    "        Affine(500, 100),       ReLU(), Dropout(0.5),\n",
    "        Affine(100, 10)\n",
    "    ])\n",
    "\n",
    "net.initialize(X, learning_on, wdec_const=2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The updates will update our shared values\n",
    "updates = []\n",
    "\n",
    "lrate = theano.tensor.scalar('lrate',dtype='float32')\n",
    "momentum = theano.tensor.scalar('momentum',dtype='float32')\n",
    "\n",
    "\n",
    "# Theano will compute the gradients for us\n",
    "gradients = theano.grad(net.cost, net.parameters)\n",
    "\n",
    "#initialize storage for momentum\n",
    "velocities = [theano.shared(np.zeros_like(p.get_value()), name='V_%s' %(p.name, )) for p in net.parameters]\n",
    "\n",
    "for p,g,v in zip(net.parameters, gradients, velocities):\n",
    "    v_new = momentum * v - lrate * g\n",
    "    p_new = p + v_new\n",
    "    updates += [(v,v_new), (p, p_new)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compile theano functions\n",
    "\n",
    "#each call to train step will make one SGD step\n",
    "train_step = theano.function([X,Y,lrate,momentum,learning_on],\n",
    "                             [net.cost, net.error_rate, net.nll, net.weight_decay],\n",
    "                             updates=updates)\n",
    "#each call to predict will return predictions on a batch of data\n",
    "predict = theano.function([X,learning_on], net.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_error_rate(stream):\n",
    "    errs = 0.0\n",
    "    num_samples = 0.0\n",
    "    for X, Y in stream.get_epoch_iterator():\n",
    "        errs += (predict(X, 0)!=Y.ravel()).sum()\n",
    "        num_samples += Y.shape[0]\n",
    "    return errs/num_samples\n",
    "\n",
    "\n",
    "#utilities to save values of parameters and to load them\n",
    "\n",
    "def init_parameters():\n",
    "    rng = np.random.RandomState(1234)\n",
    "    for p in net.parameters:\n",
    "        p.set_value(p.tag.initializer.generate(rng, p.get_value().shape))\n",
    "\n",
    "def snapshot_parameters():\n",
    "    return [p.get_value(borrow=False) for p in net.parameters]\n",
    "\n",
    "def load_parameters(snapshot):\n",
    "    for p, s in zip(net.parameters, snapshot):\n",
    "        p.set_value(s, borrow=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started at 21:37:12\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 1, took 79.8222s\n",
      "valid_err_rate:          48.240000% currently going to do 3 epochs\n",
      "averaged train_err_rate: 60.617500% averaged train nll: 1.649031 averaged train loss: 7.150473\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 2, took 79.5008s\n",
      "valid_err_rate:          45.520000% currently going to do 6 epochs\n",
      "averaged train_err_rate: 49.087500% averaged train nll: 1.358639 averaged train loss: 3.068937\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 3, took 79.6221s\n",
      "valid_err_rate:          39.820000% currently going to do 8 epochs\n",
      "averaged train_err_rate: 44.037500% averaged train nll: 1.237807 averaged train loss: 1.942275\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 4, took 79.8575s\n",
      "valid_err_rate:          36.530000% currently going to do 11 epochs\n",
      "averaged train_err_rate: 41.497500% averaged train nll: 1.168730 averaged train loss: 1.624932\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 5, took 76.7361s\n",
      "valid_err_rate:          37.270000% currently going to do 11 epochs\n",
      "averaged train_err_rate: 39.695000% averaged train nll: 1.126623 averaged train loss: 1.531489\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 6, took 79.5786s\n",
      "valid_err_rate:          34.230000% currently going to do 16 epochs\n",
      "averaged train_err_rate: 38.537500% averaged train nll: 1.094140 averaged train loss: 1.501546\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 7, took 79.9482s\n",
      "valid_err_rate:          32.510000% currently going to do 18 epochs\n",
      "averaged train_err_rate: 36.617500% averaged train nll: 1.056801 averaged train loss: 1.470452\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 8, took 79.8941s\n",
      "valid_err_rate:          30.720000% currently going to do 21 epochs\n",
      "averaged train_err_rate: 35.282500% averaged train nll: 1.004964 averaged train loss: 1.423663\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 9, took 76.3726s\n",
      "valid_err_rate:          31.710000% currently going to do 21 epochs\n",
      "averaged train_err_rate: 33.617500% averaged train nll: 0.963612 averaged train loss: 1.382897\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 10, took 79.4126s\n",
      "valid_err_rate:          29.390000% currently going to do 26 epochs\n",
      "averaged train_err_rate: 31.950000% averaged train nll: 0.918055 averaged train loss: 1.337447\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 11, took 80.3906s\n",
      "valid_err_rate:          29.250000% currently going to do 28 epochs\n",
      "averaged train_err_rate: 30.737500% averaged train nll: 0.882934 averaged train loss: 1.303974\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 12, took 76.1940s\n",
      "valid_err_rate:          32.540000% currently going to do 28 epochs\n",
      "averaged train_err_rate: 29.880000% averaged train nll: 0.853221 averaged train loss: 1.274952\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 13, took 79.2336s\n",
      "valid_err_rate:          27.940000% currently going to do 33 epochs\n",
      "averaged train_err_rate: 28.955000% averaged train nll: 0.822885 averaged train loss: 1.245204\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 14, took 80.0260s\n",
      "valid_err_rate:          26.310000% currently going to do 36 epochs\n",
      "averaged train_err_rate: 28.105000% averaged train nll: 0.802598 averaged train loss: 1.224440\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 15, took 79.3402s\n",
      "valid_err_rate:          25.120000% currently going to do 38 epochs\n",
      "averaged train_err_rate: 27.145000% averaged train nll: 0.776245 averaged train loss: 1.201211\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 16, took 76.7836s\n",
      "valid_err_rate:          26.070000% currently going to do 38 epochs\n",
      "averaged train_err_rate: 26.552500% averaged train nll: 0.762205 averaged train loss: 1.188518\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 17, took 76.3260s\n",
      "valid_err_rate:          25.270000% currently going to do 38 epochs\n",
      "averaged train_err_rate: 25.777500% averaged train nll: 0.737962 averaged train loss: 1.165240\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 18, took 76.3604s\n",
      "valid_err_rate:          25.900000% currently going to do 38 epochs\n",
      "averaged train_err_rate: 24.935000% averaged train nll: 0.720027 averaged train loss: 1.148475\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 19, took 80.2893s\n",
      "valid_err_rate:          23.390000% currently going to do 48 epochs\n",
      "averaged train_err_rate: 24.570000% averaged train nll: 0.699519 averaged train loss: 1.130833\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 20, took 76.7639s\n",
      "valid_err_rate:          24.850000% currently going to do 48 epochs\n",
      "averaged train_err_rate: 23.910000% averaged train nll: 0.686460 averaged train loss: 1.117404\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 21, took 76.3590s\n",
      "valid_err_rate:          24.280000% currently going to do 48 epochs\n",
      "averaged train_err_rate: 23.307500% averaged train nll: 0.670421 averaged train loss: 1.104297\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 22, took 80.5969s\n",
      "valid_err_rate:          22.590000% currently going to do 56 epochs\n",
      "averaged train_err_rate: 22.940000% averaged train nll: 0.653927 averaged train loss: 1.089906\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 23, took 76.7522s\n",
      "valid_err_rate:          25.860000% currently going to do 56 epochs\n",
      "averaged train_err_rate: 22.220000% averaged train nll: 0.633976 averaged train loss: 1.070749\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 24, took 79.9844s\n",
      "valid_err_rate:          22.370000% currently going to do 61 epochs\n",
      "averaged train_err_rate: 22.097500% averaged train nll: 0.633737 averaged train loss: 1.071073\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 25, took 80.4921s\n",
      "valid_err_rate:          21.430000% currently going to do 63 epochs\n",
      "averaged train_err_rate: 21.552500% averaged train nll: 0.618164 averaged train loss: 1.056976\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 26, took 76.1339s\n",
      "valid_err_rate:          23.410000% currently going to do 63 epochs\n",
      "averaged train_err_rate: 21.070000% averaged train nll: 0.604864 averaged train loss: 1.045355\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 27, took 76.2069s\n",
      "valid_err_rate:          23.010000% currently going to do 63 epochs\n",
      "averaged train_err_rate: 20.842500% averaged train nll: 0.600210 averaged train loss: 1.042237\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 28, took 76.1199s\n",
      "valid_err_rate:          21.960000% currently going to do 63 epochs\n",
      "averaged train_err_rate: 20.372500% averaged train nll: 0.586391 averaged train loss: 1.029882\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 29, took 76.1144s\n",
      "valid_err_rate:          21.680000% currently going to do 63 epochs\n",
      "averaged train_err_rate: 20.005000% averaged train nll: 0.570800 averaged train loss: 1.015481\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 30, took 80.1201s\n",
      "valid_err_rate:          20.420000% currently going to do 76 epochs\n",
      "averaged train_err_rate: 19.807500% averaged train nll: 0.567264 averaged train loss: 1.013350\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 31, took 80.4201s\n",
      "valid_err_rate:          20.160000% currently going to do 78 epochs\n",
      "averaged train_err_rate: 19.422500% averaged train nll: 0.556441 averaged train loss: 1.004429\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 32, took 76.1311s\n",
      "valid_err_rate:          20.190000% currently going to do 78 epochs\n",
      "averaged train_err_rate: 18.842500% averaged train nll: 0.545017 averaged train loss: 0.994328\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 33, took 76.2748s\n",
      "valid_err_rate:          22.670000% currently going to do 78 epochs\n",
      "averaged train_err_rate: 18.477500% averaged train nll: 0.534435 averaged train loss: 0.985175\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 34, took 76.2629s\n",
      "valid_err_rate:          20.740000% currently going to do 78 epochs\n",
      "averaged train_err_rate: 18.505000% averaged train nll: 0.531869 averaged train loss: 0.983860\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 35, took 76.3159s\n",
      "valid_err_rate:          21.640000% currently going to do 78 epochs\n",
      "averaged train_err_rate: 18.192500% averaged train nll: 0.518585 averaged train loss: 0.972256\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 36, took 76.3438s\n",
      "valid_err_rate:          20.690000% currently going to do 78 epochs\n",
      "averaged train_err_rate: 17.647500% averaged train nll: 0.515010 averaged train loss: 0.969556\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 37, took 76.3605s\n",
      "valid_err_rate:          20.760000% currently going to do 78 epochs\n",
      "averaged train_err_rate: 17.592500% averaged train nll: 0.506224 averaged train loss: 0.961908\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 38, took 80.4001s\n",
      "valid_err_rate:          19.930000% currently going to do 96 epochs\n",
      "averaged train_err_rate: 17.277500% averaged train nll: 0.499674 averaged train loss: 0.956243\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 39, took 76.6619s\n",
      "valid_err_rate:          20.500000% currently going to do 96 epochs\n",
      "averaged train_err_rate: 17.037500% averaged train nll: 0.488294 averaged train loss: 0.946106\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 40, took 80.6524s\n",
      "valid_err_rate:          19.730000% currently going to do 101 epochs\n",
      "averaged train_err_rate: 16.665000% averaged train nll: 0.482140 averaged train loss: 0.940944\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 41, took 76.7015s\n",
      "valid_err_rate:          20.190000% currently going to do 101 epochs\n",
      "averaged train_err_rate: 16.425000% averaged train nll: 0.478202 averaged train loss: 0.939162\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 42, took 76.2842s\n",
      "valid_err_rate:          21.060000% currently going to do 101 epochs\n",
      "averaged train_err_rate: 16.285000% averaged train nll: 0.470274 averaged train loss: 0.932998\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 43, took 80.1595s\n",
      "valid_err_rate:          19.690000% currently going to do 108 epochs\n",
      "averaged train_err_rate: 16.107500% averaged train nll: 0.464995 averaged train loss: 0.928789\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 44, took 80.5294s\n",
      "valid_err_rate:          18.920000% currently going to do 111 epochs\n",
      "averaged train_err_rate: 15.725000% averaged train nll: 0.456513 averaged train loss: 0.921036\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 45, took 76.3173s\n",
      "valid_err_rate:          19.080000% currently going to do 111 epochs\n",
      "averaged train_err_rate: 15.635000% averaged train nll: 0.453475 averaged train loss: 0.919401\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 46, took 79.8422s\n",
      "valid_err_rate:          18.770000% currently going to do 116 epochs\n",
      "averaged train_err_rate: 15.357500% averaged train nll: 0.446067 averaged train loss: 0.912943\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 47, took 76.5314s\n",
      "valid_err_rate:          19.800000% currently going to do 116 epochs\n",
      "averaged train_err_rate: 14.970000% averaged train nll: 0.430965 averaged train loss: 0.899384\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 48, took 76.1134s\n",
      "valid_err_rate:          19.120000% currently going to do 116 epochs\n",
      "averaged train_err_rate: 15.055000% averaged train nll: 0.436274 averaged train loss: 0.905330\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 49, took 80.6465s\n",
      "valid_err_rate:          18.740000% currently going to do 123 epochs\n",
      "averaged train_err_rate: 14.662500% averaged train nll: 0.427030 averaged train loss: 0.896739\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 50, took 76.7101s\n",
      "valid_err_rate:          19.010000% currently going to do 123 epochs\n",
      "averaged train_err_rate: 14.625000% averaged train nll: 0.421003 averaged train loss: 0.891677\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 51, took 80.0410s\n",
      "valid_err_rate:          18.720000% currently going to do 128 epochs\n",
      "averaged train_err_rate: 14.260000% averaged train nll: 0.415397 averaged train loss: 0.887614\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 52, took 81.3022s\n",
      "valid_err_rate:          18.620000% currently going to do 131 epochs\n",
      "averaged train_err_rate: 14.035000% averaged train nll: 0.409146 averaged train loss: 0.882805\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 53, took 76.3342s\n",
      "valid_err_rate:          18.760000% currently going to do 131 epochs\n",
      "averaged train_err_rate: 13.677500% averaged train nll: 0.402268 averaged train loss: 0.877204\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 54, took 76.3154s\n",
      "valid_err_rate:          19.090000% currently going to do 131 epochs\n",
      "averaged train_err_rate: 13.605000% averaged train nll: 0.399391 averaged train loss: 0.875594\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 55, took 76.3120s\n",
      "valid_err_rate:          19.210000% currently going to do 131 epochs\n",
      "averaged train_err_rate: 13.252500% averaged train nll: 0.389946 averaged train loss: 0.866934\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 56, took 76.3125s\n",
      "valid_err_rate:          18.620000% currently going to do 131 epochs\n",
      "averaged train_err_rate: 13.485000% averaged train nll: 0.391304 averaged train loss: 0.868963\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 57, took 79.3917s\n",
      "valid_err_rate:          18.240000% currently going to do 143 epochs\n",
      "averaged train_err_rate: 13.302500% averaged train nll: 0.385193 averaged train loss: 0.864186\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 58, took 76.6267s\n",
      "valid_err_rate:          18.370000% currently going to do 143 epochs\n",
      "averaged train_err_rate: 13.010000% averaged train nll: 0.381487 averaged train loss: 0.861640\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 59, took 76.3296s\n",
      "valid_err_rate:          18.830000% currently going to do 143 epochs\n",
      "averaged train_err_rate: 12.785000% averaged train nll: 0.377803 averaged train loss: 0.858232\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 60, took 76.4100s\n",
      "valid_err_rate:          18.690000% currently going to do 143 epochs\n",
      "averaged train_err_rate: 12.570000% averaged train nll: 0.369870 averaged train loss: 0.851140\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 61, took 76.3462s\n",
      "valid_err_rate:          19.260000% currently going to do 143 epochs\n",
      "averaged train_err_rate: 12.472500% averaged train nll: 0.363723 averaged train loss: 0.846052\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 62, took 76.3306s\n",
      "valid_err_rate:          18.940000% currently going to do 143 epochs\n",
      "averaged train_err_rate: 12.347500% averaged train nll: 0.360703 averaged train loss: 0.843589\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 63, took 76.3535s\n",
      "valid_err_rate:          19.190000% currently going to do 143 epochs\n",
      "averaged train_err_rate: 12.267500% averaged train nll: 0.358985 averaged train loss: 0.842572\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 64, took 76.3215s\n",
      "valid_err_rate:          19.390000% currently going to do 143 epochs\n",
      "averaged train_err_rate: 12.145000% averaged train nll: 0.357698 averaged train loss: 0.841489\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 65, took 79.3824s\n",
      "valid_err_rate:          17.710000% currently going to do 163 epochs\n",
      "averaged train_err_rate: 11.935000% averaged train nll: 0.347215 averaged train loss: 0.831725\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 66, took 76.7555s\n",
      "valid_err_rate:          18.170000% currently going to do 163 epochs\n",
      "averaged train_err_rate: 11.812500% averaged train nll: 0.345665 averaged train loss: 0.830752\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 67, took 76.3472s\n",
      "valid_err_rate:          17.720000% currently going to do 163 epochs\n",
      "averaged train_err_rate: 11.622500% averaged train nll: 0.344587 averaged train loss: 0.830298\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 68, took 76.3668s\n",
      "valid_err_rate:          18.040000% currently going to do 163 epochs\n",
      "averaged train_err_rate: 11.290000% averaged train nll: 0.340104 averaged train loss: 0.827065\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 69, took 76.3431s\n",
      "valid_err_rate:          19.030000% currently going to do 163 epochs\n",
      "averaged train_err_rate: 11.167500% averaged train nll: 0.335731 averaged train loss: 0.822859\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 70, took 76.3689s\n",
      "valid_err_rate:          18.230000% currently going to do 163 epochs\n",
      "averaged train_err_rate: 11.335000% averaged train nll: 0.332251 averaged train loss: 0.819486\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 71, took 76.3646s\n",
      "valid_err_rate:          18.650000% currently going to do 163 epochs\n",
      "averaged train_err_rate: 11.092500% averaged train nll: 0.326358 averaged train loss: 0.814794\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 72, took 76.3348s\n",
      "valid_err_rate:          19.170000% currently going to do 163 epochs\n",
      "averaged train_err_rate: 10.930000% averaged train nll: 0.325495 averaged train loss: 0.814513\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 73, took 76.2764s\n",
      "valid_err_rate:          18.880000% currently going to do 163 epochs\n",
      "averaged train_err_rate: 10.845000% averaged train nll: 0.319732 averaged train loss: 0.808967\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 74, took 76.2551s\n",
      "valid_err_rate:          18.170000% currently going to do 163 epochs\n",
      "averaged train_err_rate: 10.795000% averaged train nll: 0.316896 averaged train loss: 0.806441\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 75, took 76.2635s\n",
      "valid_err_rate:          18.750000% currently going to do 163 epochs\n",
      "averaged train_err_rate: 10.477500% averaged train nll: 0.312798 averaged train loss: 0.802861\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 76, took 76.2517s\n",
      "valid_err_rate:          17.770000% currently going to do 163 epochs\n",
      "averaged train_err_rate: 10.195000% averaged train nll: 0.305307 averaged train loss: 0.795863\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 77, took 76.2435s\n",
      "valid_err_rate:          18.400000% currently going to do 163 epochs\n",
      "averaged train_err_rate: 10.285000% averaged train nll: 0.312353 averaged train loss: 0.802854\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 78, took 79.3822s\n",
      "valid_err_rate:          17.380000% currently going to do 196 epochs\n",
      "averaged train_err_rate: 10.207500% averaged train nll: 0.306981 averaged train loss: 0.797621\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 79, took 76.7563s\n",
      "valid_err_rate:          17.870000% currently going to do 196 epochs\n",
      "averaged train_err_rate: 10.092500% averaged train nll: 0.304314 averaged train loss: 0.795254\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 80, took 76.3407s\n",
      "valid_err_rate:          18.730000% currently going to do 196 epochs\n",
      "averaged train_err_rate: 10.035000% averaged train nll: 0.298128 averaged train loss: 0.789372\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 81, took 76.3670s\n",
      "valid_err_rate:          18.030000% currently going to do 196 epochs\n",
      "averaged train_err_rate: 9.650000% averaged train nll: 0.294840 averaged train loss: 0.786628\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 82, took 76.1996s\n",
      "valid_err_rate:          17.700000% currently going to do 196 epochs\n",
      "averaged train_err_rate: 9.557500% averaged train nll: 0.288298 averaged train loss: 0.780106\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 83, took 76.1502s\n",
      "valid_err_rate:          18.670000% currently going to do 196 epochs\n",
      "averaged train_err_rate: 9.527500% averaged train nll: 0.287874 averaged train loss: 0.780418\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 84, took 76.0967s\n",
      "valid_err_rate:          17.430000% currently going to do 196 epochs\n",
      "averaged train_err_rate: 9.432500% averaged train nll: 0.284946 averaged train loss: 0.777756\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 85, took 76.1019s\n",
      "valid_err_rate:          18.630000% currently going to do 196 epochs\n",
      "averaged train_err_rate: 9.495000% averaged train nll: 0.285659 averaged train loss: 0.778590\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 86, took 76.0471s\n",
      "valid_err_rate:          18.810000% currently going to do 196 epochs\n",
      "averaged train_err_rate: 9.132500% averaged train nll: 0.280015 averaged train loss: 0.773160\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 87, took 76.0847s\n",
      "valid_err_rate:          18.780000% currently going to do 196 epochs\n",
      "averaged train_err_rate: 9.040000% averaged train nll: 0.277616 averaged train loss: 0.771159\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 88, took 76.0794s\n",
      "valid_err_rate:          18.080000% currently going to do 196 epochs\n",
      "averaged train_err_rate: 9.105000% averaged train nll: 0.279141 averaged train loss: 0.772823\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 89, took 76.0733s\n",
      "valid_err_rate:          18.040000% currently going to do 196 epochs\n",
      "averaged train_err_rate: 9.157500% averaged train nll: 0.276372 averaged train loss: 0.769982\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 90, took 79.1594s\n",
      "valid_err_rate:          17.340000% currently going to do 226 epochs\n",
      "averaged train_err_rate: 8.852500% averaged train nll: 0.272312 averaged train loss: 0.766484\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 91, took 76.5862s\n",
      "valid_err_rate:          18.440000% currently going to do 226 epochs\n",
      "averaged train_err_rate: 8.777500% averaged train nll: 0.268621 averaged train loss: 0.763420\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 92, took 76.2292s\n",
      "valid_err_rate:          17.720000% currently going to do 226 epochs\n",
      "averaged train_err_rate: 8.657500% averaged train nll: 0.266918 averaged train loss: 0.761804\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 93, took 76.3574s\n",
      "valid_err_rate:          18.190000% currently going to do 226 epochs\n",
      "averaged train_err_rate: 8.535000% averaged train nll: 0.263865 averaged train loss: 0.758630\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 94, took 76.3761s\n",
      "valid_err_rate:          18.650000% currently going to do 226 epochs\n",
      "averaged train_err_rate: 8.745000% averaged train nll: 0.265519 averaged train loss: 0.760539\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 95, took 76.3806s\n",
      "valid_err_rate:          17.870000% currently going to do 226 epochs\n",
      "averaged train_err_rate: 8.430000% averaged train nll: 0.260268 averaged train loss: 0.755484\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 96, took 76.3621s\n",
      "valid_err_rate:          18.120000% currently going to do 226 epochs\n",
      "averaged train_err_rate: 8.362500% averaged train nll: 0.258688 averaged train loss: 0.754061\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 97, took 76.3493s\n",
      "valid_err_rate:          17.670000% currently going to do 226 epochs\n",
      "averaged train_err_rate: 8.307500% averaged train nll: 0.257640 averaged train loss: 0.752911\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 98, took 76.3716s\n",
      "valid_err_rate:          18.070000% currently going to do 226 epochs\n",
      "averaged train_err_rate: 8.165000% averaged train nll: 0.252477 averaged train loss: 0.748129\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 99, took 76.3215s\n",
      "valid_err_rate:          17.530000% currently going to do 226 epochs\n",
      "averaged train_err_rate: 8.125000% averaged train nll: 0.249403 averaged train loss: 0.745298\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 100, took 76.3534s\n",
      "valid_err_rate:          18.150000% currently going to do 226 epochs\n",
      "averaged train_err_rate: 8.055000% averaged train nll: 0.248957 averaged train loss: 0.744688\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 101, took 76.3773s\n",
      "valid_err_rate:          18.280000% currently going to do 226 epochs\n",
      "averaged train_err_rate: 7.835000% averaged train nll: 0.247301 averaged train loss: 0.743350\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 102, took 76.3674s\n",
      "valid_err_rate:          17.780000% currently going to do 226 epochs\n",
      "averaged train_err_rate: 7.932500% averaged train nll: 0.247038 averaged train loss: 0.743057\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 103, took 76.3453s\n",
      "valid_err_rate:          18.590000% currently going to do 226 epochs\n",
      "averaged train_err_rate: 7.895000% averaged train nll: 0.246729 averaged train loss: 0.742533\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 104, took 76.3313s\n",
      "valid_err_rate:          17.590000% currently going to do 226 epochs\n",
      "averaged train_err_rate: 7.570000% averaged train nll: 0.240105 averaged train loss: 0.735840\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 105, took 76.2038s\n",
      "valid_err_rate:          18.320000% currently going to do 226 epochs\n",
      "averaged train_err_rate: 7.597500% averaged train nll: 0.239373 averaged train loss: 0.734999\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 106, took 76.1592s\n",
      "valid_err_rate:          17.750000% currently going to do 226 epochs\n",
      "averaged train_err_rate: 7.625000% averaged train nll: 0.239338 averaged train loss: 0.734986\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 107, took 76.0109s\n",
      "valid_err_rate:          18.060000% currently going to do 226 epochs\n",
      "averaged train_err_rate: 7.455000% averaged train nll: 0.235576 averaged train loss: 0.731312\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 108, took 79.2717s\n",
      "valid_err_rate:          17.220000% currently going to do 271 epochs\n",
      "averaged train_err_rate: 7.527500% averaged train nll: 0.236193 averaged train loss: 0.732350\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 109, took 76.5560s\n",
      "valid_err_rate:          17.500000% currently going to do 271 epochs\n",
      "averaged train_err_rate: 7.420000% averaged train nll: 0.234689 averaged train loss: 0.730855\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 110, took 76.2062s\n",
      "valid_err_rate:          17.880000% currently going to do 271 epochs\n",
      "averaged train_err_rate: 7.197500% averaged train nll: 0.229902 averaged train loss: 0.725814\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 111, took 76.1729s\n",
      "valid_err_rate:          18.070000% currently going to do 271 epochs\n",
      "averaged train_err_rate: 7.210000% averaged train nll: 0.227445 averaged train loss: 0.723411\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 112, took 76.1779s\n",
      "valid_err_rate:          18.090000% currently going to do 271 epochs\n",
      "averaged train_err_rate: 7.210000% averaged train nll: 0.227801 averaged train loss: 0.723873\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 113, took 76.1724s\n",
      "valid_err_rate:          17.340000% currently going to do 271 epochs\n",
      "averaged train_err_rate: 7.245000% averaged train nll: 0.226532 averaged train loss: 0.722682\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 114, took 76.1942s\n",
      "valid_err_rate:          17.360000% currently going to do 271 epochs\n",
      "averaged train_err_rate: 6.952500% averaged train nll: 0.222708 averaged train loss: 0.718635\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 115, took 76.1447s\n",
      "valid_err_rate:          17.700000% currently going to do 271 epochs\n",
      "averaged train_err_rate: 6.957500% averaged train nll: 0.220491 averaged train loss: 0.716107\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 116, took 76.0996s\n",
      "valid_err_rate:          17.490000% currently going to do 271 epochs\n",
      "averaged train_err_rate: 6.917500% averaged train nll: 0.221826 averaged train loss: 0.717418\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 117, took 76.3595s\n",
      "valid_err_rate:          17.930000% currently going to do 271 epochs\n",
      "averaged train_err_rate: 6.885000% averaged train nll: 0.217734 averaged train loss: 0.713326\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 118, took 76.3281s\n",
      "valid_err_rate:          17.690000% currently going to do 271 epochs\n",
      "averaged train_err_rate: 6.652500% averaged train nll: 0.216571 averaged train loss: 0.712272\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 119, took 76.2916s\n",
      "valid_err_rate:          17.630000% currently going to do 271 epochs\n",
      "averaged train_err_rate: 6.632500% averaged train nll: 0.211676 averaged train loss: 0.707379\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 120, took 76.3161s\n",
      "valid_err_rate:          17.360000% currently going to do 271 epochs\n",
      "averaged train_err_rate: 6.682500% averaged train nll: 0.215500 averaged train loss: 0.711179\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 121, took 80.4019s\n",
      "valid_err_rate:          17.190000% currently going to do 303 epochs\n",
      "averaged train_err_rate: 6.757500% averaged train nll: 0.213278 averaged train loss: 0.708523\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 122, took 76.4028s\n",
      "valid_err_rate:          18.310000% currently going to do 303 epochs\n",
      "averaged train_err_rate: 6.392500% averaged train nll: 0.210071 averaged train loss: 0.705062\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 123, took 76.4003s\n",
      "valid_err_rate:          17.920000% currently going to do 303 epochs\n",
      "averaged train_err_rate: 6.430000% averaged train nll: 0.210047 averaged train loss: 0.705019\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 124, took 76.3762s\n",
      "valid_err_rate:          17.230000% currently going to do 303 epochs\n",
      "averaged train_err_rate: 6.390000% averaged train nll: 0.210266 averaged train loss: 0.705240\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 125, took 76.3662s\n",
      "valid_err_rate:          17.890000% currently going to do 303 epochs\n",
      "averaged train_err_rate: 6.420000% averaged train nll: 0.207904 averaged train loss: 0.702548\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 126, took 76.4181s\n",
      "valid_err_rate:          17.260000% currently going to do 303 epochs\n",
      "averaged train_err_rate: 6.552500% averaged train nll: 0.209418 averaged train loss: 0.704243\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 127, took 76.3656s\n",
      "valid_err_rate:          19.470000% currently going to do 303 epochs\n",
      "averaged train_err_rate: 6.287500% averaged train nll: 0.206280 averaged train loss: 0.700945\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 128, took 76.3419s\n",
      "valid_err_rate:          18.420000% currently going to do 303 epochs\n",
      "averaged train_err_rate: 6.255000% averaged train nll: 0.205183 averaged train loss: 0.699684\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 129, took 76.3280s\n",
      "valid_err_rate:          17.780000% currently going to do 303 epochs\n",
      "averaged train_err_rate: 6.170000% averaged train nll: 0.200893 averaged train loss: 0.695364\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 130, took 76.3194s\n",
      "valid_err_rate:          17.340000% currently going to do 303 epochs\n",
      "averaged train_err_rate: 6.027500% averaged train nll: 0.202111 averaged train loss: 0.696341\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 131, took 76.3125s\n",
      "valid_err_rate:          17.770000% currently going to do 303 epochs\n",
      "averaged train_err_rate: 5.887500% averaged train nll: 0.197844 averaged train loss: 0.691838\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 132, took 76.3191s\n",
      "valid_err_rate:          17.610000% currently going to do 303 epochs\n",
      "averaged train_err_rate: 5.932500% averaged train nll: 0.195317 averaged train loss: 0.689128\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 133, took 76.3107s\n",
      "valid_err_rate:          17.740000% currently going to do 303 epochs\n",
      "averaged train_err_rate: 5.950000% averaged train nll: 0.197661 averaged train loss: 0.691361\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 134, took 76.3176s\n",
      "valid_err_rate:          18.040000% currently going to do 303 epochs\n",
      "averaged train_err_rate: 5.967500% averaged train nll: 0.197506 averaged train loss: 0.691469\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 135, took 76.3441s\n",
      "valid_err_rate:          18.390000% currently going to do 303 epochs\n",
      "averaged train_err_rate: 5.837500% averaged train nll: 0.193851 averaged train loss: 0.687719\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 136, took 76.2983s\n",
      "valid_err_rate:          17.330000% currently going to do 303 epochs\n",
      "averaged train_err_rate: 5.812500% averaged train nll: 0.194228 averaged train loss: 0.687896\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 137, took 80.3853s\n",
      "valid_err_rate:          17.160000% currently going to do 343 epochs\n",
      "averaged train_err_rate: 5.745000% averaged train nll: 0.193593 averaged train loss: 0.686897\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 138, took 76.7026s\n",
      "valid_err_rate:          17.890000% currently going to do 343 epochs\n",
      "averaged train_err_rate: 5.775000% averaged train nll: 0.192079 averaged train loss: 0.685213\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 139, took 76.3348s\n",
      "valid_err_rate:          18.150000% currently going to do 343 epochs\n",
      "averaged train_err_rate: 5.737500% averaged train nll: 0.191774 averaged train loss: 0.684699\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 140, took 76.3511s\n",
      "valid_err_rate:          17.530000% currently going to do 343 epochs\n",
      "averaged train_err_rate: 5.617500% averaged train nll: 0.189919 averaged train loss: 0.682510\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 141, took 76.3313s\n",
      "valid_err_rate:          17.350000% currently going to do 343 epochs\n",
      "averaged train_err_rate: 5.620000% averaged train nll: 0.191409 averaged train loss: 0.683819\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 142, took 76.3633s\n",
      "valid_err_rate:          17.960000% currently going to do 343 epochs\n",
      "averaged train_err_rate: 5.745000% averaged train nll: 0.188722 averaged train loss: 0.680868\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 143, took 80.3440s\n",
      "valid_err_rate:          16.970000% currently going to do 358 epochs\n",
      "averaged train_err_rate: 5.655000% averaged train nll: 0.187647 averaged train loss: 0.679536\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 144, took 76.6198s\n",
      "valid_err_rate:          17.800000% currently going to do 358 epochs\n",
      "averaged train_err_rate: 5.552500% averaged train nll: 0.187744 averaged train loss: 0.679399\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 145, took 76.2068s\n",
      "valid_err_rate:          18.070000% currently going to do 358 epochs\n",
      "averaged train_err_rate: 5.500000% averaged train nll: 0.185969 averaged train loss: 0.677540\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 146, took 76.1629s\n",
      "valid_err_rate:          17.550000% currently going to do 358 epochs\n",
      "averaged train_err_rate: 5.507500% averaged train nll: 0.185676 averaged train loss: 0.676869\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 147, took 76.1864s\n",
      "valid_err_rate:          17.760000% currently going to do 358 epochs\n",
      "averaged train_err_rate: 5.407500% averaged train nll: 0.183089 averaged train loss: 0.674114\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 148, took 76.0609s\n",
      "valid_err_rate:          18.000000% currently going to do 358 epochs\n",
      "averaged train_err_rate: 5.650000% averaged train nll: 0.185832 averaged train loss: 0.676762\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 149, took 76.1005s\n",
      "valid_err_rate:          17.540000% currently going to do 358 epochs\n",
      "averaged train_err_rate: 5.402500% averaged train nll: 0.181394 averaged train loss: 0.672272\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 150, took 76.0744s\n",
      "valid_err_rate:          17.410000% currently going to do 358 epochs\n",
      "averaged train_err_rate: 5.332500% averaged train nll: 0.182580 averaged train loss: 0.673197\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 151, took 76.0799s\n",
      "valid_err_rate:          18.320000% currently going to do 358 epochs\n",
      "averaged train_err_rate: 5.157500% averaged train nll: 0.175762 averaged train loss: 0.666168\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 152, took 76.1168s\n",
      "valid_err_rate:          17.450000% currently going to do 358 epochs\n",
      "averaged train_err_rate: 5.160000% averaged train nll: 0.178755 averaged train loss: 0.669012\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 153, took 76.0519s\n",
      "valid_err_rate:          17.360000% currently going to do 358 epochs\n",
      "averaged train_err_rate: 5.300000% averaged train nll: 0.177923 averaged train loss: 0.668056\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 154, took 76.1046s\n",
      "valid_err_rate:          18.350000% currently going to do 358 epochs\n",
      "averaged train_err_rate: 5.270000% averaged train nll: 0.180372 averaged train loss: 0.670464\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 155, took 76.1231s\n",
      "valid_err_rate:          17.600000% currently going to do 358 epochs\n",
      "averaged train_err_rate: 5.192500% averaged train nll: 0.178073 averaged train loss: 0.668080\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 156, took 76.0711s\n",
      "valid_err_rate:          18.030000% currently going to do 358 epochs\n",
      "averaged train_err_rate: 5.027500% averaged train nll: 0.173799 averaged train loss: 0.663315\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 157, took 76.0153s\n",
      "valid_err_rate:          17.210000% currently going to do 358 epochs\n",
      "averaged train_err_rate: 4.910000% averaged train nll: 0.170424 averaged train loss: 0.659712\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "After epoch 158, took 76.0059s\n",
      "valid_err_rate:          18.100000% currently going to do 358 epochs\n",
      "averaged train_err_rate: 5.105000% averaged train nll: 0.174416 averaged train loss: 0.663316\n",
      ". . . . . . . . . . . . . \n",
      "Keyboard interruption, user stopped learning\n",
      "Setting network parameters from after epoch 143\n",
      "Learning ended at 01:01:05\n",
      "Test error rate: 0.181400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f71e1b29a50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEDCAYAAAAvNJM9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXd4VGXWwH+HpnQSWgAJoYgCNsSlCGLUxQUWBdeCiAjq\nZ1tRsKKCm6C4Cmsviw3BCioqKgKCLFFsIApKESnSAwjSISQkOd8fdzKZSWaSSZma83ue95l733rO\n3OSeedt5RVUxDMMwjIJUCrcAhmEYRmRiBsIwDMPwiRkIwzAMwydmIAzDMAyfmIEwDMMwfGIGwjAM\nw/CJGQjDMAzDJ2YgDMMwDJ9UCWblItIf+DtQB5ikqvOC2Z5hGIZRfkgodlKLSD3gcVX9v6A3ZhiG\nYZQLJR5iEpHXRGSniCwvEN9bRFaLyFoRGVWg2Bjg+bIIahiGYYSW0sxBTAZ6e0aISGUcA9AbaA8M\nEpF24jAemK2qy8osrWEYhhEySjwHoaoLRSSpQHRnYJ2qbgQQkWlAf+CvwAVAHRFpo6ovlUlawzAM\nI2SU1yR1M2CLx/1WoIuq3gY8V05tGIZhGCGkvAxEqWe6RcT8jRuGYZQCVZVg1l9e+yC2Ac097pvj\n9CICIiUlhQULFqCqMRdSUlLCLoPpZ/pVNN1iWb8FCxaQkpJSTq/uoikvA7EEOFFEkkSkGjAQ+CTQ\nwqmpqSQnJ5eTKIZhGLFLcnIyqampIWmrNMtcpwLfAm1FZIuIXKuq2cBw4HNgFfCuqv4aaJ2pqamk\npaWVVBTDMIwKR1paWsgMREg2yhUpgIiGW4ZgkpaWFtO9I9Mveoll3SD29RMRNMhzEBFhIFJSUkhO\nTo7ph2kYhlEepKWlkZaWxtixYyuGgQi3DIYRTkSC+j9uxAC+3pGh6EEE1VlfoORNUlsPwqio2I8k\nwx8Ff0Dk9SBC0na4/zCtB2FUdFy/BMMthhGh+Pv7CEUPws6DMAzDMHwSEQbClrkaRmSSlJTE/Pnz\ng95OamoqQ4YMCXo7nvTt25c333yzVGVD9b34IpTLXCPGQNj8g2FEHiJS6kn05ORkJk2aFHA7JaFS\npUr8/vvvpRHLzaxZs0ptlMryvZSViN4oZxiGEQgleYGWZg6mqDLZ2dklrs8oTEQYCBtiMozIZfHi\nxXTo0IH4+Hiuu+46MjMzAdi3bx/9+vWjUaNGxMfHc9FFF7Ft2zYARo8ezcKFCxk+fDi1a9fm9ttv\nB2DlypX06tWL+vXrk5CQwKOPPgo4xiQrK4uhQ4dSp04dTjnlFH788Uef8vTs2ROA008/ndq1a/P+\n+++TlpbGCSecwIQJE2jSpAnXX399kfKBdw9nypQp9OjRg3vuuYf4+HhatWrFnDlzAvp+MjMzGTly\nJM2aNaNZs2bccccdZGVlAbB792769etHXFwc9evXd8sOMH78eE444QTq1KnDySefzP/+97+A2gvl\nEFPYHU85IhhGxSWS/wdatGihp556qm7dulX37Nmj3bt31zFjxqiq6p9//qkffvihZmRk6MGDB/Xy\nyy/XAQMGuMsmJyfrpEmT3PcHDhzQhIQEffLJJzUzM1MPHjyoixYtUlXVlJQUPf7443X27Nmam5ur\n999/v3bt2tWvXCKi69evd98vWLBAq1Spovfdd59mZWVpRkZGieSbPHmyVq1aVV999VXNzc3ViRMn\natOmTf22n5SUpPPnz1dV1QcffFC7deumu3bt0l27dunZZ5+tDz74oKqq3nfffXrzzTdrdna2Zmdn\n69dff62qqqtXr9bmzZvr9u3bVVV106ZNXvp44u/vwxUf3PdzsBsoVoAI/ucwjFAQyf8DSUlJ+tJL\nL7nvZ82apa1bt/aZd+nSpRoXF+e+T05O1ldffdV9/8477+iZZ57ps2xKSor26tXLfb9y5UqtXr26\nX7l8GYhq1appZmam3zK+5PM0EG3atHGnHT58WEVEd+7c6bMuTwPRunVrnT17tjvt888/16SkJFVV\n/de//qX9+/fXdevWeZVfu3atNmrUSL/44gvNysryK7NqeA1ERAwxGYbhH5HyCaWlefN8T/6JiYmk\np6cDcOTIEW666SaSkpKoW7cu5557Lvv37/eaG/Cch9iyZQutWrXy207jxo3d1zVq1ODo0aPk5uYG\nLGfDhg2pVq2a+z4Q+TxJSEjwah/g0KFDxbabnp5OixYt3Pee39E999xDmzZtuPDCC2ndujXjx48H\noE2bNjz99NOkpqbSuHFjBg0axPbt2wPWNVREhIGwOQjD8I/T0y97KC2bN2/2um7WrBkATzzxBGvW\nrGHx4sXs37+fL7/80nNkoNAkdWJiot+VR+WxIqhgHcXJV140bdqUjRs3uu83b95M06ZNAahVqxaP\nP/4469ev55NPPuHJJ590zzUMGjSIhQsXsmnTJkSEUaNGBdSeLXM1DCMiUFVeeOEFtm3bxp49e3jk\nkUcYOHAg4Py6rl69OnXr1mXPnj2MHTvWq2zjxo1Zv369+75fv35s376dZ555hszMTA4ePMjixYvd\n7ZSEgnX7ojj5yotBgwYxbtw4du/eze7du3nooYfcy2dnzpzJunXrUFXq1KlD5cqVqVy5MmvWrOF/\n//sfmZmZHHfccRx//PFUrlw5oPZsmathGBGBiDB48GD3EMmJJ57ImDFjABg5ciQZGRk0aNCAs88+\nmz59+nj9ih8xYgTTp08nPj6ekSNHUqtWLebNm8enn35KkyZNaNu2rXvkwNe+gqJ6FampqQwdOpS4\nuDimT5/us3xx8hVsqyTtezJmzBjOOussTjvtNE477TTOOuss93e0bt06evXqRe3atTn77LO59dZb\nOffcc8nMzOT++++nYcOGNGnShN27d7tXdEUS5ovJMMKM+WIyisJ8MRmGYRgRhxkIwzAMwycRYSBs\nFZNhGEZg2JnUhlGBsDkIoyhsDsIwDMOIOMxAGIZhGD4xA2EYhmH4pEowKxeRlsBooK6qXh7Mtgwj\nmgnX4TOGURQhmaQWkff9GQibpDYMwyg5ETlJLSKvichOEVleIL63iKwWkbUiEpjXKcMwDCNiKc0c\nxGSgt2eEiFQGnnfFtwcGiUi7sotnGIZhhIsSGwhVXQjsLRDdGVinqhtV9RgwDegvIvEi8iJwhvUq\nDMMwoovymqRuBmzxuN8KdFHVPcDNxRW+665Uatd2rpOTk831t2EYRgHS0tJC7nGiVJPUIpIEfKqq\np7ruLwV6q+oNrvurcQzEbQHUpaBlOtDEMAyjohGRk9R+2AY097hvjtOLCBDzxWQYhhEIEe+LyUcP\nogrwG3ABkA4sBgap6q8B1GU9CMMwjBISkT0IEZkKfAu0FZEtInKtqmYDw4HPgVXAu4EYh3ysB2EY\nhhEIEd+DKFcBrAdhGIZRYiKyBxEcrAdhGIYRCNaDMAzDMIqkQvUg/vvftHALYRiGEfFUyB4EYL0I\nwzCMAKlAPQjDMAwj0gjqeRCBkwoku4JhGIbhj1C63LAhJsMwjCikwg0xZWeHWwLDMAwjjwgxEKlA\nGl99FW45DMMwIpsKu4oJbJjJMAwjECrcEBPA0qXhlsAwDMOACDEQmzblXz/8cPjkMAzDMPKJiGWu\nr72WSt4y148+Cq8shmEYkUyFW+aqqojHSNrcudCrF0ydCjVqQP/+4ZPPMAwjEgnFHEREGgiAb7+F\ns8+G2rXhwAGYNw/atoUWLcIjp2EYRiRRISep8zj7bOfz4EFYvhwuvBCGDIG33oKHHoI2beCf/yxc\nbvt2uP12yM0NrbyGYRixRsT2IAJl0ybYuxd+/hmqVYNBg5z4I0egevXyk9MwDCOSqFBDTD16wDff\nlF+9u3dDpUqO8UhKcq7B6ZHUqoVPg9SokdNLeeKJ8pPDMAwjGFSYIabU1FTGjUsr1zobNID4eGjd\nGipXdgzCa69BnTpw220wbJizKe/Agfwyu3bBk086+fwxb56TLzsbDh2CjIzyk3njRsjJ8Y6bO9dc\nkBiGkU+F20mdJ0Nph5nKygUXwPz5hePHj4dRo2DKFMeg7NwJjRvnpzdtCq1awYABkJwMZ50F11wD\n550Hp50GZ54J//2vU/cHH+SXy8lxjMvevY5RAKe8CBx3HBw9mp9XBB54AB55BNauheOPh+bNy/0r\nMAwjyqhQQ0zOdVhFKXemTYMrr8y/HzHCMRpbtsCYMd55H3kERo/Ov58/H84/P/876dsXZs1yVnEt\nXuwMh6nCKac4K72+/z74+sQCqs4ChsqVwy2JYZSNUBgIVDWswRHB4bHHVJ1/YQuBhH//O//6229V\nV692vsc+fZy4PG68UXXGDOc6I0O9GDBAdcwYLcSmTarHjjlhx478+PR01ZNPVs3Jce7XrVMdPbpw\n+bJwxRWObuXFnj3538d//uP93RhGtOJ6dwb3/RzsBooVwOO/dfXq8L90Yy2kpRWO+/xz1SVLVHv3\ndu4TE1UXLlTt188xNMeOOfGVK+eXUXWMwt/+5tw/+6zqe+/lpz/7rGqDBqq5uUX/UefmqmZl5d9n\nZDiyqOuvcdgw57Nt2/x0zxf611+rtmunet99vuvfubNw3K+/OnW88IJq//7e9fni/feLz2MY4Sbq\nDQRQE3gdeBm4yk+eAkpbiMSQnq76wAOB5R0xwnnBe8YtXap6/fX59/fc452eZ6zyQp6ByPv1P3Gi\nt8EC1c2bnc9PP1V96SXV88937h96SHX5ctXsbKeOPAPhGVQdY7ViReF/vHvvzc+za5djdH7+2TGe\nnqxf7xjTkrByperhwyUrYxi+iAUDMQT4u+t6mp88BZS2YCE/5P3iL00491zHsP31r4XTCv6tnXCC\nY4wOHco3ZKqqSUmFy338cf59166qF12U3wsq/p9a9e67A8t7+eVO/rPPLjrfzp2qffsWX9/vv6t+\n9JHq1q2BtR8qvv/e+QFhlIyINBDAa8BOYHmB+N7AamAtMMoVdx9wmuv6bT/1eSn96qvhfylZsFCa\n8Ouvqu+841w/+KDTC3roIdUJE1QXL1b95JP8vJ6MGOGE1FQn7bHHVG+91bvu997zLpOWpnrkiHee\nqVMdA5fH2rWq552n+pe/5L1QnHDhhc793r1Ozys315lLWrfOic/JcYYcVVUPHsyf28orc9ttqgMH\nOvfff6+akqIBkTenpar69NOqVarky1WrVvHl09Kcz99+Uz16tOi84Ogfy0SqgTgH6OhpIIDKwDog\nCagKLAPaAVd79CCm+qnPh+IWLMR+6N5d9a67Sl7Oc6jOX3juucDrq1Mn//rMM/PnYDzDvn2qH3zg\nHbdpU/71/v2q8+Y5BkNVdft2x4icc44zPLh1q+pZZ6n27OmUu+qq/HpBtWZN1czM/PruvtvpGT3x\nhFNfXlt574exY538eXNOTz6pOmiQ6oIF3nm++kp11KgSv3ujglAYiFItcxWRJOBTVT3Vdd8NSFHV\n3q77+1xZnwWeB44CC1V1qo+6tKAMGzdCy5YlFsswjBjiscfgvvucfUYzZjhxntcloRSvuYgnFMtc\ny+s8iGbAFo/7rUAXVT0CXFdcYc9dgcnJySQnJ6Mae/siDMMInPtcPzM9DUJpjANAx46OC53zzy+7\nXOEilOdA5FFePYhLgd6qeoPr/mocA3FbAHUV6kHkkZHhnAdx113mH8kwjLLRqRMsWRJuKcqPaPLF\ntA3wdADRHKcXERCpqak+LWP16k7X8PHHnc+XXy6znIZhVFB+/DHcEpQPEe+LyUcPogrwG3ABkA4s\nBgap6q8B1OW3B1EQVdi/H+LiSiyyYRhGTM1FRGQPQkSmAt8CbUVki4hcq6rZwHDgc2AV8G4gxiEP\nfz2Iwm1DvXqF12Hk8X//VzJdDMMwoo1Q9iBKPEmtqoP8xM8GZpdZolJw552Ol9V774VXX/VOK+2q\nB8MwjIpORHlzLQ/GjIHp0x033LNm5bXhGImePR3Ppz//DIMHw2+/lVuzhmFEATbEVMI2Ys1AlJQT\nT4R9+5wT6AASEmDmTMeNdkaGc8Z1+/b5+Rs0cPJOmOCcD2GrqwwjejADUTIi5kS5UK/vzWPtWueE\nOFXYvNlZ6dCpk3NwT7160K4dHD7sHBj08suwbRusWQP33AMPPQTvv++c+LZ3L2zd6pzjcOyYc/bD\nDz9A165OO2+9BWlpkJ5etCwAr7/ufN57b/HyV67se+6lXr2SfAuGYUQLoZyDCOo27UACefvnKwi5\nuc75C1995biy/vVX1Zdfzk/fv993ub17VY8/3rnessXx7ePJggXOlL2vcxRmzXJcEpx9tuPa4MMP\nHZ89eb5/wKnzyy8dD6jz56s2bap64IDq7NlO+tNP5+e9/HLV++9XHTJEdc4cx334sWPOuRCgum2b\n4/hu61bV6dPzy23dqtqjR75rhqeecq6nTcuPb9bM+axaVfVf/yrs8mHiROfzjTfynfDdfXd++muv\nqY4b510mPt6/mwkLFSvEEq53J8EMETHElJKS4t5BbZSeF16A665z9o8EygMPwN//Dt27+8+TlQXV\nqjlHpW7c6JzzHQ4OH4aaNX2nZWZClSpOj0rVGfq75hrn5L3i2LwZmjRxhg4bNnROnKtWzTvP0aOw\naZOzzPovf/He5Z/3L5QXp+rkr1IFqlYtum1Vp+fYooXTk23aFCpVgj17HBlq1XLyHTzozJ8dOQKf\nfOL0bGvXdubawJH5jz+cIdJDh5y2jz/eu62DB52Np1lZ8O9/Q0qKs3Gsa1dYtcqRZfduZ9fx9u3w\nzDNOPf/5j9Nb7t/f+f7btHGO0F2/3snbrJkjV61asGOHU78I1K0Lzz8PqalOuf37nTPfH3rI6alf\ncgkMHOjcv/kmjBvn9M6XLXOeZ40a8OyzThvjxzv6JSU5f4d33QUnn+zk/eMPR5e33oKVK6FDB+jc\n2fl7mTbNkXfLFudvIimp+L+HSCdvR/XYsWNRm4MwDMMwClJh5iAMwzCMyMMMhGEYhuGTiDAQ4VzF\nZBiGEU1EvC+mchXA5iAMwzBKjM1BGIZhGGHDDIRhGIbhk4gwEDYHYRiGERg2B2EYhmEUic1BGIZh\nGGHDDIRhGIbhEzMQhmEYhk/MQBiGYRg+iQgDYauYDMMwAsNWMRmGYRhFYquYDMMwjLBhBsIwDMPw\niRkIwzAMwydBNRAi0lJEXhWR94PZjmEYhlH+BNVAqOoGVf2/YLYR6cT66izTL3qJZd0g9vULBQEZ\nCBF5TUR2isjyAvG9RWS1iKwVkVHBETG6ifU/UtMveoll3SD29QsFgfYgJgO9PSNEpDLwvCu+PTBI\nRNqJyBAReUpEmpavqIZhGEYoCchAqOpCYG+B6M7AOlXdqKrHgGlAf1V9U1XvUNV0EYkXkReBM6yH\nYRiGEV0EvFFORJKAT1X1VNf9ZcDfVPUG1/3VQBdVva1EAojYLjnDMIxSEOyNclXKULZcXuzBVtAw\nDMMoHWVZxbQNaO5x3xzYWjZxDMMwjEihLAZiCXCiiCSJSDVgIPBJ+YhlGIZhhJtAl7lOBb4F2orI\nFhG5VlWzgeHA58Aq4F1V/bUkjUfTMlkR2Sgiv4jIUhFZ7IqLF5F5IrJGROaKSD2P/Pe79FotIhd6\nxHcSkeWutGc84o8TkXdd8d+LSIsg61No6XKo9BGRoa421ojINSHSLVVEtrqe31IR6RONurnaaC4i\nC0RkpYisEJHbXfGx8vz86RcTz1BEjheRRSKyTERWicijrvjIe36qGpYAVAbWAUlAVWAZ0C5c8gQg\n7wYgvkDcBOBe1/Uo4DHXdXuXPlVd+q0jf0HAYqCz63oW0Nt1/U/gv67rgcC0IOtzDtARWB5KfYB4\nYD1QzxXWA/VCoFsKcKePvFGlm6udBOAM13Ut4DegXQw9P3/6xdIzrOH6rAJ8D/SIxOcXTl9MPpfJ\nhlGeQCg4oX4x8Lrr+nVggOu6PzBVVY+p6kacB9pFRJoAtVV1sSvfGx5lPOv6ALig/MXPR30vXQ6F\nPn8D5qrqPlXdB8yjwB6bsuJHNyj8/CDKdANQ1R2qusx1fQj4FWhG7Dw/f/pB7DzDI67Lajg/lvcS\ngc8vnAaiGbDF434r+X8EkYgCX4jIEhG5wRXXWFV3uq53Ao1d103xnrDP061g/DbydXZ/H+oM3+0X\nkfhy16Jogq1P/SLqCgW3icjPIjLJo/se1bqJs/y8I7CIGHx+Hvp974qKiWcoIpVEZBnOc1qgqiuJ\nwOcXTgMRbfsfuqtqR6APcKuInOOZqE7/Ldp08kus6QNMBFoCZwDbgSfCK07ZEZFaOL8OR6jqQc+0\nWHh+Lv2m4+h3iBh6hqqaq6pnACcAPUXkvALpEfH8wmkgomqZrKpud33uAj7CGSLbKSIJAK7u3h+u\n7AV1OwFHt22u64LxeWUSXXVVAeqq6p6gKOOfYOvzp4+6QvLcVfUPdQG8ivP88uSMOt1EpCqOcXhT\nVWe4omPm+Xno91aefrH2DAFUdT/wGdCJSHx+5T35EmjAmZxZjzPpUo0InqQGauCM9QHUBL4BLsSZ\nVBrlir+PwpNK1XB+8awnf1JpEdAFZyy14KTSRNf1lQR5ktrVThKFJ6mDqg/OJNnvOBNkcXnXIdCt\nicf1HcA7Uayb4Iw3P1UgPiaeXxH6xcQzBBrk1QlUB77CmSOIuOcX1BdQAF9UH5wVCuuA+8MpSzFy\ntnQ9oGXAijxZXV/2F8AaYK7nFw084NJrNY5Lkrz4TsByV9qzHvHHAe8Ba3HGW5OCrNNUIB3Iwhmr\nvDZU+rjaWusKQ0Og23U4L5xfgJ+BGTjjvVGnm6uNHkCu6+9xqSv0jqHn50u/PrHyDIFTgZ9c+v0C\n3OOKj7jnF7AvJsMwDKNiYUeOGoZhGD4xA2EYhmH4pFgDIQG6wxCRv4hItohcWtKyhmEYRuRRpIEQ\nP6fG+ck3HphT0rKGYRhGZFJcDyJQdxi34Wxo2VWKsoZhGEYEUpyBKNYdhog0w3nxT3RF5S2LijZX\nGoZhGIYHxRmIQNbAPg3cp856WSHfmZatnzUMw4hiijtyNJBt2Z2AaSICzg7BPiJyLMCydia1YRhG\nKdFgH9lczI6/ErnDACYD/yhJWUBBvcJX9NALmFcoPjpDSthlcHp3Trj5Zue+QQP/+X/6qXDZZcuc\nz2bN8uPXrcvXr149LURiYn7e7t3zr/0BqtdcU3QeT11CQUpKih45Err2QklKSkq4RQgqsa4fLp9+\nwQxFDjGpn1PjROQmEbmpNGUDMVqL6EJnFhef0QgZav08w6hwFDfEhKrOBmYXiHvJT95riysbCIvp\nzGDeLmkxI8RIcDu3hmGEmYjcSb2ILnRhEbExz50cbgF8UtIega/8joFILlV9JWknnCQnJ8esIUxO\nTg63CEEl1vULBRFpIDY7bsxJZHOYJSkPksMtQIkp2Us62W9KLLxYY/klE8u6QezrFwoi0kCAuOch\nqpJFPH+GW6AKj/8ehGEYsUqEGghnmOkcFvIx/XmXgeEWxyiGWDYWsaybYRRFmZ31iUh/1yHiS0Xk\nRxE53yNto4j84kor0bKkRXRhOM+TSyW6sIgqHCtJcaMYym8OonT1GYYR+ZSHs74vVPV0Ve0IDANe\n9khTIFlVO6pqZ0rAd3RjLCn8gw/ZSBJnsKwkxY0QUNwv69L88jZDYxiRQ5md9anqYY/bWsDuAnWU\nqoOeQQ0eIoUsjuMbutOdb0pTjYH3i/rFF537PXv85+/UqXDZs85yPrdty49v0SI/3/79TtyQIc7n\n4cPedXzzTf71+PHwwANw2mnw44/e8s2YUXLd5s0LPP+LL0K9eiVvI4+4OJg40X9ew4glyuysD0BE\nBojIrzh7Hm73SFLgCxFZIiI3lFZIMxDRw0cfOZ8ZGf7zzJsHc+fC8uWwbp132qFDJW9zxYrA837z\njWPMSsu+ffnGzjBinfJw1oeqzlDVdsBFwJseSd1dQ099gFtF5JzSCPk1PVwGwsYfogmb3DWM6KY8\nnPW5UdWFIlJFROqr6p+qut0Vv0tEPsIZslpYuGSqx3UyBdfWbyQJgCQ2spGWxYhsRAqxMp9Q0NDF\nil5GdJGWlkZaWlpI2yzOQCwBThSRJCAdGAgM8swgIq2B31VVReRMAFX9U0RqAJVV9aCI1AQuBMb6\nbia1GDGEb+hOD742A2EUoiQ9FevVGNFKcnKy1+a/sWP9vE7LkfJw1ncpsFxElgLPAFe64hOAhSKy\nDFgEzFTVuaUVdCb9uJJppS1uRBDR+pK2noNR0Sizsz5VnQBM8FHud+CMcpARgPe5nCe5k0Q2sZkW\nxRcwwoLnyz8SDUEkymQYkUrE7qQuSAY1eJvBXM+kcItiVHCsJ2FUFKLGQAC8zI1czyQqk11kvqZs\nw1Y8VRxC1Ssww2BUNKLKQKzkFDaSRD9mFpnvO7pxFktCJJVRUsI5zGNDTIYROFFlIABe4iZuIv+8\nompkeqU3ZRuJbKEdAR1eZ5QzeRvdGjaEDRt855k3z9lBDXCla0lDwbmLvDBunPe9vzmO445z7o8e\n9c47erR3uddfL9zGggXe8lWr5sS//DLMmuXcA1Su7HyqQvPmsHJlYd169nTK5uTAwIHwyiv+v6vJ\nk+HSS73jGjaE+vVh/nz/5fL4+mtnN3qg1KgBO3YEnj8QliyBtm3Lt04jcgi2s74iy5aG97mcziym\nBRu5jkms4BQ8h5Pyjio9id/KozkjzKSkFJ9HBLKynGtPFx8AEwotnyjM3AJr6465/EJOngwz/XRW\nt26FH34oHL/QtcsnOxveew+mTPHf7htvwIcfesft3u24QZkzp3i55893dqMHSkaGf6NdWr7+Gtau\nLd86jcihyFVMHs76/oqzae4HEfmkwNnSX6jqx678pwIfAW0CLFtijlKdt7iaf/MAvZhHDpU5jV/4\nhdMB6MIiVtKek1ldlmaMCkRp5xZsTsKIdYLprK/YsqXlZW7kKqaSSirTuJKL+NSd1oVFvME11oMw\nIoKijEg45kPMqBklIZjO+gIqWxpW0YHufM1/+SefcDEX8wkAlcihEz/yNoNpzXoqkVMezRlRRHm6\nGC8451EwfzBftvYiNyKBoDjrEwn+b6Nv6Q4ICzmHNqyjCem041d2kMA2TuAPGtGCTcEWw4gAivpr\nC9eqpUDmXa6IAAAgAElEQVTatRVVRqQTFGd9QLwrX4BlUz2ukynorK8osqnK5/yNwbzNAeqwiC4A\n/MZJnMxqNtAq4LqM6Kc0jvWCOQdR2rqDZTysZxK9xJqzvv3Flc0ntZTiO0zkFl7mRtqyhn/yX8Ax\nECfxG7PpW6a6jYpLsIeYrAdhlIRwOOsr0kCoaraI5DnrqwxMynPW50p/CcdZ3zUicgw4hMtZn7+y\nwVBiIT1px2pqcJgMqgOOgTiFEpwkY0QtkfiiLatM9kvfiASC5qzPX9lgcoSa7uvfOIlL+SBUTRsR\nQsEXczCNRzCHmIJFpMljRDiqGtYAqPNnW76hOZt0O40VcoNSvwULzz+ff92wof98F12kumqVqqrq\niBGqp5/unZ7Hjh2Fy374ofO5bJlqjRqqd9yRn//++520ceNUn3rKiQPVPn1Un3tOvcjJcdIeeEC1\nVy/VO+9UXbBA9a9/1WK55RbVn3/2nZaQ4K2DquqzzzpxO3aoHj6c38aSJfl6HTvmxA0YoPrHH6pv\nv63atm3hulRVJ0xQbdHCKV8Uu3ap9u+ff//yy6pTphSvX7TivL6D/H4OdgPFCkBwDATk6ipO1nNZ\nEPYXiYXYDKmpged96KG8f+rCIY+pUwunHX+88zl8eOH8N9xQuB5f9aqqHj1auO5zzimcz/eLSPXe\ne/2nFawjL27GDNU1a/LT//nP/LQDB/LzzpqlGh/vuy7P+oYPL1rOOXO8y4NqtWrF6xethMJARJ0v\npsARnuM2bufZcAtiGFGParglKB3RKnekUB6+mAa7fDH9IiLfiMhpHmkbXfFLRWRxeQtfHG9wDT35\nihZsDHXTRgWgvF8+Rc2X+GorEifniyLY8kbb9xENFGkgPPwp9QbaA4NEpF2BbL8DPVX1NOBh4GWP\nNAWSVbWjqnYuP7ED4zC1mMIwhvN8qJs2KgCh+HVaXm34enmW5IVaWjkCKRfuhQSGf8rDF9N3qrrf\ndbsIOKFAHWG1688wgmFMIZFNgPIcw/mHa3VTNTLpztdFlhdyOZE1IZDUqOiU9EUZ6Utpy3tFWXHl\ni9qzYpSOcvHF5MH1wCyPewW+EJElInJD6UQsG1tpzrPczhPcxT/5L+exgIncwt+ZyRx6M58LqMkh\nv+WTSeML/hpCiY1oIdxDTKEk3O2XlmiVO1Iobh9EwF+viJwHXAd094jurqrbRaQhME9EVqvqwlLI\nWSb+wz2spAPnsYAuLKIlG5hFX17kZgQlmTQ+o5/Psl35nkS20JA/2EWjEEtuGP4J9i/y8sDzBe2v\nvfKSw3oQ5U+5+GJyTUy/AvRW1b158aq63fW5S0Q+whmy8mEgUj2ukymJL6ZAOEp1ruIdanGI9bRh\nPW1IZDM7SOAe/kNv5vAZ/RjEO9RjHxO5hbyRsS4sIouqdOJH5tCnXOUyopto6kFE+nBUsIhWuX0R\nrb6YEoEPgatVdZ1HfA2gsqoeFJGawIWAH+chqaUSviQsoqvX/Q6aAPA5f2M6l1GdIzzJnewljs4s\n5kZe5hhV6cIiPuBSzmKJGQjDi2iapPZFKCap/R0RWx51F9VWLBIOX0zFbpQA+gC/AeuA+11xNwE3\nua5fBf4ElrrCYld8K2CZK6zIK+uj/jBveMrVdBL0GW7TD7hEa3BI0+ipNzFRE9mo6SToZbynM7g4\nzHJasBCc0Llz/vWLLzqfw4YVznfGGaqbNjk7mwcMUO3Rwzv97rvzN9/5CkOG5F97lh00yDtfhw6q\n//d/vuvYsiVfvg8/VH3/fdUHH1S99db8PE2aqPbtm38/b57q9OnluEMtQnBe37aTOujhNZz/hjNZ\noqB6AfP0Z07Vy3lXP6K/JvG7bqGZV5nKHAu73BYshDpcfHHpy4qUvf0bbyx92VgjFAYihndSB867\nDOQdBvETnQCYzwVUI4s7eZJFdGEjSVQngwS2A87S19WczIdcQmvWFVW1YRhG1GIGAvic3gzmHY8Y\nYSK30JVFrgOIhCWcRSd+BKAHX3OU41lEF76nK21YW2wbQi61OBgcBQwjRJRlnL885ghUy16HEThm\nIPzwOkP5mdNYwlkA/Egn/sIPAAzmbd5kCOO5j4d5kMlcW+z519cziTn0DrrchhFMYn0i2PDGDIQf\n9lOPM/iZg9QBYDqXcTMvciJruJQPmOpazPUct5FLJVIYS1Wy/NbXj5l059uAehuGEYuYcYk+gu2s\nr8iy0cRSzmQ8o/iaHqykA1tIBECpxFBepwdfs4XmXMG7hcpWI5Nk0niTq7matwC4nldpzuaQ6mAY\nZSXcL3kbYgoxRc1g4xwVug5IAqriLFltVyBPN6Cu67o38H2gZV35wr4yI/CQq28yWK9gms/0Lnyn\nO2moddnrFX8e8/U7umhHftT1tNTBvKkHqKXf0UWrkBVw+9U4GgHfgYWKHP7xj9KXrVKl7O1ff33p\ny8Yazus7vKuYyuKsr9iy0YcwhLd4j4E+UxfRlRkMYDSPeMX3YTZz6M1SOpJBdV7gVnrwNbtoyFPc\nwd+YQxe+L7LlB3mIZZxBZbLLTRvDKCnh7kEYoSWYzvpKWjYm+BcPcS2T6ctn7onrPsxmNn0AYQzj\nuJq3+IXTGcYUTuI37uRJZjCA3symEjmMZhx/Y467zv7M4AZe4QB13ENUhhEOwr2KyQgt4vRU/CSK\nXIrjX+kG1/3VQBdVvc1H3vOAF3Ac9O0NtKyIKIH7BIwKLuZjxjCOFmziCDWoRC4t2UAulf2W6ca3\nzGAAyzmV4znKiazlMqZzImt5jPvoyyyO5yhvcA0n8RvHqBZCjQwj+iniVReViAiqGlSzG0xnfQGV\nBfj731P57LO8u2TK21lfqPmE/nxCf5qzmcrksIuGRRoHgO84m1uYyFks4V88RDJpzKE3q2jPX/mC\nXzgdgDW05VZe4GnuKFTHYN7iKt7hSqa5V18ZRiAIuShCmI9vMYogHM76ipygwDEg63Emmqvhe5I6\nEWcyumtJy7ryuSZcLBQMrVlbyKVHG9ZoOgl6ER8rqFbnsIJqCzboHzTQ97hMv6OLxvFnQG004A/t\nxed6BdO0EtnF5j+NZXoz/9Xa7NfjyND+fKSvcL0u5qxCk/OBhJNZpU3YFvbvuqKHVP6l73K5Qm7Y\nZQlWiDVc706CGYrPUEpnff7K+qjfpayFQEMnftCdNNS1tNYsquj/SNbv6az3MF4hVx/jXt1BI72b\nCfokI/VXTtInGamns1SPI0OP54iezdc6maG6h3r6P5L1Bzrpx1yktTjg1VZVMvUapmhfZuowXtM/\naKAf0V93E69/Eqf/I1lv52n9lL/rCJ7yK3MHlutK2unJrFJQrUS2PsA43UlD3UM9fZfLtT67FByj\n15StRX4Hx5Gh9dhTKF7I8bpPIF2vYJpeyyS9mBkBGcGKF3J1DW00nQS9knciQJ7ghFgjFAaiyDmI\nUCAiqqo+JrCsq2tEC/n/Q5XJJsc1cjuYtzibb7mVFwChHnvZT11C7QKtMtlUI4sMavhM78AKZtKP\ny3mfmfSjEz+yrdDJwb6px15as54fXR4HQkFNDpFBda9h28pk05idpBexDibMr7pyJxRzEBG9kzrY\n1tGChbIGgKpk8TQj2EASRzmexxhFH2bxBHdxHgsYyuucwVJ+pxUf8g9qcZBOLOEq3i70N1+TQ/yd\nmYxjNE8zgpt4scj/kSocoz67i8zzLLezhebczjNeu/3zlkxfwkfMYABL+AvjGcVX9Cx2x39jdvAQ\nD7KONnzBX2nHKq/0eP7kVp5nMsPcTi7zOIEtXnJUJYsBfOTaZKpedfRirtfS7locZAln8RZXe+Wd\nwL38Sjs6sQRQejObhvwBQAN28QR3Qm5ukToZPoiAfzBVVR9dQifeMCIZQOfyV/2I/tqGNdqIHTqD\ni/Uo1fQcvtRT+Vl3UV/TSdCBTNUXuVH3UE83kqgbaKHX8aqCak0O6oOM1d3E63zO0xRSdARP6Qra\n6ygedf9ftGKdPsxovZJ3tBef60ra6UFqaho99d/cpyN4yj2MB6rd+Ea30lS7s1C/4HydRW89jgy9\nlkl6gFo6gA/1J87Qc/jSXeb/eFnTSdBL+ECrkKV3M0E/5iJ9gHH6AOP0QwboHurpRG7SlqzXm5io\n39PZPV92Gst0O431bQbp49ypG2ihp7FMQbUfn+ghauhEblJQPZMlmk6CptFTl3Gavsvl+k+e1y84\nX/dRR5fTQX+gk3bhO63MMX2Xy/U1hukPdHINqar24nPdzAk6jNd0O411HhdoOgm6mLO0Nvv1C87X\nf3NfuP9Uyh1CMMRkBsIwygCgj3NngbmNXK+J96t4Sy/hA/d9B5ZrZY5pW1brThrqZIbqbuL1bQZp\nS9Z7/R80YZuuo5V+Ti/9H8m6i/r6JCP1E/rpKk7WfzBdjyNDL+JjfYBx+gK36Daa6Pd01ocYoyto\nr5fxnoJzhsk7XKkraacbSdTLeE+30lR30rDQ3Mw5fKmrOFl30lBn8zcdyFSdwN06nnv0Kt7ymv8R\ncvQLztdpXKHXMsl9yFZe+mDe1J001HW00m000fP5QtfTUm/hBd1CM/0H0xWceaUJ3K2vM0T785Fr\nAUauXseruoY2msFxuoQz9Tgy9AQ26xaa6Vpa627i9TzmK6heyvt6O09rFbL0dYboVprqXP6qlcgO\n959KuRMKAxHRcxDhls0wikNEoAz7eLrxLcmk8RZXu/17FaQxO+jCIjKozvd0LXYJc2WyOY8FJJNG\nNlVIJZW8Ob3KZHMnTzKNK9lCIklsoD2rmMXfC9VTjUxOZTk/0oni5gQb8gdDeZ3ufMM0ruRdrvRK\nF3LpwEr+oBF/0JhufMtCzuF+HuU/3Ftk3XnU4iCZHOfeA1SNTJLYSFWOsZJTfMr/IA/zNCP5kwbE\n2uskFHMQxRoIEekNPI3jW+lVVR1fIP1kYDLQERitqk94pG0EDgA5wDFV7eyj/qg0EElJSUyaNIkL\nLrggqO2kpqayfv163nzzzaC240nfvn0ZNGgQQ4YMCVmb0UpZDURFpiW/s4GWhGpBSgS/TkpF2Cep\nRaQy8DyOE772wCARaVcg25/AbcDjPqpQIFlVO/oyDtGMiLheDiUnOTmZSZMmBdxOSahUqRK///57\nacRyM2vWrAplHKZMmcI555wTbjEqHBtoRShXK+7bF7KmYobycNa3S1WXAMf81BHQX8DJJweSKzYo\nyUu/NL2oospkZ0eOs7+cHO9DlvLGPQMlkPyRpK8RXuLiwi1B9FHezvoKosAXIrJERG4oKuNZrmXU\nrVuXoPYws3jxYjp06EB8fDzXXXcdmZmZAOzbt49+/frRqFEj4uPjueiii9i2bRsAo0ePZuHChQwf\nPpzatWtz++23A7By5Up69epF/fr1SUhI4NFHHwUcY5KVlcXQoUOpU6cOp5xyCj/++KNPeXr27AnA\n6aefTu3atXn//fdJS0vjhBNOYMKECTRp0oTrr7++SPnAu4czZcoUevTowT333EN8fDytWrVizpw5\nPtsHSE9P59JLL6VRo0a0atWK5557zp2WmprKZZddxpAhQ6hbty5TpkwhOTmZ0aNH0717d2rWrMmG\nDRv49ttv+ctf/kK9evXo3Lkz3333nZdsY8aM8cpfkKSkJCZMmMBpp51G7dq1ycnJ4bHHHqNNmzbU\nqVOHDh06MGPGDAB+/fVXbrnlFr777jtq165NfHw8AJmZmdx99920aNGChIQEbrnlFo4ePVrUn4Nh\nxB5FzWADlwKveNxfDTznJ28KcFeBuCauz4Y4rjbO8VFOVVWvvtpZ8dC6dXSsYmrRooWeeuqpunXr\nVt2zZ492795dx4wZo6qqf/75p3744YeakZGhBw8e1Msvv1wHDBjgLpucnKyTJk1y3x84cEATEhL0\nySef1MzMTD148KAuWrRIVVVTUlL0+OOP19mzZ2tubq7ef//92rVrV79yiYiuX7/efb9gwQKtUqWK\n3nfffZqVlaUZGRklkm/y5MlatWpVffXVVzU3N1cnTpyoTZs29dl2Tk6Onnnmmfrwww/rsWPH9Pff\nf9dWrVrp559/7talatWq+vHHH6uqakZGhp577rnaokULXbVqlebk5OiOHTu0Xr16+tZbb2lOTo5O\nnTpV4+LidM+ePaqqhfIfO3bM57Pp2LGjbt26VY8ePaqqqu+//75u375dVVXfffddrVmzpu7YsUNV\nVadMmaI9evTwqmPkyJHav39/3bt3rx48eFAvuugivf/++wu1BdF0nomFWIIQrGIqOhG6AnM87u8H\nRvnJW8hABJIOaEpKip56aopCijZtuiAqDERSUpK+9NJL7vtZs2Zp69atfeZdunSpxsXFue+Tk5P1\n1Vdfdd+/8847euaZZ/osm5KSor169XLfr1y5UqtXr+5XLl8Golq1apqZmem3jC/5PA1EmzZt3GmH\nDx9WEdGdO3cWquf777/XxMREr7h///vfeu2117p1Offcc73Sk5OTNSUlxX3/xhtvaJcuXbzydOvW\nTadMmeIzvy+SkpJ08uTJReY544wz3IZq8uTJXgYiNzdXa9as6fU9fvvtt9qyZctC9ZiBiK4QzSxY\nsEBTUlLcIRQGojhvrkuAE0UkCUgHBoLrMObCeA2si0gNoLKqHhSRmsCFwFhfBZ2VOrB8OVSvXoxE\nXm0EntcfqqUv27x5vrPaxMRE0tPTAThy5Ah33HEHn3/+OXv3Os5tDx06hKq65x885yG2bNlCq1at\n/LbTuHFj93WNGjU4evQoubm5VKoU2Eb4hg0bUq1avnvwQOTzJCEhwav9vPyNGjXyyrdp0ybS09OJ\n8xjszcnJcQ99AZxwQmEXDp7fY3p6OomJ3ss9W7Ro4f5uC+b3R8E8b7zxBk899RQbN250y//nn3/6\nLLtr1y6OHDlCp06d3HGqSq7txDXCSHJyMsnJye77sWN9vk7LlSLfMKqaDQwHPgdWAe+q6q8icpOI\n3AQgIgkisgW4AxgjIptFpBaQACwUkWU4J83NVNW55Sl8efymKAubN2/2um7WzJmeeeKJJ1izZg2L\nFy9m//79fPnll26LDIUnqRMTE/2uPCrtSqmi6ihOvtKSmJhIy5Yt2bt3rzscOHCAmTNnuuXwpY9n\nXLNmzdi0aZNX+qZNm9zfrS99fOGZZ9OmTdx444288MIL7Nmzh71793LKKaf4fR4NGjSgevXqrFq1\nyq3Hvn37OHDgQADfgmHEDsX+BFXV2ap6kqq2UdVHXXEvqepLrusdqtpcVeuqapyqJqrqIVX9XVXP\ncIVT8srGCqrKCy+8wLZt29izZw+PPPIIAwc6R5EeOnSI6tWrU7duXfbs2VPI0jdu3Jj169e77/v1\n68f27dt55plnyMzM5ODBgyxevNjdTkkoWLcvipOvtHTu3JnatWszYcIEMjIyyMnJYcWKFSxZsgTw\nr4tnfN++fVmzZg1Tp04lOzubd999l9WrV9OvXz+f+QPh8OHDiAgNGjQgNzeXyZMns2LFCnd648aN\n2bp1K8eOOQvxKlWqxA033MDIkSPZtWsXANu2bWPu3HL9fWMYEU9EO+uLZESEwYMHc+GFF9K6dWtO\nPPFExowZA8DIkSPJyMigQYMGnH322fTp08frV+qIESOYPn068fHxjBw5klq1ajFv3jw+/fRTmjRp\nQtu2bd0Hg/j61V3UL+jU1FSGDh1KXFwc06dP91m+OPkKthVo+5UqVWLmzJksW7aMVq1a0bBhQ268\n8Ub3L+9AehDx8fHMnDmTJ554ggYNGvD4448zc+ZM9+qi4vT3Rfv27bnrrrvo1q0bCQkJrFixgh49\nerjTL7jgAjp06EBCQoJ72Gz8+PG0adOGrl27UrduXXr16sWaNWtK1K5hRDsR42pjyBB46y1nmavz\nAziyd1IbBthO6mgjll4pYd9JbRiGYVRcijUQItJbRFaLyFoRGeUj/WQR+U5EjorIXSUp64t//hM6\ndgxcAcMwDCM4BM0XU4BlC3HnnfDTTwHLbxiGYQSJYPpiKrasYRiGEbkE0xdTWf04GYZhGGGkOANR\nljn/GFovYBiGUfEoztXGNsDTZ0FznJ5AIARcNjU1lZ9/dq7T0ry3kxuGYRiQlpbm3h8VKorcByEi\nVYDfgAtwfDEtBgap6q8+8qYCB9V1olygZQvug8gTx7XGt8wKGkYwsX0Q0UUsvVLCvg+iLL6Y/JUN\npjLRQFpampcjuVNOOYWvvvoqoLwl5ZZbbmHcuHGlLm8YRsWmuCEmVHU2MLtA3Ese1zvwHkoqsqzh\njadPoLIwZcoUJk2axMKFC91xEydOLJe6Y4VKlSqxbt26Ij3nGoaRj+2kNoKKryM/Cx41WhyB5A+0\nThu2NIzAiRgD0b071K0bbikCY/z48Vx++eVecSNGjGDEiBEATJ48mfbt21OnTh1at27Nyy+/7Leu\npKQk5s+fD0BGRgbDhg0jPj6eDh068MMPP3jlLemxmcOGDePBBx90l3/llVc48cQTqV+/Pv3792f7\n9u3utEqVKvHSSy/Rtm1b4uLiGD58uF+ZVdUtS4MGDRg4cKD7XImNGzdSqVIlXnvtNVq0aMEFF1zA\n66+/Tvfu3bnzzjtp0KABY8eO5cCBA1xzzTU0atSIpKQkHnnkEffLe8qUKYXyF6Tg8aWvv/46P/zw\nA926dSMuLo6mTZty2223uT20+jqOFWDmzJmcccYZxMXF0b17d5YvX+5Xb8OocAT7RKLiAn6OefIX\nHwls2rRJa9SooQcPHlRV1ezsbG3SpIn7mNDPPvtMf//9d1VV/fLLL7VGjRr6008/qapzKtQJJ5zg\nrispKUnnz5+vqqqjRo3Snj176t69e3XLli3aoUMHbd68uTtvSY/NHDZsmD744IOqqjp//nxt0KCB\nLl26VDMzM/W2227Tnj17uvOKiF500UW6f/9+3bx5szZs2FDnzJnjU/+nn35au3Xrptu2bdOsrCy9\n6aabdNCgQaqqumHDBhURHTp0qB45ckQzMjJ08uTJWqVKFX3++ec1JydHMzIydMiQITpgwAA9dOiQ\nbty4Udu2bet1il3B/AXxdXzpjz/+qIsWLdKcnBzduHGjtmvXTp9++mkvHT1Pifvpp5+0UaNGunjx\nYs3NzdXXX39dk5KSijx9ryBgJ8pFU4glXO/IcnsX+wpBrTwgAaLQQKiq9ujRQ9944w1VVZ07d67f\n40ZVVQcMGKDPPPOMqhZtIDzPb1ZVffnll73yFqSoYzNVvQ3Eddddp6NGjXKnHTp0SKtWraqbNm1S\nVefl+c0337jTr7jiCn3sscd8ttuuXTu3zKqq6enpWrVqVc3JyXEbiA0bNrjTJ0+e7HUUaXZ2tlar\nVk1//fVXd9xLL72kycnJPvP7wtfxpQV56qmn9JJLLnHfFzQQN998s/v7yeOkk07SL7/8ssh6PTED\nEV0hlgiFgSizsz5Xnmdd6T+LSEeP+I0i8ouILBWRxWXv7xRquOyhlFx11VVMnToVgHfeeYfBgwe7\n02bPnk3Xrl2pX78+cXFxzJo1y+/xlp6kp6cXOsbUkzfeeIOOHTsSFxdHXFwcK1asCKhegO3bt9Oi\nRQv3fc2aNalfvz7btm1zxxU8WvTQoUM+69q4cSOXXHKJW4727dtTpUoVdu7c6c5TcPWV5/3u3bs5\nduyYlzyJiYlesgSyeqvg8aVr1qyhX79+NGnShLp16zJ69Ogiv59NmzbxxBNPuPWIi4tj69atXkNv\nhlGRKbOzPhHpC7RR1ROBGwHPpTMKJKtqR1XtXK6SQ/n8qCgll112GWlpaWzbto0ZM2Zw1VVXAZCZ\nmcmll17Kvffeyx9//MHevXvp27cvGkBbTZo0KXSMaR4lPTazIE2bNnWfxwzOKWt//vmn11GegZKY\nmMicOXO8jhY9cuQITZo0cecp6pChBg0aULVqVS95Nm/e7PXCL04fX4cP3XLLLbRv355169axf/9+\nHnnkkSLPkU5MTGT06NFeehw6dMh9MqBhVHTK7KwPuBh4HUBVFwH1RKSxR3pQN3KEi4YNG5KcnMyw\nYcNo1aoVJ510EgBZWVlkZWXRoEEDKlWqxOzZswM+qvKKK67g0UcfZd++fWzdupXnnnvOnVbSYzMB\ndzcRYNCgQUyePJmff/6ZzMxMHnjgAbp27Vqol+JZ1h8333wzDzzwgNuA7dq1i08++SQgHQEqV67M\nFVdcwejRozl06BCbNm3iqaee4uqrrw64Dl/yHTp0iNq1a1OjRg1Wr15daJlvweNYb7jhBl588UUW\nL16MqnL48GE+++wzvz0nw6holIezvqLyKPCFiCwRkRvKImgkctVVVzF//nx37wGgdu3aPPvss1xx\nxRXEx8czdepU+vf3tqn+fh2npKTQokULWrZsSe/evbnmmmvceUtzbKbnr+wLLriAhx9+mEsvvZSm\nTZuyYcMGpk2b5lcmf8eDgrNi6+KLL+bCCy+kTp06dOvWzX2GdqB1Pffcc9SsWZNWrVpxzjnnMHjw\nYK699tpi2y6qzscff5x33nmHOnXqcOONN3LllVd65Sl4HGunTp145ZVXGD58OPHx8Zx44om88cYb\nRbZrGBWJ4lxtXAr0VtUbXPdXA11U9TaPPJ8Cj6nqN677L4B7VfUnEWmqquki0hCYB9ymqgsLtKG+\nZDBXG0Y0YK42ootYeqWEwtVGeTjrK5jnBFccqpru+twlIh/hDFktLFCe1NRU93VysjnrMwzDKEhU\nOutzTVIPV9W+ItIVeFpVu4pIDaCyqh4UkZrAXGCsqs4t0Ib1IIyoxXoQ0UUsvVLC3oNQ1WwRyXO4\nVxmYpC5nfa70l1R1loj0FZF1wGHgWlfxBOBD1xhwFeDtgsbBMAzDiFyK7EGERADrQRhRjPUgootY\neqWE3d23YRiGUXExA2EYhmH4xAyEYRiG4ZNiDwwKJ8VtljIMwzCCR7Cd9RVb1h+l9T7YooUCBT3G\nKtu3F44rKjRtqtx7b/H5LFgwjFglaM76AikbSsLXGUkLV8MhIi3cAgSZtHALEETSwi1AkEkLtwBR\nT714ZvsAAATESURBVLCc9SUEWDZkmIEIFmnhFiDIpIVbgCCSFm4BgkxauAWIeoLprK9pAGUNwzCM\nCKU4AxHoAGvEzCZ7HEngRZUSTsc3aQJxcWWXxzAMI1oJlrO+rUDVAMoCwVmtVLDK+vVLVv7HH51Q\nPowtr4oiFNMveoll3aCgfrYwsmQUZyCWACeKSBKOs76BwKACeT4BhgPTXM769qnqThH5M4CyQd8q\nbhiGYZSOoDnr81c2mMoYhmEY5UfYnfUZhmEYkUlYXW2UZSNdqBGRjSLyi4gsFZHFrrh4EZknImtE\nZK6I1PPIf79Lr9UicqFHfCcRWe5Ke8Yj/jgRedcV/72ItAiyPq+JyE4RWe4RFxJ9RGSoq401InJN\niHRLFZGtrue3VET6RKNurjaai8gCEVkpIitE5HZXfKw8P3/6xcQzFJHjRWSRiCwTkVUi8qgrPvKe\nX2l3LJc14Aw7rQOScCa0lwHtwiVPAPJuAOILxE3AOV4VYBTO0avgbAxc5tIryaVnXm9tMdDZdT0L\n50hXgH8C/3VdDwSmBVmfc4COwPJQ6gPEA+uBeq6wHqgXAt1SgDt95I0q3VztJABnuK5r4Rzq1S6G\nnp8//WLpGdZwfVYBvgd6ROLzC2cPIqI20gVIwQl19yZB1+cA13V/YKqqHlPVjTgPtIuINAFqq+pi\nV743PMp41vUBzil+QUOds8H3FogOhT5/A+aq6j5V3YdzVnnvclMMv7qB7+XYUaUbgKruUNVlrutD\nwK84e4xi5fn50w9i5xkecV1Ww/mxvJcIfH7hNBCBbMKLJBT4QkSWiMgNrrjGqrrTdb0TaOy6bor3\nkl7PzYOe8dvI19n9fahqNrBfROLLXYuiCbY+9YuoKxTcJo6/sEke3feo1k2cVYIdgUXE4PPz0O97\nV1RMPEMRqSQiy3Ce0wJVXUkEPr9wGohomx3vrqodgT7ArSJyjmeiOv23aNPJL7GmD46PsJbAGcB2\n4InwilN2RKQWzq/DEap60DMtFp6fS7/pOPodIoaeoarmquoZOPvGeorIeQXSI+L5hdNABLIJL2JQ\n1e2uz13ARzhDZDvF8TuFq7v3hyu7v82D21zXBePzyiS66qoC1FXVPUFRxj/B1udPH3WF5Lmr6h/q\nAngV5/nlyRl1uolIVRzj8KaqznBFx8zz89DvrTz9Yu0ZAqjqfuAzoBOR+PzKe/Il0IAzObMeZ9Kl\nGhE8SQ3UwBnrA6gJfANciDOpNMoVfx+FJ5Wq4fziWU/+pNIioAvOWGrBSaWJrusrCfIktaudJApP\nUgdVH5xJst9xJsji8q5DoFsTj+s7gHeiWDfBGW9+qkB8TDy/IvSLiWcINMirE6gOfIUzRxBxzy+o\nL6AAvqg+OCsU1gH3h1OWYuRs6XpAy4AVebK6vuwvgDXAXM8vGnjApddq4G8e8Z2A5a60Zz3ijwPe\nA9bijLcmBVmnqTg73LNwxiqvDZU+rrbWusLQEOh2Hc4L5xfgZ2AGznjv/7d3BycUwkAQQKchO7AA\nLcg2/fALEi97nAJU3oNccgnDBuYU8rpsc8aa5Jr7+Ju1fWh+Ld/+lRkmWZKck++f5Jj9x83PQzkA\nKn9SA1ApCAAqBQFApSAAqBQEAJWCAKBSEABUCgKA6gZyNBwJWPLISgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7247ac4290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# init training\n",
    "i=0\n",
    "e=0\n",
    "\n",
    "init_parameters()\n",
    "for v in velocities:\n",
    "    v.set_value(np.zeros_like(v.get_value()))\n",
    "\n",
    "best_valid_error_rate = np.inf\n",
    "best_params = snapshot_parameters()\n",
    "best_params_epoch = 0\n",
    "\n",
    "train_erros = []\n",
    "train_loss = []\n",
    "train_nll = []\n",
    "validation_errors = []\n",
    "\n",
    "number_of_epochs = 3\n",
    "patience_expansion = 2.5\n",
    "\n",
    "base_lrate = 1e-2\n",
    "K = 10000\n",
    "momentum=0.9\n",
    "\n",
    "# training loop\n",
    "try:\n",
    "    print \"Learning started at %02d:%02d:%02d\" % (datetime.now().hour, datetime.now().minute, datetime.now().second)\n",
    "    while e<number_of_epochs: #This loop goes over epochs\n",
    "        e += 1\n",
    "        #First train on all data from this batch\n",
    "        epoch_start_i = i\n",
    "        start_time = time.time()\n",
    "        for X_batch, Y_batch in cifar10_train_stream.get_epoch_iterator(): \n",
    "            i += 1\n",
    "            lrate = base_lrate * K / np.maximum(K, i)\n",
    "\n",
    "            X_batch = random_transform(X_batch)\n",
    "            L, err_rate, nll, wdec = train_step(X_batch, Y_batch, lrate, momentum, 0) # DROPOUT OFF\n",
    "\n",
    "            train_loss.append((i,L))\n",
    "            train_erros.append((i,err_rate))\n",
    "            train_nll.append((i,nll))\n",
    "            if i % 40 == 0:\n",
    "                print '.',\n",
    "            \n",
    "        # After an epoch compute validation error\n",
    "        val_error_rate = compute_error_rate(cifar10_validation_stream)\n",
    "        if val_error_rate < best_valid_error_rate:\n",
    "            number_of_epochs = np.maximum(number_of_epochs, e * patience_expansion+1)\n",
    "            best_valid_error_rate = val_error_rate\n",
    "            best_params = snapshot_parameters()\n",
    "            best_params_epoch = e\n",
    "            pickle.dump(best_params, open('Conv2.pkl', 'w'))\n",
    "            pickle.dump(e, open('Conv2_e.pkl', 'w'))\n",
    "            pickle.dump(i, open('Conv2_i.pkl', 'w'))\n",
    "            pickle.dump(number_of_epochs, open('Conv2_number_of_epochs.pkl', 'w'))\n",
    "\n",
    "        validation_errors.append((i,val_error_rate))\n",
    "        print \"\\nAfter epoch %d, took %.4fs\" % (e, time.time() - start_time)\n",
    "        print \"valid_err_rate:          %f%% currently going to do %d epochs\" %(\n",
    "            val_error_rate*100, number_of_epochs)\n",
    "        print \"averaged train_err_rate: %f%% averaged train nll: %f averaged train loss: %f\" %(\n",
    "            np.mean(np.asarray(train_erros)[epoch_start_i:,1])*100, \n",
    "            np.mean(np.asarray(train_nll)[epoch_start_i:,1]),\n",
    "            np.mean(np.asarray(train_loss)[epoch_start_i:,1]))\n",
    "except KeyboardInterrupt:\n",
    "    print \"\\nKeyboard interruption, user stopped learning\"\n",
    "\n",
    "\n",
    "print \"Setting network parameters from after epoch %d\" %(best_params_epoch)\n",
    "load_parameters(best_params)\n",
    "\n",
    "print \"Learning ended at %02d:%02d:%02d\" % (datetime.now().hour,\n",
    "                                            datetime.now().minute,\n",
    "                                            datetime.now().second)\n",
    "\n",
    "print \"Test error rate: %f\" % (compute_error_rate(cifar10_test_stream), )\n",
    "\n",
    "subplot(2,1,1)\n",
    "train_loss = np.array(train_loss)\n",
    "semilogy(train_loss[:,0], train_loss[:,1], label='batch train loss')\n",
    "legend()\n",
    "\n",
    "subplot(2,1,2)\n",
    "train_erros = np.array(train_erros)\n",
    "plot(train_erros[:,0], train_erros[:,1], label='batch train error rate')\n",
    "validation_errors = np.array(validation_errors)\n",
    "plot(validation_errors[:,0], validation_errors[:,1], label='validation error rate', color='r')\n",
    "ylim(0,0.4)\n",
    "legend(loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
